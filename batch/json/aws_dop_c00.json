[
  {
    "topic_number": 1,
    "question_number": 1,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 1 discussion",
    "answers": {
      "A": "Use AWS CDK to deploy API Gateway and Lambda functions. When code needs to be changed, update the AWS CloudFormation stack and deploy the new version of the APIs and Lambda functions. Use a Route 53 failover routing policy for the canary release strategy.",
      "B": "Use AWS CloudFormation to deploy API Gateway and Lambda functions using Lambda function versions. When code needs to be changed, update the CloudFormation stack with the new Lambda code and update the API versions using a canary release strategy. Promote the new version when testing is complete.",
      "C": "Use AWS Elastic Beanstalk to deploy API Gateway and Lambda functions. When code needs to be changed, deploy a new version of the API and Lambda functions. Shift traffic gradually using an Elastic Beanstalk blue/green deployment.",
      "D": "Use AWS OpsWorks to deploy API Gateway in the service layer and Lambda functions in a custom layer. When code needs to be changed, use OpsWorks to perform a blue/green deployment and shift traffic gradually."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/48835-exam-aws-devops-engineer-professional-topic-1-question-1/",
    "multiple_choice": false,
    "question_text": "A company wants to migrate its content sharing web application hosted on Amazon EC2 to a serverless architecture. The company currently deploys changes to its application by creating a new Auto Scaling group of EC2 instances and a new Elastic Load Balancer, and then shifting the traffic away using an Amazon Route\n53 weighted routing policy.\nFor its new serverless application, the company is planning to use Amazon API Gateway and AWS Lambda. The company will need to update its deployment processes to work with the new application. It will also need to retain the ability to test new features on a small number of users before rolling the features out to the entire user base.\nWhich deployment strategy will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 2,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 2 discussion",
    "answers": {
      "A": "Create a new DynamoDB table in the new Region with cross-Region replication enabled.",
      "B": "Create new ALB and Auto Scaling group global resources and configure the new ALB to direct traffic to the new Auto Scaling group.",
      "C": "Create new ALB and Auto Scaling group resources in the new Region and configure the new ALB to direct traffic to the new Auto Scaling group.",
      "D": "Create Amazon Route 53 records, health checks, and latency-based routing policies to route to the ALB.",
      "E": "Create Amazon Route 53 aliases, health checks, and failover routing policies to route to the ALB.",
      "F": "Convert the DynamoDB table to a global table."
    },
    "suggested_answer": "CDF",
    "answer": "CDF",
    "link": "https://www.examtopics.com/discussions/amazon/view/28037-exam-aws-devops-engineer-professional-topic-1-question-2/",
    "multiple_choice": true,
    "question_text": "A company's application is currently deployed to a single AWS Region. Recently, the company opened a new office on a different continent. The users in the new office are experiencing high latency. The company's application runs on Amazon EC2 instances behind an Application Load Balancer (ALB) and uses Amazon\nDynamoDB as the database layer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones. A DevOps Engineer is tasked with minimizing application response times and improving availability for users in both Regions.\nWhich combination of actions should be taken to address the latency issues? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 3,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 3 discussion",
    "answers": {
      "A": "Ensure the Lambda function code has exited successfully.",
      "B": "Ensure the Lambda function code returns a response to the pre-signed URL.",
      "C": "Ensure the Lambda function IAM role has cloudformation:UpdateStack permissions for the stack ARN.",
      "D": "Ensure the Lambda function IAM role has ds:ConnectDirectory permissions for the AWS account."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/48069-exam-aws-devops-engineer-professional-topic-1-question-3/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer used an AWS CloudFormation custom resource to set up AD Connector. The AWS Lambda function executed and created AD Connector, but\nCloudFormation is not transitioning from CREATE_IN_PROGRESS to CREATE_COMPLETE.\nWhich action should the engineer take to resolve this issue?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 4,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 4 discussion",
    "answers": {
      "A": "Allow inbound access to TCP port 22 in all associated EC2 security groups from the VPC CIDR range.",
      "B": "Attach an IAM policy with the necessary Systems Manager permissions to the existing IAM instance profile.",
      "C": "Create a VPC endpoint for Systems Manager in the desired Region.",
      "D": "Deploy a new EC2 instance that will act as a bastion host to the rest of the EC2 instance fleet.",
      "E": "Remove any default routes in the associated route tables."
    },
    "suggested_answer": "BC",
    "answer": "BC",
    "link": "https://www.examtopics.com/discussions/amazon/view/28020-exam-aws-devops-engineer-professional-topic-1-question-4/",
    "multiple_choice": true,
    "question_text": "A company plans to stop using Amazon EC2 key pairs for SSH access, and instead plans to use AWS Systems Manager Session Manager. To further enhance security, access to Session Manager must take place over a private network only.\nWhich combinations of actions will accomplish this? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 5,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 5 discussion",
    "answers": {
      "A": "Add the physical machines into AWS Systems Manager using Systems Manager Hybrid Activations.",
      "B": "Attach an IAM role to the EC2 instances, allowing them to be managed by AWS Systems Manager.",
      "C": "Create IAM access keys for the on-premises machines to interact with AWS Systems Manager.",
      "D": "Execute an AWS Systems Manager Automation document to patch the systems every hour.",
      "E": "Use Amazon CloudWatch Events scheduled events to schedule a patch window.",
      "F": "Use AWS Systems Manager Maintenance Windows to schedule a patch window."
    },
    "suggested_answer": "ABF",
    "answer": "ABF",
    "link": "https://www.examtopics.com/discussions/amazon/view/28128-exam-aws-devops-engineer-professional-topic-1-question-5/",
    "multiple_choice": true,
    "question_text": "A company runs an application with an Amazon EC2 and on-premises configuration. A DevOps Engineer needs to standardize patching across both environments. Company policy dictates that patching only happens during non-business hours.\nWhich combination of actions will meet these requirements? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 6,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 6 discussion",
    "answers": {
      "A": "Create one AWS CodeCommit repository for all applications. Put each application's code in different branch. Merge the branches, and use AWS CodeBuild to build the applications. Use AWS CodeDeploy to deploy the applications to one centralized application server.",
      "B": "Create one AWS CodeCommit repository for each of the applications Use AWS CodeBuild to build the applications one at a time. Use AWS CodeDeploy to deploy the applications to one centralized application server.",
      "C": "Create one AWS CodeCommit repository for each of the applications. Use AWS CodeBuild to build the applications one at a time to create one AMI for each server. Use AWS CloudFormation StackSets to automatically provision and decommission Amazon EC2 fleets by using these AMIs.",
      "D": "Create one AWS CodeCommit repository for each of the applications. Use AWS CodeBuild to build one Docker image for each application in Amazon Elastic Container Registry (Amazon ECR). Use AWS CodeDeploy to deploy the applications to Amazon Elastic Container Service (Amazon ECS) on infrastructure that AWS Fargate manages."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/78510-exam-aws-devops-engineer-professional-topic-1-question-6/",
    "multiple_choice": false,
    "question_text": "A company has many applications. Different teams in the company developed the applications by using multiple languages and frameworks. The applications run on premises and on different servers with different operating systems. Each team has its own release protocol and process. The company wants to reduce the complexity of the release and maintenance of these applications.\nThe company is migrating its technology stacks, including these applications, to AWS. The company wants centralized control of source code, a consistent and automatic delivery pipeline, and as few maintenance tasks as possible on the underlying infrastructure.\nWhat should a DevOps engineer do to meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 7,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 7 discussion",
    "answers": {
      "A": "Modify the S3 bucket's ACL to grant bucket-owner-read access to the uploading user's IAM role. Create an IAM policy that grants s3:GetObject operations on the S3 bucket when aws:ResourceTag/DataClassification equals confidential, and s3:ExistingObjectTag/Owner equals ${aws:userid}. Attach the policy to the IAM roles for users who require access to the S3 bucket.",
      "B": "Modify the S3 bucket policy to allow the s3:GetObject action when aws:ResourceTag/DataClassification equals confidential, and s3:ExistingObjectTag/Owner equals ${aws:userid}. Create an IAM policy that grants s3:GetObject operations on the S3 bucket. Attach the policy to the IAM roles for users who require access to the S3 bucket.",
      "C": "Modify the S3 bucket policy to allow the s3:GetObject action when aws:ResourceTag/DataClassification equals confidential, and aws:RequesttTag/Owner equals ${aws:userid}. Create an IAM policy that grants s3:GetObject operations on the S3 bucket. Attach the policy to the IAM roles for users who require access to the S3 bucket.",
      "D": "Modify the S3 bucket's ACL to grant authenticated-read access when aws:ResourceTag/DataClassification equals confidential, and s3:ExistingObjectTag/Owner equals ${aws:userid}. Create an IAM policy that grants s3:GetObject operations on the S3 bucket. Attach the policy to the IAM roles for users who require access to the S3 bucket."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/78521-exam-aws-devops-engineer-professional-topic-1-question-7/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer is developing an application for a company. The application needs to persist files to Amazon S3. The application needs to upload files with different security classifications that the company defines. These classifications include confidential, private, and public. Files that have a confidential classification must not be viewable by anyone other than the user who uploaded them. The application uses the IAM role of the user to call the S3 API operations.\nThe DevOps engineer has modified the application to add a DataClassification tag with the value of confidential and an Owner tag with the uploading user's ID to each confidential object that is uploaded to Amazon S3.\nWhich set of additional steps must the DevOps engineer take to meet the company's requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 8,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 8 discussion",
    "answers": {
      "A": "Add a BeforeAllowTraffic hook to the AppSpec file that tests and waits for any necessary database changes before traffic can flow to the new version of the Lambda function",
      "B": "Add an AfterAllowTraffic hook to the AppSpec file that forces traffic to wait for any pending database changes before allowing the new version of the Lambda function to respond",
      "C": "Add a BeforeInstall hook to the AppSpec file that tests and waits for any necessary database changes before deploying the new version of the Lambda function",
      "D": "Add a ValidateService hook to the AppSpec file that inspects incoming traffic and rejects the payload if dependent services, such as the database, are not yet ready"
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/18123-exam-aws-devops-engineer-professional-topic-1-question-8/",
    "multiple_choice": false,
    "question_text": "A company has developed an AWS Lambda function that handles orders received through an API. The company is using AWS CodeDeploy to deploy the Lambda function as the final stage of a CI/CD pipeline.\nA DevOps Engineer has noticed there are intermittent failures of the ordering API for a few seconds after deployment. After some investigation, the DevOps\nEngineer believes the failures are due to database changes not having fully propagated before the Lambda function begins executing.\nHow should the DevOps Engineer overcome this?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 9,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 9 discussion",
    "answers": {
      "A": "Add a buildspec.yml file to the source code with build instructions.",
      "B": "Configure a GitHub webhook to trigger a build every time a code change is pushed to the repository.",
      "C": "Create an AWS CodeBuild project with GitHub as the source repository.",
      "D": "Create an AWS CodeDeploy application with the Amazon EC2/On-Premises compute platform.",
      "E": "Create an AWS OpsWorks deployment with the install dependencies command.",
      "F": "Provision an Amazon EC2 instance to perform the build."
    },
    "suggested_answer": "ABC",
    "answer": "ABC",
    "link": "https://www.examtopics.com/discussions/amazon/view/48819-exam-aws-devops-engineer-professional-topic-1-question-9/",
    "multiple_choice": true,
    "question_text": "A software company wants to automate the build process for a project where the code is stored in GitHub. When the repository is updated, source code should be compiled, tested, and pushed to Amazon S3.\nWhich combination of steps would address these requirements? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 10,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 10 discussion",
    "answers": {
      "A": "Use Amazon Redshift for the product catalog and Amazon DynamoDB tables for the customer information and purchases.",
      "B": "Use Amazon DynamoDB global tables for the product catalog and regional tables for the customer information and purchases.",
      "C": "Use Aurora with read replicas for the product catalog and additional local Aurora instances in each region for the customer information and purchases.",
      "D": "Use Aurora for the product catalog and Amazon DynamoDB global tables for the customer information and purchases."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/7681-exam-aws-devops-engineer-professional-topic-1-question-10/",
    "multiple_choice": false,
    "question_text": "An online retail company based in the United States plans to expand its operations to Europe and Asia in the next six months. Its product currently runs on\nAmazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. All data is stored in an Amazon Aurora database instance.\nWhen the product is deployed in multiple regions, the company wants a single product catalog across all regions, but for compliance purposes, its customer information and purchases must be kept in each region.\nHow should the company meet these requirements with the LEAST amount of application changes?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 11,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 11 discussion",
    "answers": {
      "A": "Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Amazon Kinesis Agent to capture system logs and deliver them to Amazon S3.",
      "B": "Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Systems Manager Agent to capture system logs and view login activity in the CloudTrail console.",
      "C": "Configure Amazon CloudWatch to detect vulnerabilities on the EC2 instances. Install the AWS Config daemon to capture system logs and view them in the AWS Config console.",
      "D": "Configure Amazon Inspector to detect vulnerabilities on the EC2 instances. Install the Amazon CloudWatch Agent to capture system logs and record them via Amazon CloudWatch Logs."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/47015-exam-aws-devops-engineer-professional-topic-1-question-11/",
    "multiple_choice": false,
    "question_text": "A company wants to ensure that their EC2 instances are secure. They want to be notified if any new vulnerabilities are discovered on their instances, and they also want an audit trail of all login activities on the instances.\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 12,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 12 discussion",
    "answers": {
      "A": "Create a replication IAM role in the source account.",
      "B": "Create a replication IAM role in the target account.",
      "C": "Add statements to the source bucket policy allowing the replication IAM role to replicate objects.",
      "D": "Add statements to the target bucket policy allowing the replication IAM role to replicate objects.",
      "E": "Create a replication rule in the source bucket to enable the replication.",
      "F": "Create a replication rule in the target bucket to enable the replication."
    },
    "suggested_answer": "ADE",
    "answer": "ADE",
    "link": "https://www.examtopics.com/discussions/amazon/view/51619-exam-aws-devops-engineer-professional-topic-1-question-12/",
    "multiple_choice": true,
    "question_text": "A DevOps Engineer needs to back up sensitive Amazon S3 objects that are stored within an S3 bucket with a private bucket policy using the S3 cross-region replication functionality. The objects need to be copied to a target bucket in a different AWS Region and account.\nWhich actions should be performed to enable this replication? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 13,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 13 discussion",
    "answers": {
      "A": "Use AWS Config to ensure all EC2 instances are managed by Amazon Inspector.",
      "B": "Use AWS Config to ensure all EC2 instances are managed by AWS Systems Manager.",
      "C": "Use AWS Systems Manager to install and manage Amazon Inspector, Systems Manager Patch Manager, and the Amazon CloudWatch agent on all instances.",
      "D": "Use Amazon Inspector to install and manage AWS Systems Manager, Systems Manager Patch Manager, and the Amazon CloudWatch agent on all instances.",
      "E": "Use AWS Systems Manager maintenance windows with Systems Manager Run Command to schedule Systems Manager Patch Manager tasks. Use the Amazon CloudWatch agent to schedule Amazon Inspector assessment runs.",
      "F": "Use AWS Systems Manager maintenance windows with Systems Manager Run Command to schedule Systems Manager Patch Manager tasks. Use Amazon CloudWatch Events to schedule Amazon Inspector assessment runs."
    },
    "suggested_answer": "BCF",
    "answer": "BCF",
    "link": "https://www.examtopics.com/discussions/amazon/view/46933-exam-aws-devops-engineer-professional-topic-1-question-13/",
    "multiple_choice": true,
    "question_text": "A company is using Amazon EC2 for various workloads. Company policy requires that instances be managed centrally to standardize configurations. These configurations include standard logging, metrics, security assessments, and weekly patching.\nHow can the company meet these requirements? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 14,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 14 discussion",
    "answers": {
      "A": "Modify the CodeBuild projects within the pipeline to use a compute type with more available network throughput.",
      "B": "Create a custom CodeBuild execution environment that includes a symmetric multiprocessing configuration to run the builds in parallel.",
      "C": "Modify the CodePipeline configuration to execute actions for each Lambda function in parallel by specifying the same runOrder.",
      "D": "Modify each CodeBuild project to run within a VPC and use dedicated instances to increase throughput."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/5043-exam-aws-devops-engineer-professional-topic-1-question-14/",
    "multiple_choice": false,
    "question_text": "A business has an application that consists of five independent AWS Lambda functions.\nThe DevOps Engineer has built a CI/CD pipeline using AWS CodePipeline and AWS CodeBuild that builds, tests, packages, and deploys each Lambda function in sequence. The pipeline uses an Amazon CloudWatch Events rule to ensure the pipeline execution starts as quickly as possible after a change is made to the application source code.\nAfter working with the pipeline for a few months, the DevOps Engineer has noticed the pipeline takes too long to complete.\nWhat should the DevOps Engineer implement to BEST improve the speed of the pipeline?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 15,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 15 discussion",
    "answers": {
      "A": "Upload the licenses to a private Amazon S3 bucket. Create an AWS CloudFormation template with a Mappings section for the licenses. In the template, create an Auto Scaling group to launch the servers. In the user data script, acquire an available license from the Mappings section. Create an Auto Scaling lifecycle hook, then use it to update the mapping after the instance is terminated.",
      "B": "Upload the licenses to an Amazon DynamoDB table. Create an AWS CloudFormation template that uses an Auto Scaling group to launch the servers. In the user data script, acquire an available license from the DynamoDB table. Create an Auto Scaling lifecycle hook, then use it to update the mapping after the instance is terminated.",
      "C": "Upload the licenses to a private Amazon S3 bucket. Populate an Amazon SQS queue with the list of licenses stored in S3. Create an AWS CloudFormation template that uses an Auto Scaling group to launch the servers. In the user data script acquire an available license from SQS. Create an Auto Scaling lifecycle hook, then use it to put the license back in SQS after the instance is terminated.",
      "D": "Upload the licenses to an Amazon DynamoDB table. Create an AWS CLI script to launch the servers by using the parameter --count, with min:max instances to launch. In the user data script, acquire an available license from the DynamoDB table. Monitor each instance and, in case of failure, replace the instance, then manually update the DynamoDB table."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/8044-exam-aws-devops-engineer-professional-topic-1-question-15/",
    "multiple_choice": false,
    "question_text": "A company is creating a software solution that executes a specific parallel-processing mechanism. The software can scale to tens of servers in some special scenarios. This solution uses a proprietary library that is license-based, requiring that each individual server have a single, dedicated license installed. The company has 200 licenses and is planning to run 200 server nodes concurrently at most.\nThe company has requested the following features:\n✑ A mechanism to automate the use of the licenses at scale.\n✑ Creation of a dashboard to use in the future to verify which licenses are available at any moment.\nWhat is the MOST effective way to accomplish these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 16,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 16 discussion",
    "answers": {
      "A": "Launch the application from the CloudFormation template in the second region, which sets the capacity of the Auto Scaling group to 1. Create an Amazon RDS read replica in the second region. In the second region, enable cross-region replication between the original S3 bucket and a new S3 bucket. To fail over, promote the read replica as master. Update the CloudFormation stack and increase the capacity of the Auto Scaling group.",
      "B": "Launch the application from the CloudFormation template in the second region, which sets the capacity of the Auto Scaling group to 1. Create a scheduled task to take daily Amazon RDS cross-region snapshots to the second region. In the second region, enable cross-region replication between the original S3 bucket and Amazon Glacier. In a disaster, launch a new application stack in the second region and restore the database from the most recent snapshot.",
      "C": "Launch the application from the CloudFormation template in the second region, which sets the capacity of the Auto Scaling group to 1. Use Amazon CloudWatch Events to schedule a nightly task to take a snapshot of the database, copy the snapshot to the second region, and replace the DB instance in the second region from the snapshot. In the second region, enable cross-region replication between the original S3 bucket and a new S3 bucket. To fail over, increase the capacity of the Auto Scaling group.",
      "D": "Use Amazon CloudWatch Events to schedule a nightly task to take a snapshot of the database and copy the snapshot to the second region. Create an AWS Lambda function that copies each object to a new S3 bucket in the second region in response to S3 event notifications. In the second region, launch the application from the CloudFormation template and restore the database from the most recent snapshot."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/2335-exam-aws-devops-engineer-professional-topic-1-question-16/",
    "multiple_choice": false,
    "question_text": "A DevOps Engineer administers an application that manages video files for a video production company. The application runs on Amazon EC2 instances behind an ELB Application Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones. Data is stored in an Amazon RDS PostgreSQL\nMulti-AZ DB instance, and the video files are stored in an Amazon S3 bucket. On a typical day, 50 GB of new video are added to the S3 bucket. The Engineer must implement a multi-region disaster recovery plan with the least data loss and the lowest recovery times. The current application infrastructure is already described using AWS CloudFormation.\nWhich deployment option should the Engineer choose to meet the uptime and recovery objectives for the system?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 17,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 17 discussion",
    "answers": {
      "A": "Add a stage to the CodePipeline pipeline between the source and deploy stages. Use AWS CodeBuild to create an execution environment and build commands in the buildspec file to invoke test scripts. If errors are found, use the aws deploy stop-deployment command to stop the deployment.",
      "B": "Add a stage to the CodePipeline pipeline between the source and deploy stages. Use this stage to execute an AWS Lambda function that will run the test scripts. If errors are found, use the aws deploy stop-deployment command to stop the deployment.",
      "C": "Add a hooks section to the CodeDeploy AppSpec file. Use the AfterAllowTestTraffic lifecycle event to invoke an AWS Lambda function to run the test scripts. If errors are found, exit the Lambda function with an error to trigger rollback.",
      "D": "Add a hooks section to the CodeDeploy AppSpec file. Use the AfterAllowTraffic lifecycle event to invoke the test scripts. If errors are found, use the aws deploy stop-deployment CLI command to stop the deployment."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/47953-exam-aws-devops-engineer-professional-topic-1-question-17/",
    "multiple_choice": false,
    "question_text": "A company is using AWS CodePipeline to automate its release pipeline. AWS CodeDeploy is being used in the pipeline to deploy an application to Amazon ECS using the blue/green deployment model. The company wants to implement scripts to test the green version of the application before shifting traffic. These scripts will complete in 5 minutes or less. If errors are discovered during these tests, the application must be rolled back.\nWhich strategy will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 18,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 18 discussion",
    "answers": {
      "A": "Create an Amazon Aurora cluster in one Availability Zone across multiple Regions as the data store. Use Aurora's automatic recovery capabilities in the event of a disaster.",
      "B": "Create an Amazon Aurora global database in two Regions as the data store. In the event of a failure, promote the secondary Region as the master for the application.",
      "C": "Create an Amazon Aurora multi-master cluster across multiple Regions as the data store. Use a Network Load Balancer to balance the database traffic in different Regions.",
      "D": "Set up the application in two Regions and use Amazon Route 53 failover-based routing that points to the Application Load Balancers in both Regions. Use health checks to determine the availability in a given Region. Use Auto Scaling groups in each Region to adjust capacity based on demand.",
      "E": "Set up the application in two Regions and use a multi-Region Auto Scaling group behind Application Load Balancers to manage the capacity based on demand. In the event of a disaster, adjust the Auto Scaling group's desired instance count to increase baseline capacity in the failover Region."
    },
    "suggested_answer": "BD",
    "answer": "BD",
    "link": "https://www.examtopics.com/discussions/amazon/view/48436-exam-aws-devops-engineer-professional-topic-1-question-18/",
    "multiple_choice": true,
    "question_text": "A company requires an RPO of 2 hours and an RTO of 10 minutes for its data and application at all times. An application uses a MySQL database and Amazon\nEC2 web servers. The development team needs a strategy for failover and disaster recovery.\nWhich combination of deployment strategies will meet these requirements? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 19,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 19 discussion",
    "answers": {
      "A": "The S3 bucket default encryption is enabled",
      "B": "There is an error in the S3 bucket policy",
      "C": "The object has been moved to Amazon Glacier",
      "D": "There is an error in the IAM role configuration",
      "E": "S3 versioning is enabled"
    },
    "suggested_answer": "BD",
    "answer": "BD",
    "link": "https://www.examtopics.com/discussions/amazon/view/78641-exam-aws-devops-engineer-professional-topic-1-question-19/",
    "multiple_choice": true,
    "question_text": "An Amazon EC2 instance is running in a Virtual Private Cloud (VPC) and needs to download an object from a restricted Amazon S3 bucket. When the DevOps engineer tries to download, the object an AccessDenied error is received.\nWhat are the possible causes for this error? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 20,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 20 discussion",
    "answers": {
      "A": "Install the CloudWatch agent server side and configure the agent to upload relevant logs to CloudWatch.",
      "B": "Enable AWS X-Ray tracing in API Gateway, modify the application to capture request segments, and upload those segments to X-Ray during each request.",
      "C": "Enable AWS X-Ray tracing in API Gateway, modify the application to capture request segments, and use the X-Ray daemon to upload segments to X-Ray.",
      "D": "Modify the on-premises application to send log information back to API Gateway with each request.",
      "E": "Modify the on-premises application to calculate and upload statistical data relevant to the API service requests to CloudWatch metrics."
    },
    "suggested_answer": "AC",
    "answer": "AC",
    "link": "https://www.examtopics.com/discussions/amazon/view/47013-exam-aws-devops-engineer-professional-topic-1-question-20/",
    "multiple_choice": true,
    "question_text": "A DevOps team manages an API running on-premises that serves as a backend for an Amazon API Gateway endpoint. Customers have been complaining about high response latencies, which the development team has verified using the API Gateway latency metrics in Amazon CloudWatch. To identify the cause, the team needs to collect relevant data without introducing additional latency.\nWhich actions should be taken to accomplish this? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 21,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 21 discussion",
    "answers": {
      "A": "Upload the application as a Docker image that contains all the necessary software to Amazon ECR. Create an Amazon ECS cluster using an AWS Fargate launch type and an Auto Scaling group. Create an AWS CodePipeline pipeline that uses Amazon ECR as a source and Amazon ECS as a deployment provider.",
      "B": "Upload the application code to an AWS CodeCommit repository with a saved configuration file to configure and install the software. Create an AWS Elastic Beanstalk web server tier and a load balanced-type environment that uses the Tomcat solution stack. Create an AWS CodePipeline pipeline that uses CodeCommit as a source and Elastic Beanstalk as a deployment provider.",
      "C": "Upload the application code to an AWS CodeCommit repository with a set of .ebextensions files to configure and install the software. Create an AWS Elastic Beanstalk worker tier environment that uses the Tomcat solution stack. Create an AWS CodePipeline pipeline that uses CodeCommit as a source and Elastic Beanstalk as a deployment provider.",
      "D": "Upload the application code to an AWS CodeCommit repository with an appspec.yml file to configure and install the necessary software. Create an AWS CodeDeploy deployment group associated with an Amazon EC2 Auto Scaling group. Create an AWS CodePipeline pipeline that uses CodeCommit as a source and CodeDeploy as a deployment provider."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/47585-exam-aws-devops-engineer-professional-topic-1-question-21/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer wants to find a solution to migrate an application from on premises to AWS. The application is running on Linux and needs to run on specific versions of Apache Tomcat, HAProxy, and Varnish Cache to function properly. The application's operating system-level parameters require tuning. The solution must include a way to automate the deployment of new application versions. The infrastructure should be scalable and faulty servers should be replaced automatically.\nWhich solution should the DevOps engineer use?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 22,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 22 discussion",
    "answers": {
      "A": "Create AWS Trusted Advisor checks to find and remediate unapproved CloudFormation StackSets.",
      "B": "Create a CloudFormation drift detection operation to find and remediate unapproved CloudFormation StackSets.",
      "C": "Create CloudFormation StackSets with approved CloudFormation templates.",
      "D": "Create AWS Service Catalog products with approved CloudFormation templates."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/47587-exam-aws-devops-engineer-professional-topic-1-question-22/",
    "multiple_choice": false,
    "question_text": "A company wants to use AWS CloudFormation for infrastructure deployment. The company has strict tagging and resource requirements and wants to limit the deployment to two Regions. Developers will need to deploy multiple versions of the same application.\nWhich solution ensures resources are deployed in accordance with company policy?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 23,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 23 discussion",
    "answers": {
      "A": "Use Amazon CloudWatch metrics provided by Elastic Load Balancing to calculate average latency. Alarm and stop deployment when latency increases beyond the defined threshold.",
      "B": "Use AWS Lambda and Elastic Load Balancing access logs to detect average latency. Alarm and stop deployment when latency increases beyond the defined threshold.",
      "C": "Use AWS CodeDeploy's MinimumHealthyHosts setting to define thresholds for rolling back deployments. If these thresholds are breached, roll back the deployment.",
      "D": "Use Metric Filters to parse application logs in Amazon CloudWatch Logs. Create a filter for latency. Alarm and stop deployment when latency increases beyond the defined threshold."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/8034-exam-aws-devops-engineer-professional-topic-1-question-23/",
    "multiple_choice": false,
    "question_text": "A DevOps Engineer must track the health of a stateless RESTful service sitting behind a Classic Load Balancer. The deployment of new application revisions is through a CI/CD pipeline. If the service's latency increases beyond a defined threshold, deployment should be stopped until the service has recovered.\nWhich of the following methods allow for the QUICKEST detection time?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 24,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 24 discussion",
    "answers": {
      "A": "Implement AWS CloudWatch Logs for CodePipeline and CodeDeploy, create an AWS Config rule to evaluate code deployment issues, and create an Amazon SNS topic to notify stakeholders of deployment issues.",
      "B": "Implement AWS CloudWatch Events for CodePipeline and CodeDeploy, create an AWS Lambda function to evaluate code deployment issues, and create an Amazon SNS topic to notify stakeholders of deployment issues.",
      "C": "Implement AWS CloudTrail to record CodePipeline and CodeDeploy API call information, create an AWS Lambda function to evaluate code deployment issues, and create an Amazon SNS topic to notify stakeholders of deployment issues.",
      "D": "Implement AWS CloudWatch Events for CodePipeline and CodeDeploy, create an Amazon Inspector assessment target to evaluate code deployment issues, and create an Amazon SNS topic to notify stakeholders of deployment issues."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/8320-exam-aws-devops-engineer-professional-topic-1-question-24/",
    "multiple_choice": false,
    "question_text": "An AWS CodePipeline pipeline has implemented a code release process. The pipeline is integrated with AWS CodeDeploy to deploy versions of an application to multiple Amazon EC2 instances for each CodePipeline stage.\nDuring a recent deployment, the pipeline failed due to a CodeDeploy issue. The DevOps team wants to improve monitoring and notifications during deployment to decrease resolution times.\nWhat should the DevOps Engineer do to create notifications when issues are discovered?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 25,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 25 discussion",
    "answers": {
      "A": "Check that an Amazon CloudWatch Events rule has been created for the master branch to trigger the pipeline.",
      "B": "Check that the CodePipeline service role has permission to access the CodeCommit repository.",
      "C": "Check that the developer's IAM role has permission to push to the CodeCommit repository.",
      "D": "Check to see if the pipeline failed to start because of CodeCommit errors in Amazon CloudWatch Logs."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/47016-exam-aws-devops-engineer-professional-topic-1-question-25/",
    "multiple_choice": false,
    "question_text": "A development team is using AWS CodeCommit to version control application code and AWS CodePipeline to orchestrate software deployments. The team has decided to use a remote master branch as the trigger for the pipeline to integrate code changes. A developer has pushed code changes to the CodeCommit repository, but noticed that the pipeline had no reaction, even after 10 minutes.\nWhich of the following actions should be taken to troubleshoot this issue?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 26,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 26 discussion",
    "answers": {
      "A": "The networking configuration does not allow the EC2 instances to reach the internet via a NAT gateway or internet gateway, and the CodeDeploy endpoint cannot be reached.",
      "B": "The IAM user who triggered the application deployment does not have permission to interact with the CodeDeploy endpoint.",
      "C": "The target EC2 instances were not properly registered with the CodeDeploy endpoint.",
      "D": "An instance profile with proper permissions was not attached to the target EC2 instances.",
      "E": "The appspec.yml file was not included in the application revision."
    },
    "suggested_answer": "AD",
    "answer": "AD",
    "link": "https://www.examtopics.com/discussions/amazon/view/47925-exam-aws-devops-engineer-professional-topic-1-question-26/",
    "multiple_choice": true,
    "question_text": "A DevOps engineer is deploying a new version of a company's application in an AWS CodeDeploy deployment group associated with its Amazon EC2 instances.\nAfter some time, the deployment fails. The engineer realizes that all the events associated with the specific deployment ID are in a Skipped status, and code was not deployed in the instances associated with the deployment group.\nWhat are valid reasons for this failure? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 27,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 27 discussion",
    "answers": {
      "A": "Configure a latency-based Amazon Route 53 CNAME with health checks so it points to both the primary and replica endpoints. Subscribe an Amazon SNS topic to Amazon RDS failure notifications from AWS CloudTrail and use that topic to trigger an AWS Lambda function that will promote the replica instance as the master.",
      "B": "Create an Aurora custom endpoint to point to the primary database instance. Configure the application to use this endpoint. Configure AWS CloudTrail to run an AWS Lambda function to promote the replica instance and modify the custom endpoint to point to the newly promoted instance.",
      "C": "Create an AWS Lambda function to modify the application's AWS Cloud Formation template to promote the replica, apply the template to update the stack, and point the application to the newly promoted instance. Create an Amazon CloudWatch alarm to trigger this Lambda function after the failure event occurs.",
      "D": "Store the Aurora endpoint in AWS Systems Manager Parameter Store. Create an Amazon EventBridge (Amazon CloudWatch Events) event that defects the database failure and runs an AWS Lambda function to promote the replica instance and update the endpoint URL stored in AWS Systems Manager Parameter Store. Code the application to reload the endpoint from Parameter Store if a database connection fails."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/47924-exam-aws-devops-engineer-professional-topic-1-question-27/",
    "multiple_choice": false,
    "question_text": "A company has an application that is using a MySQL-compatible Amazon Aurora Multi-AZ DB cluster as the database. A cross-Region read replica has been created for disaster recovery purposes. A DevOps engineer wants to automate the promotion of the replica so it becomes the primary database instance in the event of a failure.\nWhich solution will accomplish this?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 28,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 28 discussion",
    "answers": {
      "A": "Collect system logs and application logs by using the Amazon CloudWatch Logs agent. Use the Amazon S3 API to export on-premises logs, and store the logs in an S3 bucket in a central account. Build an Amazon EMR cluster to reduce the logs and derive the root cause.",
      "B": "Collect system logs and application logs by using the Amazon CloudWatch Logs agent. Use the Amazon S3 API to import on-premises logs. Store all logs in S3 buckets in individual accounts. Use Amazon Macie to write a query to search for the required specific event-related data point.",
      "C": "Collect system logs and application logs using the Amazon CloudWatch Logs agent. Install the CloudWatch Logs agent on the on-premises servers. Transfer all logs from AWS to the on-premises data center. Use an Amazon Elasticsearch Logstash Kibana stack to analyze logs on premises.",
      "D": "Collect system logs and application logs by using the Amazon CloudWatch Logs agent. Install a CloudWatch Logs agent for on-premises resources. Store all logs in an S3 bucket in a central account. Set up an Amazon S3 trigger and an AWS Lambda function to analyze incoming logs and automatically identify anomalies. Use Amazon Athena to run ad hoc queries on the logs in the central account."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/8032-exam-aws-devops-engineer-professional-topic-1-question-28/",
    "multiple_choice": false,
    "question_text": "An application has microservices spread across different AWS accounts and is integrated with an on-premises legacy system for some of its functionality.\nBecause of the segmented architecture and missing logs, every time the application experiences issues, it is taking too long to gather the logs to identify the issues. A DevOps Engineer must fix the log aggregation process and provide a way to centrally analyze the logs.\nWhich is the MOST efficient and cost-effective solution?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 29,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 29 discussion",
    "answers": {
      "A": "Create an Amazon CloudWatch Synthetics canary to monitor the firewall state. If the firewall reaches a CRITICAL state or logs a CRITICAL event, use a CloudWatch alarm to publish a notification to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the security team's email address to the topic.",
      "B": "Create an Amazon CloudWatch mettic filter by using a search for CRITICAL events. Publish a custom metric for the finding. Use a CloudWatch alarm based on the custom metric to publish a notification to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the security team's email address to the topic.",
      "C": "Enable Amazon GuardDuty in the network operations account. Configure GuardDuty to monitor flow logs. Create an Amazon EventBridge (Amazon CloudWatch Events) event rule that is invoked by GuardDuty events that are CRITICAL. Define an Amazon Simple Notification Service (Amazon SNS) topic as a target. Subscribe the security team's email address to the topic.",
      "D": "Use AWS Firewall Manager to apply consistent policies across all accounts. Create an Amazon EventBridge (Amazon CloudWatch Events) event rule that is invoked by Firewall Manager events that are CRITICAL. Define an Amazon Simple Notification Service (Amazon SNS) topic as a target. Subscribe the security team's email address to the topic."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/78570-exam-aws-devops-engineer-professional-topic-1-question-29/",
    "multiple_choice": false,
    "question_text": "A company's DevOps engineer is working in a multi-account environment. The company uses AWS Transit Gateway to route all outbound traffic through a network operations account. In the network operations account, all account traffic passes through a firewall appliance for inspection before the traffic goes to an internet gateway.\nThe firewall appliance sends logs to Amazon CloudWatch Logs and includes event severities of CRITICAL, HIGH, MEDIUM, LOW, and INFO. The security team wants to receive an alert if any CRITICAL events occur.\nWhat should the DevOps engineer do to meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 30,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 30 discussion",
    "answers": {
      "A": "Introduce changes as a separate environment parallel to the existing one. Configure API Gateway to use a canary release deployment to send a small subset of user traffic to the new environment.",
      "B": "Introduce changes as a separate environment parallel to the existing one. Update the application's DNS alias records to point to the new environment.",
      "C": "Introduce changes as a separate target group behind the existing Application Load Balancer. Configure API Gateway to route user traffic to the new target group in steps.",
      "D": "Introduce changes as a separate target group behind the existing Application Load Balancer. Configure API Gateway to route all traffic to the Application Load Balancer, which then sends the traffic to the new target group."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/48072-exam-aws-devops-engineer-professional-topic-1-question-30/",
    "multiple_choice": false,
    "question_text": "A company recently migrated its legacy application from on-premises to AWS. The application is hosted on Amazon EC2 instances behind an Application Load\nBalancer, which is behind Amazon API Gateway. The company wants to ensure users experience minimal disruptions during any deployment of a new version of the application. The company also wants to ensure it can quickly roll back updates if there is an issue.\nWhich solution will meet these requirements with MINIMAL changes to the application?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 31,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 31 discussion",
    "answers": {
      "A": "Auto Scaling groups can create new instances in a single AZ only.",
      "B": "The EC2 instances have not been manually associated to the ALB.",
      "C": "The ALB should be replaced with a Network Load Balancer (NLB).",
      "D": "The new AZ has not been added to the ALB."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/46365-exam-aws-devops-engineer-professional-topic-1-question-31/",
    "multiple_choice": false,
    "question_text": "A company recently launched an application that is more popular than expected. The company wants to ensure the application can scale to meet increasing demands and provide reliability using multiple Availability Zones (AZs). The application runs on a fleet of Amazon EC2 instances behind an Application Load\nBalancer (ALB). A DevOps engineer has created an Auto Scaling group across multiple AZs for the application. Instances launched in the newly added AZs are not receiving any traffic for the application.\nWhat is likely causing this issue?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 32,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 32 discussion",
    "answers": {
      "A": "Use an AWS CloudFormation template with a retention policy for the ALB set to 1 hour. Update the Amazon Route 53 record to reflect the new ALB.",
      "B": "Use two AWS Elastic Beanstalk environments to perform a blue/green deployment from the original environment to the new one. Create an application version lifecycle policy to terminate the original environment in 1 hour.",
      "C": "Use AWS CodeDeploy with a deployment group configured with a blue/green deployment configuration. Select the option Terminate the original instances in the deployment group with a waiting period of 1 hour.",
      "D": "Use AWS Elastic Beanstalk with the configuration set to Immutable. Create an .ebextension using the Resources key that sets the deletion policy of the ALB to 1 hour, and deploy the application."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/28034-exam-aws-devops-engineer-professional-topic-1-question-32/",
    "multiple_choice": false,
    "question_text": "A DevOps Engineer manages a web application that runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The instances run in an EC2\nAuto Scaling group across multiple Availability Zones. The engineer needs to implement a deployment strategy that:\n✑ Launches a second fleet of instances with the same capacity as the original fleet.\n✑ Maintains the original fleet unchanged while the second fleet is launched.\n✑ Transitions traffic to the second fleet when the second fleet is fully deployed.\n✑ Terminates the original fleet automatically 1 hour after transition.\nWhich solution will satisfy these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 33,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 33 discussion",
    "answers": {
      "A": "Use AWS Systems Manager Configuration Compliance. Use calls to the put-compliance-items API action to scan and build a database of noncompliant EC2 instances based on their host placement configuration. Use an Amazon DynamoDB table to store these instance IDs for fast access. Generate a report through Systems Manager by calling the list-compliance-summaries API action.",
      "B": "Use custom Java code running on an EC2 instance. Set up EC2 Auto Scaling for the instance depending on the number of instances to be checked. Send the list of noncompliant EC2 instance IDs to an Amazon SQS queue. Set up another worker instance to process instance IDs from the SQS queue and write them to Amazon DynamoDB. Use an AWS Lambda function to terminate noncompliant instance IDs obtained from the queue, and send them to an Amazon SNS email topic for distribution.",
      "C": "Use AWS Config. Identify all EC2 instances to be audited by enabling Config Recording on all Amazon EC2 resources for the region. Create a custom AWS Config rule that triggers an AWS Lambda function by using the ג€config-rule-change-triggeredג€ blueprint. Modify the Lambda evaluateCompliance() function to verify host placement to return a NON_COMPLIANT result if the instance is not running on an EC2 Dedicated Host. Use the AWS Config report to address noncompliant instances.",
      "D": "Use AWS CloudTrail. Identify all EC2 instances to be audited by analyzing all calls to the EC2 RunCommand API action. Invoke an AWS Lambda function that analyzes the host placement of the instance. Store the EC2 instance ID of noncompliant resources in an Amazon RDS MySQL DB instance. Generate a report by querying the RDS instance and exporting the query results to a CSV text file."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/2843-exam-aws-devops-engineer-professional-topic-1-question-33/",
    "multiple_choice": false,
    "question_text": "A healthcare services company is concerned about the growing costs of software licensing for an application for monitoring patient wellness. The company wants to create an audit process to ensure that the application is running exclusively on Amazon EC2 Dedicated Hosts. A DevOps Engineer must create a workflow to audit the application to ensure compliance.\nWhat steps should the Engineer take to meet this requirement with the LEAST administrative overhead?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 34,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 34 discussion",
    "answers": {
      "A": "Filter the data through AWS X-Ray to visualize the data.",
      "B": "Filter the data through Amazon QuickSight to visualize the data.",
      "C": "Query the data with Amazon Athena.",
      "D": "Query the data with Amazon Redshift.",
      "E": "Use AWS Glue as the persistent metadata store.",
      "F": "Use Amazon S3 as the persistent metadata store."
    },
    "suggested_answer": "BCE",
    "answer": "BCE",
    "link": "https://www.examtopics.com/discussions/amazon/view/48004-exam-aws-devops-engineer-professional-topic-1-question-34/",
    "multiple_choice": true,
    "question_text": "A company has 100 GB of log data in an Amazon S3 bucket stored in .csv format. SQL developers want to query this data and generate graphs to visualize it.\nThey also need an efficient, automated way to store metadata from the .csv file.\nWhich combination of steps should be taken to meet these requirements with the LEAST amount of effort? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 35,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 35 discussion",
    "answers": {
      "A": "Have the application send its logs to an Amazon EMR cluster and normalize the logs before sending them to Amazon S3",
      "B": "Have the application send its logs to Amazon QuickSight, then use the Amazon QuickSight SPICE engine to normalize the logs. Do the analysis directly from Amazon QuickSight",
      "C": "Keep the logs in Amazon S3 and use Amazon Redshift Spectrum to normalize the logs in place",
      "D": "Use Amazon Kinesis Agent on each server to upload the logs and have Amazon Kinesis Data Firehose use an AWS Lambda function to normalize the logs before writing them to Amazon S3"
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/19604-exam-aws-devops-engineer-professional-topic-1-question-35/",
    "multiple_choice": false,
    "question_text": "A DevOps Engineer has several legacy applications that all generate different log formats. The Engineer must standardize the formats before writing them to\nAmazon S3 for querying and analysis.\nHow can this requirement be met at the LOWEST cost?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 36,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 36 discussion",
    "answers": {
      "A": "Configure an AWS CodePipeline pipeline with a build stage using AWS CodeBuild.",
      "B": "Copy the build artifact from CodeCommit to Amazon S3.",
      "C": "Create an Auto Scaling group of Amazon EC2 instances behind an Application Load Balancer (ALB) and set the ALB as the deployment target in AWS CodePipeline.",
      "D": "Create an AWS Elastic Beanstalk environment as the deployment target in AWS CodePipeline.",
      "E": "Implement an Amazon SQS queue to decouple the pipeline components.",
      "F": "Provision all resources using AWS CloudFormation."
    },
    "suggested_answer": "ADF",
    "answer": "ADF",
    "link": "https://www.examtopics.com/discussions/amazon/view/78881-exam-aws-devops-engineer-professional-topic-1-question-36/",
    "multiple_choice": true,
    "question_text": "A company needs to implement a robust CI/CD pipeline to automate the deployment of an application in AWS. The pipeline must support continuous integration, continuous delivery, and automatic rollback upon deployment failure. The entire CI/CD pipeline must be capable of being re-provisioned in alternate AWS accounts or Regions within minutes. A DevOps engineer has already created an AWS CodeCommit repository to store the source code.\nWhich combination of actions should be taken when building this pipeline to meet these requirements? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 37,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 37 discussion",
    "answers": {
      "A": "Create primary and secondary Amazon S3 buckets in two separate Availability Zones that are at least 500 miles (805 kilometers) apart. Use a bucket policy to enforce access to the buckets only through HTTPS. Use a bucket policy to enforce Amazon S3 SSE-C on all objects uploaded to the bucket. Configure cross- region replication between the two buckets.",
      "B": "Create primary and secondary Amazon S3 buckets in two separate AWS Regions that are at least 500 miles (805 kilometers) apart. Use a bucket policy to enforce access to the buckets only through HTTPS. Use a bucket policy to enforce S3-Managed Keys (SSE-S3) on all objects uploaded to the bucket. Configure cross-region replication between the two buckets.",
      "C": "Create primary and secondary Amazon S3 buckets in two separate AWS Regions that are at least 500 miles (805 kilometers) apart. Use an IAM role to enforce access to the buckets only through HTTPS. Use a bucket policy to enforce Amazon S3-Managed Keys (SSE-S3) on all objects uploaded to the bucket. Configure cross-region replication between the two buckets.",
      "D": "Create primary and secondary Amazon S3 buckets in two separate Availability Zones that are at least 500 miles (805 kilometers) apart. Use a bucket policy to enforce access to the buckets only through HTTPS. Use a bucket policy to enforce AWS KMS encryption on all objects uploaded to the bucket. Configure cross-region replication between the two buckets. Create a KMS Customer Master Key (CMK) in the primary region for encrypting objects."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/82871-exam-aws-devops-engineer-professional-topic-1-question-37/",
    "multiple_choice": false,
    "question_text": "A company is building a solution for storing files containing Personally Identifiable Information (PII) on AWS.\nRequirements state:\n✑ All data must be encrypted at rest and in transit.\n✑ All data must be replicated in at least two locations that are at least 500 miles (805 kilometers) apart.\nWhich solution meets these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 38,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 38 discussion",
    "answers": {
      "A": "Modify the post_build to command to use ג€\"-acl public-read and configure a bucket policy that grants read access to the relevant AWS accounts only.",
      "B": "Configure a default ACL for the S3 bucket that defines the set of authenticated users as the relevant AWS accounts only and grants read-only access.",
      "C": "Create an S3 bucket policy that grants read access to the relevant AWS accounts and denies read access to the principal ג€*ג€",
      "D": "Modify the post_build command to remove ג€\"-acl authenticated-read and configure a bucket policy that allows read access to the relevant AWS accounts only."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/8455-exam-aws-devops-engineer-professional-topic-1-question-38/",
    "multiple_choice": false,
    "question_text": "A company is using an AWS CodeBuild project to build and package an application. The packages are copied to a shared Amazon S3 bucket before being deployed across multiple AWS accounts.\nThe buildspec.yml file contains the following:\n//IMG//\n\nThe DevOps Engineer has noticed that anybody with an AWS account is able to download the artifacts.\nWhat steps should the DevOps Engineer take to stop this?",
    "answer_images": [],
    "question_images": [
      "https://www.examtopics.com/assets/media/exam-media/04243/0002400001.png"
    ]
  },
  {
    "topic_number": 1,
    "question_number": 39,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 39 discussion",
    "answers": {
      "A": "Create an IAM user and SSH keys for each contractor. Add the public SSH key to the application server's SSH authorized_keys file. Instruct the contractors to install the AWS CLI and AWS Systems Manager Session Manager plugin, update their AWS credentials files with their private keys, and use the aws ssm start-session command to gain access to the target application server instance ID.",
      "B": "Ask each contractor to securely send their SSH public key. Add this public key to the application server's SSH authorized-keys file. Instruct the contractors to use their private key to connect to the application server through SSH.",
      "C": "Ask each contractor to securely send their SSH public key. Use EC2 pairs to import their key. Update the application server's SSH authorized_keys file. Instruct the contractors to use their private key to connect to the application server through SSH.",
      "D": "Create an IAM user for each contractor with programmatic access. Add each user to an IAM group that has a policy that allows the ssm:StartSession action. Instruct the contractors to install the AWS CLI and AWS Systems Manager Session Manager plugin, update their AWS credentials files with their access keys, and use the aws ssm start-session to gain access to the target application server instance ID."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/78785-exam-aws-devops-engineer-professional-topic-1-question-39/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer needs to grant several external contractors access to a legacy application that runs on an Amazon Linux Amazon EC2 instance. The application server is available only in a private subnet. The contractors are not authorized for VPN access.\nWhat should the DevOps engineer do to grant the contactors access to the application server?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 40,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 40 discussion",
    "answers": {
      "A": "Add the instance to an EC2 Auto Scaling group with the minimum, maximum, and desired capacity set to 1.",
      "B": "Add the instance to an EC2 Auto Scaling group with a lifecycle hook to detach the EBS volume when the EC2 instance shuts down or terminates.",
      "C": "Create an Amazon CloudWatch alarm for the StatusCheckFailed_System metric and select the EC2 action to recover the instance.",
      "D": "Create an Amazon CloudWatch alarm for the StatusCheckFailed_Instance metric and select the EC2 action to reboot the instance."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/47001-exam-aws-devops-engineer-professional-topic-1-question-40/",
    "multiple_choice": false,
    "question_text": "A company hosts its staging website using an Amazon EC2 instance backed with Amazon EBS storage. The company wants to recover quickly with minimal data losses in the event of network connectivity issues or power failures on the EC2 instance.\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 41,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 41 discussion",
    "answers": {
      "A": "✑ A subdomain us.example.com with weighted routing: the US ALB with weight 2 and the EU ALB with weight 1.\n✑ Another subdomain eu.example.com with weighted routing: the EU ALB with weight 2 and the US ALB with weight 1.\n✑ Geolocation routing records for example.com: North America aliased to us.example.com and Europe aliased to eu.example.com.",
      "B": "✑ A subdomain us.example.com with latency-based routing: the US ALB as the first target and the EU ALB as the second target.\n✑ Another subdomain eu.example.com with latency-based routing: the EU ALB as the first target and the US ALB as the second target.\n✑ Failover routing records for example.com aliased to us.example.com as the first target and eu.example.com as the second target.",
      "C": "✑ A subdomain us.example.com with failover routing: the US ALB as primary and the EU ALB as secondary.\n✑ Another subdomain eu.example.com with failover routing: the EU ALB as primary and the US ALB as secondary.\n✑ Latency-based routing records for example.com that are aliased to us.example.com and eu.example.com.",
      "D": "✑ A subdomain us.example.com with multivalue answer routing: the US ALB first and the EU ALB second.\n✑ Another subdomain eu.example.com with multivalue answer routing: the EU ALB first and the US ALB second.\n✑ Failover routing records for example.com that are aliased to us.example.com and eu.example.com."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/46934-exam-aws-devops-engineer-professional-topic-1-question-41/",
    "multiple_choice": false,
    "question_text": "A company has built a web service that runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The company has deployed the application in us-east-1. Amazon Route 53 provides an external DNS that routes traffic from example.com to the application, created with appropriate health checks.\nThe company has deployed a second environment for the application in eu-west-1. The company wants traffic to be routed to whichever environment results in the best response time for each user. If there is an outage in one Region, traffic should be directed to the other environment.\nWhich configuration will achieve these requirements?\nA.\n✑ A subdomain us.example.com with weighted routing: the US ALB with weight 2 and the EU ALB with weight 1.\n✑ Another subdomain eu.example.com with weighted routing: the EU ALB with weight 2 and the US ALB with weight 1.\n✑ Geolocation routing records for example.com: North America aliased to us.example.com and Europe aliased to eu.example.com.\nB.\n✑ A subdomain us.example.com with latency-based routing: the US ALB as the first target and the EU ALB as the second target.\n✑ Another subdomain eu.example.com with latency-based routing: the EU ALB as the first target and the US ALB as the second target.\n✑ Failover routing records for example.com aliased to us.example.com as the first target and eu.example.com as the second target.\nC.\n✑ A subdomain us.example.com with failover routing: the US ALB as primary and the EU ALB as secondary.\n✑ Another subdomain eu.example.com with failover routing: the EU ALB as primary and the US ALB as secondary.\n✑ Latency-based routing records for example.com that are aliased to us.example.com and eu.example.com.\nD.\n✑ A subdomain us.example.com with multivalue answer routing: the US ALB first and the EU ALB second.\n✑ Another subdomain eu.example.com with multivalue answer routing: the EU ALB first and the US ALB second.\n✑ Failover routing records for example.com that are aliased to us.example.com and eu.example.com.",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 42,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 42 discussion",
    "answers": {
      "A": "Use a scheduled Amazon CloudWatch Events rule to filter for Amazon EC2 instance status checks and identify idle EC2 instances. Use the CloudWatch Events rule to target an AWS Lambda function to stop non-production instances and send notifications.",
      "B": "Use a scheduled Amazon CloudWatch Events rule to filter AWS Systems Manager events and identify idle EC2 instances and resources. Use the CloudWatch Events rule to target an AWS Lambda function to stop non-production instances and send notifications.",
      "C": "Use a scheduled Amazon CloudWatch Events rule to target a custom AWS Lambda function that runs AWS Trusted Advisor checks. Create a second CloudWatch Events rule to filter events from Trusted Advisor to trigger a Lambda function to stop idle non-production instances and send notifications.",
      "D": "Use a scheduled Amazon CloudWatch Events rule to target Amazon Inspector events for idle EC2 instances. Use the CloudWatch Events rule to target the AWS Lambda function to stop non-production instances and send notifications."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/47270-exam-aws-devops-engineer-professional-topic-1-question-42/",
    "multiple_choice": false,
    "question_text": "A company has multiple development teams sharing one AWS account. The development team's manager wants to be able to automatically stop Amazon EC2 instances and receive notifications if resources are idle and not tagged as production resources.\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 43,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 43 discussion",
    "answers": {
      "A": "Use Amazon Aurora as a drop-in replacement for RDS MySQL. Use snapshots to populate the table with the correct data.",
      "B": "Modify the launch configuration of the Auto Scaling group to pause user data execution for 600 seconds, allowing the table to be populated.",
      "C": "Use AWS Step Functions to monitor and maintain the state of data population. Mark the database in service before continuing with the deployment.",
      "D": "Use an EC2 Auto Scaling lifecycle hook to pause the configuration of the web tier until the table is populated."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/28583-exam-aws-devops-engineer-professional-topic-1-question-43/",
    "multiple_choice": false,
    "question_text": "An n-tier application requires a table in an Amazon RDS MySQL DB instance to be dropped and repopulated at each deployment. This process can take several minutes and the web tier cannot come online until the process is complete. Currently, the web tier is configured in an Amazon EC2 Auto Scaling group, with instances being terminated and replaced at each deployment. The MySQL table is populated by running a SQL query through an AWS CodeBuild job.\nWhat should be done to ensure that the web tier does not come online before the database is completely configured?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 44,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 44 discussion",
    "answers": {
      "A": "Install the Amazon Inspector agent on each EC2 instance. Subscribe to Amazon CloudWatch Events notifications. Trigger an AWS Lambda function to check if a message is about user logins. If it is, send a notification to the Security team using Amazon SNS.",
      "B": "Install the Amazon CloudWatch agent on each EC2 instance. Configure the agent to push all logs to Amazon CloudWatch Logs and set up a CloudWatch metric filter that searches for user logins. If a login is found, send a notification to the Security team using Amazon SNS.",
      "C": "Set up AWS CloudTrail with Amazon CloudWatch Logs. Subscribe CloudWatch Logs to Amazon Kinesis. Attach AWS Lambda to Kinesis to parse and determine if a log contains a user login. If it does, send a notification to the Security team using Amazon SNS.",
      "D": "Set up a script on each Amazon EC2 instance to push all logs to Amazon S3. Set up an S3 event to trigger an AWS Lambda function, which triggers an Amazon Athena query to run. The Athena query checks for logins and sends the output to the Security team using Amazon SNS."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/28082-exam-aws-devops-engineer-professional-topic-1-question-44/",
    "multiple_choice": false,
    "question_text": "A highly regulated company has a policy that DevOps Engineers should not log in to their Amazon EC2 instances except in emergencies. If a DevOps Engineer does log in, the Security team must be notified within 15 minutes of the occurrence.\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 45,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 45 discussion",
    "answers": {
      "A": "Insert a manual approval action between the test actions and deployment actions of the pipeline.",
      "B": "Modify the buildspec.yml file for the compilation stage to require manual approval before completion.",
      "C": "Update the CodeDeploy deployment groups so that they require manual approval to proceed.",
      "D": "Update the pipeline to directly call the REST API for the penetration testing tool.",
      "E": "Update the pipeline to invoke a Lambda function that calls the REST API for the penetration testing tool."
    },
    "suggested_answer": "AE",
    "answer": "AE",
    "link": "https://www.examtopics.com/discussions/amazon/view/78792-exam-aws-devops-engineer-professional-topic-1-question-45/",
    "multiple_choice": true,
    "question_text": "A DevOps engineer has automated a web service deployment by using AWS CodePipeline with the following steps:\n1. An AWS CodeBuild project compiles the deployment artifact and runs unit tests.\n2. An AWS CodeDeploy deployment group deploys the web service to Amazon EC2 instances in the staging environment.\n3. A CodeDeploy deployment group deploys the web service to EC2 instances in the production environment.\nThe quality assurance (QA) team requests permission to inspect the build artifact before the deployment to the production environment occurs. The QA team wants to run an internal penetration testing tool to conduct manual tests. The tool will be invoked by a REST API call.\nWhich combination of actions should the DevOps engineer take to fulfill this request? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 46,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 46 discussion",
    "answers": {
      "A": "Modify the Kinesis consumer application to store the logs durably in Amazon S3. Use Amazon EMR to process the data directly on Amazon S3 to derive customer insights. Store the results in Amazon S3.",
      "B": "Horizontally scale the Kinesis consumer application by adding more EC2 instances based on the Amazon CloudWatch GetRecords.IteratorAgeMilliseconds metric. Increase the retention period of the Kinesis Data Streams.",
      "C": "Convert the Kinesis consumer application to run as an AWS Lambda function. Configure the Kinesis Data Streams as the event source for the Lambda function to process the data streams.",
      "D": "Increase the number of shards in the Kinesis Data Streams to increase the overall throughput so that the consumer application processes data faster."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/78795-exam-aws-devops-engineer-professional-topic-1-question-46/",
    "multiple_choice": false,
    "question_text": "A DevOps Engineer manages a large commercial website that runs on Amazon EC2. The website uses Amazon Kinesis Data Streams to collect and process web logs. The DevOps Engineer manages the Kinesis consumer application, which also runs on Amazon EC2.\nSudden increases of data cause the Kinesis consumer application to fall behind, and the Kinesis data streams drop records before the records can be processed.\nThe DevOps Engineer must implement a solution to improve stream handling.\nWhich solution meets these requirements with the MOST operational efficiency?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 47,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 47 discussion",
    "answers": {
      "A": "Create an AWS CloudFormation template that defines an AWS Inspector rule to check whether EBS encryption is enabled. Save the template to an Amazon S3 bucket that has been shared with all accounts within the company. Update the account creation script pointing to the CloudFormation template in Amazon S3.",
      "B": "Create an AWS Config organizational rule to check whether EBS encryption is enabled and deploy the rule using the AWS CLI. Create and apply an SCP to prohibit stopping and deleting AWS Config across the organization.",
      "C": "Create an SCP in Organizations. Set the policy to prevent the launch of Amazon EC2 instances without encryption on the EBS volumes using a conditional expression. Apply the SCP to all AWS accounts. Use Amazon Athena to analyze the AWS CloudTrail output, looking for events that deny an ec2:RunInstances action.",
      "D": "Deploy an IAM role to all accounts from a single trusted account. Build a pipeline with AWS CodePipeline with a stage in AWS Lambda to assume the IAM role, and list all EBS volumes in the account. Publish a report to Amazon S3."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/52621-exam-aws-devops-engineer-professional-topic-1-question-47/",
    "multiple_choice": false,
    "question_text": "A company uses AWS Organizations to manage multiple accounts. Information security policies require that all unencrypted Amazon EBS volumes be marked as non-compliant. A DevOps engineer needs to automatically deploy the solution and ensure that this compliance check is always present.\nWith solution will accomplish this?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 48,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 48 discussion",
    "answers": {
      "A": "Convert the RDS database to an Amazon Aurora Serverless database. Use an AWS Lambda function to start and stop the EC2 instances before and after tests.",
      "B": "Put the EC2 instances into an Auto Scaling group. Schedule scaling to run at the start of the deployment tests.",
      "C": "Replace the EC2 instances with EC2 Spot Instances and the RDS database with an RDS Reserved Instance.",
      "D": "Subscribe Amazon CloudWatch Events to CodePipeline to trigger AWS Systems Manager Automation documents that start and stop all EC2 and RDS instances before and after deployment tests."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/47930-exam-aws-devops-engineer-professional-topic-1-question-48/",
    "multiple_choice": false,
    "question_text": "A company develops and maintains a web application using Amazon EC2 instances and an Amazon RDS for SQL Server DB instance in a single Availability\nZone. The resources need to run only when new deployments are being tested using AWS CodePipeline. Testing occurs one or more times a week and each test takes 2-3 hours to run. A DevOps engineer wants a solution that does not change the architecture components.\nWhich solution will meet these requirements in the MOST cost-effective manner?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 49,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 49 discussion",
    "answers": {
      "A": "Combine the multiple separate code repositories into a single one, and deploy using an AWS CodePipeline that has logic for each project.",
      "B": "Create new pipelines by using the AWS API or AWS CLI, and configure them to use a single S3 bucket with separate prefixes for each project.",
      "C": "Create a new pipeline in a different region for each project to bypass the service limits for S3 buckets in a single region.",
      "D": "Create a new pipeline and S3 bucket for each project by using the AWS API or AWS CLI to bypass the service limits for S3 buckets in a single account."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/46890-exam-aws-devops-engineer-professional-topic-1-question-49/",
    "multiple_choice": false,
    "question_text": "The Development team has grown substantially in recent months and so has the number of projects that use separate code repositories. The current process involves configuring AWS CodePipeline manually. There have been service limit alerts regarding the number of Amazon S3 buckets that exist.\nWhich pipeline option will reduce S3 bucket sprawl alerts?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 50,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 50 discussion",
    "answers": {
      "A": "Activate the user-defined cost allocation tags in each AWS account.",
      "B": "Create and attach an SCP that requires a specific tag.",
      "C": "Define each line of business (LOB) in AWS Budgets. Assign the required tag to each resource.",
      "D": "Scan all accounts with Tag Editor. Assign the required tag to each resource.",
      "E": "Use the budget report to find untagged resources. Assign the required tag to each resource."
    },
    "suggested_answer": "BD",
    "answer": "BD",
    "link": "https://www.examtopics.com/discussions/amazon/view/80129-exam-aws-devops-engineer-professional-topic-1-question-50/",
    "multiple_choice": true,
    "question_text": "A company runs several applications across multiple AWS accounts in an organization in AWS Organizations. Some of the resources are not tagged properly and the company's finance team cannot determine which costs are associated with which applications. A DevOps engineer must remediate this issue and prevent this issue from happening in the future.\nWhich combination of actions should the DevOps engineer take to meet these requirements? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 51,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 51 discussion",
    "answers": {
      "A": "At instance launch time, use EC2 user data to deploy the AWS CodeDeploy agent. Use CodeDeploy to install the Puppet agent. When the Auto Scaling group scales out, run a script to register the newly deployed instances to the Puppet master. When the Auto Scaling group scales in, use the EC2 Auto Scaling EC2_INSTANCE_TERMINATING lifecycle hook to trigger de-registration from the Puppet master.",
      "B": "Bake the AWS CodeDeploy agent into the base AMI. When the Auto Scaling group scales out, use CodeDeploy to install the Puppet agent, and execute a script to register the newly deployed instances to the Puppet master. When the Auto Scaling group scales in, use the CodeDeploy ApplicationStop lifecycle hook to run a script to de-register the instance from the Puppet master.",
      "C": "At instance launch time, use EC2 user data to deploy the AWS CodeDeploy agent. When the Auto Scaling group scales out, use CodeDeploy to install the Puppet agent, and run a script to register the newly deployed instances to the Puppet master. When the Auto Scaling group scales in, use the EC2 user data instance stop script to run a script to de-register the instance from the Puppet master.",
      "D": "Bake the AWS Systems Manager agent into the base AMI. When the Auto Scaling group scales out, use the AWS Systems Manager to install the Puppet agent, and run a script to register the newly deployed instances to the Puppet master. When the Auto Scaling group scales in, use the Systems Manager instance stop lifecycle hook to run a script to de-register the instance from the Puppet master."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/8075-exam-aws-devops-engineer-professional-topic-1-question-51/",
    "multiple_choice": false,
    "question_text": "An online company uses Amazon EC2 Auto Scaling extensively to provide an excellent customer experience while minimizing the number of running EC2 instances. The company's self-hosted Puppet environment in the application layer manages the configuration of the instances. The IT manager wants the lowest licensing costs and wants to ensure that whenever the EC2 Auto Scaling group scales down, removed EC2 instances are deregistered from the Puppet master as soon as possible.\nHow can the requirement be met?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 52,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 52 discussion",
    "answers": {
      "A": "Create an AWS Lambda function to deploy the CloudFormation templates in the required order. Use stack policies to alert the data engineering team.",
      "B": "Host the CloudFormation templates in Amazon S3. Use Amazon S3 events to directly trigger CloudFormation updates and Amazon SNS notifications.",
      "C": "Implement CloudFormation StackSets and use drift detection to trigger update alerts to the data engineering team.",
      "D": "Leverage CloudFormation nested stacks and stack sets for deployments. Use Amazon SNS to notify the data engineering team."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/83032-exam-aws-devops-engineer-professional-topic-1-question-52/",
    "multiple_choice": false,
    "question_text": "A company uses a series of individual Amazon CloudFormation templates to deploy its multi-Region applications. These templates must be deployed in a specific order. The company is making more changes to the templates than previously expected and wants to deploy new templates more efficiently. Additionally, the data engineering team must be notified of all changes to the templates.\nWhat should the company do to accomplish these goals?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 53,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 53 discussion",
    "answers": {
      "A": "Add a health check to the Auto Scaling group to invoke an AWS Lambda function whenever an instance status is impaired.",
      "B": "Configure the Auto Scaling group to send a notification to an Amazon SNS topic whenever a failed instance launch occurs.",
      "C": "Create an Amazon CloudWatch alarm that invokes an AWS Lambda function when a failed AttachInstances Auto Scaling API call is made.",
      "D": "Create a status check alarm on Amazon EC2 to send a notification to an Amazon SNS topic whenever a status check fail occurs."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/28613-exam-aws-devops-engineer-professional-topic-1-question-53/",
    "multiple_choice": false,
    "question_text": "A company is running an application on Amazon EC2 instances in an Auto Scaling group. Recently, an issue occurred that prevented EC2 instances from launching successfully, and it took several hours for the Support team to discover the issue. The Support team wants to be notified by email whenever an EC2 instance does not start successfully.\nWhich action will accomplish this?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 54,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 54 discussion",
    "answers": {
      "A": "Configure a nightly Amazon EventBridge (Amazon CloudWatch Events) event to trigger an AWS Lambda function to run the RefreshCache command for Storage Gateway.",
      "B": "Instruct the third party to put data into the S3 bucket using AWS Transfer for SFTP.",
      "C": "Modify Storage Gateway to run in volume gateway mode.",
      "D": "Use S3 same-Region replication to replicate any changes made directly in the S3 bucket to Storage Gateway."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/48068-exam-aws-devops-engineer-professional-topic-1-question-54/",
    "multiple_choice": false,
    "question_text": "A company uses AWS Storage Gateway in file gateway mode in front of an Amazon S3 bucket that is used by multiple resources. In the morning when business begins, users do not see the objects processed by a third party the previous evening. When a DevOps engineer looks directly at the S3 bucket, the data is there, but it is missing in Storage Gateway.\nWhich solution ensures that all the updated third-party files are available in the morning?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 55,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 55 discussion",
    "answers": {
      "A": "Only one event notification is allowed from the S3 console.",
      "B": "Amazon S3 needs proper permissions to publish an event notification to Amazon SNS.",
      "C": "Lambda has precedence over Amazon SNS in handling the event notification.",
      "D": "Amazon SNS is not a valid destination for some S3 event notifications, including object PUT."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/78822-exam-aws-devops-engineer-professional-topic-1-question-55/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer sets up two Amazon S3 event notifications for an S3 bucket from the S3 console. Both event notifications will be invoked when an object PUT action occurs. One event notification will invoke an AWS Lambda function if the file suffix is .csv. Another event notification will invoke an Amazon Simple\nNotification Service (Amazon SNS) topic if the file suffix is .xlsx\nThe DevOps engineer notices that files with the .csv suffix can invoke the Lambda function successfully. However, files with the .xlsx suffix cannot invoke the SNS topic.\nWhich reason explains why the SNS topic is not invoked when .xlsx files are added to the S3 bucket?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 56,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 56 discussion",
    "answers": {
      "A": "Use Fn::ImportValue intrinsic functions in the Resources section of the template to retrieve Virtual Private Cloud (VPC) and subnet values. Use CloudFormation StackSets for the development environments, using the Count input parameter to indicate the number of environments needed. use the UpdateStackSet command to update existing development environments.",
      "B": "Use nested stacks to define common infrastructure components. To access the exported values, use TemplateURL to reference the Networking team's template. To retrieve Virtual Private Cloud (VPC) and subnet values, use Fn::ImportValue intrinsic functions in the Parameters section of the master template. Use the CreateChangeSet and ExecuteChangeSet commands to update existing development environments.",
      "C": "Use nested stacks to define common infrastructure components. Use Fn::ImportValue intrinsic functions with the resources of the nested stack to retrieve Virtual Private Cloud (VPC) and subnet values. Use the CreateChangeSet and ExecuteChangeSet commands to update existing development environments.",
      "D": "Use Fn::ImportValue intrinsic functions in the Parameters section of the master template to retrieve Virtual Private Cloud (VPC) and subnet values. Define the development resources in the order they need to be created in the CloudFormation nested stacks. Use the CreateChangeSet and ExecuteChangeSet commands to update existing development environments."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/8121-exam-aws-devops-engineer-professional-topic-1-question-56/",
    "multiple_choice": false,
    "question_text": "A rapidly growing company wants to scale for Developer demand for AWS development environments. Development environments are created manually in the\nAWS Management Console. The Networking team uses AWS CloudFormation to manage the networking infrastructure, exporting stack output values for the\nAmazon VPC and all subnets. The development environments have common standards, such as Application Load Balancers, Amazon EC2 Auto Scaling groups, security groups, and Amazon DynamoDB tables.\nTo keep up with the demand, the DevOps Engineer wants to automate the creation of development environments. Because the infrastructure required to support the application is expected to grow, there must be a way to easily update the deployed infrastructure. CloudFormation will be used to create a template for the development environments.\nWhich approach will meet these requirements and quickly provide consistent AWS environments for Developers?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 57,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 57 discussion",
    "answers": {
      "A": "Change the Auto Scaling configuration to replace the instances when they fail the load balancer's health checks.",
      "B": "Change the target group health check HealthCheckIntervalSeconds parameter to reduce the interval between health checks.",
      "C": "Change the target group health checks from HTTP to TCP to check if the port where the application is listening is reachable.",
      "D": "Enable the available memory consumption metric within the Amazon CloudWatch dashboard for the entire Auto Scaling group. Create an alarm when the memory utilization is high. Associate an Amazon SNS topic to the alarm to receive notifications when the alarm goes off.",
      "E": "Use the Amazon CloudWatch agent to collect the memory utilization of the EC2 instances in the Auto Scaling group. Create an alarm when the memory utilization is high and associate an Amazon SNS topic to receive a notification."
    },
    "suggested_answer": "AE",
    "answer": "AE",
    "link": "https://www.examtopics.com/discussions/amazon/view/47704-exam-aws-devops-engineer-professional-topic-1-question-57/",
    "multiple_choice": true,
    "question_text": "A DevOps engineer notices that all Amazon EC2 instances running behind an Application Load Balancer in an Auto Scaling group are failing to respond to user requests. The EC2 instances are also failing target group HTTP health checks.\nUpon inspection, the engineer notices the application process was not running in any EC2 instances. There are a significant number of out of memory messages in the system logs. The engineer needs to improve the resilience of the application to cope with a potential application memory leak. Monitoring and notifications should be enabled to alert when there is an issue.\nWhich combination of actions will meet these requirements? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 58,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 58 discussion",
    "answers": {
      "A": "Create the CodeCommit repository using the AWS CLI. Clone the Git repository directly to CodeCommit using the AWS CLI. Validate that the files were migrated, and publish the CodeCommit repository.",
      "B": "Create the CodeCommit repository using the AWS Management Console. Clone both the Git and CodeCommit repositories to the local computer. Copy the files from the Git repository to the CodeCommit repository on the local computer. Commit the CodeCommit repository. Validate that the files were migrated, and share the CodeCommit repository.",
      "C": "Create the CodeCommit repository using the AWS Management Console. Use the console to clone the Git repository into the CodeCommit repository. Validate that the files were migrated, and publish the CodeCommit repository.",
      "D": "Create the CodeCommit repository using the AWS Management Console or the AWS CLI. Clone the Git repository with a mirror argument to the local computer and push the repository to CodeCommit. Validate that the files were migrated, and share the CodeCommit repository."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/46940-exam-aws-devops-engineer-professional-topic-1-question-58/",
    "multiple_choice": false,
    "question_text": "A company wants to migrate a legacy application to AWS and develop a deployment pipeline that uses AWS services only. A DevOps engineer is migrating all of the application code from a Git repository to AWS CodeCommit while preserving the history of the repository. The DevOps engineer has set all the permissions within CodeCommit, installed the Git client and the AWS CLI on a local computer, and is ready to migrate the repository.\nWhich actions will follow?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 59,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 59 discussion",
    "answers": {
      "A": "Create a manual approval action after the build action of the pipeline. Use Amazon SNS to inform the team of the stage being triggered. Next, add a test action using CodeBuild to perform the required tests. At the end of the pipeline, add a deploy action to deploy the application to the next stage.",
      "B": "Create a test action after the CodeBuild build of the pipeline. Configure the action to use CodeBuild to perform the required tests. If these tests are successful, mark the action as successful. Add a manual approval action that uses Amazon SNS to notify the team, and add a deploy action to deploy the application to the next stage.",
      "C": "Create a new pipeline that uses a source action that gets the code from the same repository as the first pipeline. Add a deploy action to deploy the code to a test environment. Use a test action using AWS Lambda to test the deployment. Add a manual approval action by using Amazon SNS to notify the team, and add a deploy action to deploy the application to the next stage.",
      "D": "Create a test action after the build action. Use a Jenkins server on Amazon EC2 to perform the required tests and mark the action as successful if the tests pass. Create a manual approval action that uses Amazon SQS to notify the team and add a deploy action to deploy the application to the next stage."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/47875-exam-aws-devops-engineer-professional-topic-1-question-59/",
    "multiple_choice": false,
    "question_text": "A company is using AWS to deploy an application. The development team must automate the deployments. The team has created an AWS CodePipeline pipeline to deploy the application to Amazon EC2 instances using AWS CodeDeploy after it has been built using AWS CodeBuild.\nThe team wants to add automated testing to the pipeline to confirm that the application is healthy before deploying the code to the EC2 instances. The team also requires a manual approval action before the application is deployed, even if the tests are successful. The testing and approval must be accomplished at the lowest costs, using the simplest management solution.\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 60,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 60 discussion",
    "answers": {
      "A": "Create separate staging and production accounts to segregate deployment targets. Use AWS Key Management Service (AWS KMS) to store environment- specific values. Use CodePipeline to automate deployments with AWS CodeDeploy.",
      "B": "Create separate staging and production accounts to segregate deployment targets. Use Lambda environment variables to store environment-specific values. Use CodePipeline to automate deployments with AWS CodeDeploy.",
      "C": "Define tagging conventions for staging and production environments to segregate deployment targets. Use AWS Key Management Service (AWS KMS) to store environment-specific values. Use CodePipeline to automate deployments with AWS CodeDeploy.",
      "D": "Define tagging conventions for staging and production environments to segregate deployment targets. Use Lambda environment variables to store environment-specific values. Use CodePipeline to automate deployments with AWS CodeDeploy."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/79621-exam-aws-devops-engineer-professional-topic-1-question-60/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer wants to deploy a serverless web application that is based on AWS Lambda. The deployment must meet the following requirements:\n✑ Provide staging and production environments.\n✑ Restrict developers from accessing the production environment.\n✑ Avoid hardcoding passwords in the Lambda functions.\n✑ Store source code in AWS CodeCommit.\n✑ Use AWS CodePipeline to automate the deployment.\nWhat is the MOST operationally efficient solution that meets these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 61,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 61 discussion",
    "answers": {
      "A": "Use AWS CodeBuild to test the application. Use bash scripts invoked by AWS CodeDeploy's appspec.yml file to restart services, and deregister and register instances with the ALB. Use the appspec.yml file to update file permissions without a custom script.",
      "B": "Use AWS CodePipeline to move the application from the AWS CodeCommit repository to AWS CodeDeploy. Use CodeDeploy's deployment group to test the application, unregister and re-register instances with the ALB, and restart services. Use the appspec.yml file to update the permissions without a custom script.",
      "C": "Use AWS CodePipeline to move the application source code from the AWS CodeCommit repository to AWS CodeDeploy. Use CodeDeploy to test the application. Use CodeDeploy's appspec.yml file to restart services and update permissions without a custom script. Use AWS CodeBuild to unregister and re- register instances with the ALB.",
      "D": "Use AWS CodePipeline to trigger AWS CodeBuild to test the application. Use bash scripts invoked by AWS CodeDeploy's appspec.yml file to restart services. Unregister and re-register the instances in the AWS CodeDeploy deployment group with the ALB. Update the appspec.yml file to update file permissions without a custom script."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/52608-exam-aws-devops-engineer-professional-topic-1-question-61/",
    "multiple_choice": false,
    "question_text": "A company wants to use AWS development tools to replace its current bash deployment scripts. The company currently deploys a LAMP application to a group of\nAmazon EC2 instances behind an Application Load Balancer (ALB). During the deployments, the company unit tests the committed application, stops and starts services, unregisters and re-registers instances with the load balancer, and updates file permissions. The company wants to maintain the same deployment functionality through the shift to using AWS services.\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 62,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 62 discussion",
    "answers": {
      "A": "Configure AWS Config to publish logs to an Amazon S3 bucket. Use Amazon Athena to query the logs and send a notification to the security team when the administrator role is assumed.",
      "B": "Configure Amazon GuardDuty to monitor when the administrator role is assumed and send a notification to the security team.",
      "C": "Create an Amazon EventBridge (Amazon CloudWatch Events) event rule using an AWS Management Console sign-in events event pattern that publishes a message to an Amazon SNS topic if the administrator role is assumed.",
      "D": "Create an Amazon EventBridge (Amazon CloudWatch Events) events rule using an AWS API call that uses an AWS CloudTrail event pattern to trigger an AWS Lambda function that publishes a message to an Amazon SNS topic if the administrator role is assumed."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/52620-exam-aws-devops-engineer-professional-topic-1-question-62/",
    "multiple_choice": false,
    "question_text": "A company gives its employees limited rights to AWS. DevOps engineers have the ability to assume an administrator role. For tracking purposes, the security team wants to receive a near-real-time notification when the administrator role is assumed.\nHow should this be accomplished?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 63,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 63 discussion",
    "answers": {
      "A": "Create a scheduled Amazon CloudWatch Events rule to execute an AWS Systems Manager automation document that checks if any EC2 instances are scheduled for retirement once a week. If the instance is scheduled for retirement, the automation document will hibernate the instance.",
      "B": "Enable EC2 Auto Recovery on all of the instances. Create an AWS Config rule to limit the recovery to occur during a maintenance window only.",
      "C": "Reboot all EC2 instances during an approved maintenance window that is outside of standard business hours. Set up Amazon CloudWatch alarms to send a notification in case any instance is failing EC2 instance status checks.",
      "D": "Set up an AWS Health Amazon CloudWatch Events rule to execute AWS Systems Manager automation documents that stop and start the EC2 instance when a retirement scheduled event occurs."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/28676-exam-aws-devops-engineer-professional-topic-1-question-63/",
    "multiple_choice": false,
    "question_text": "An ecommerce company uses a large number of Amazon EBS backed Amazon EC2 instances. To decrease manual work across all the instances, a DevOps\nEngineer is tasked with automating restart actions when EC2 instance retirement events are scheduled.\nHow can this be accomplished?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 64,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 64 discussion",
    "answers": {
      "A": "Configure the AWS Config ec2-volume-inuse-check managed rule with a configuration changes trigger type and an Amazon EC2 volume resource target. Create a new Amazon CloudWatch Events rule scheduled to execute an AWS Lambda function in 14 days to delete the specified EBS volume.",
      "B": "Use Amazon EC2 and Amazon Data Lifecycle Manager to configure a volume lifecycle policy. Set the interval period for unattached EBS volumes to 14 days and set the retention rule to delete. Set the policy target volumes as *.",
      "C": "Create an Amazon CloudWatch Events rule to execute an AWS Lambda function daily. The Lambda function should find unattached EBS volumes and tag them with the current date, and delete unattached volumes that have tags with dates that are more than 14 days old.",
      "D": "Use AWS Trusted Advisor to detect EBS volumes that have been detached for more than 14 days. Execute an AWS Lambda function that creates a snapshot and then deletes the EBS volume."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/47010-exam-aws-devops-engineer-professional-topic-1-question-64/",
    "multiple_choice": false,
    "question_text": "A company that runs many workloads on AWS has an Amazon EBS spend that has increased over time. The DevOps team notices there are many unattached\nEBS volumes. Although there are workloads where volumes are detached, volumes over 14 days old are stale and no longer needed. A DevOps engineer has been tasked with creating automation that deletes unattached EBS volumes that have been unattached for 14 days.\nWhich solution will accomplish this?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 65,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 65 discussion",
    "answers": {
      "A": "Create a trust relationship that allows users in the child accounts to assume the management account IAM role.",
      "B": "Create a trust relationship that allows users in the management account to assume the IAM roles of the child accounts.",
      "C": "Create an IAM role in each child account that has access to the AmazonEC2ReadOnlyAccess managed policy.",
      "D": "Create an IAM role in each child account to allow the sts:AssumeRole action against the management account IAM role's ARN.",
      "E": "Create an IAM role in the management account that allows the sts:AssumeRole action against the child account IAM role's ARN.",
      "F": "Create an IAM role in the management account that has access to the AmazonEC2ReadOnlyAccess managed policy."
    },
    "suggested_answer": "BCE",
    "answer": "BCE",
    "link": "https://www.examtopics.com/discussions/amazon/view/80257-exam-aws-devops-engineer-professional-topic-1-question-65/",
    "multiple_choice": true,
    "question_text": "A company has multiple child accounts that are part of an organization in AWS Organizations. The security team needs to review every Amazon EC2 security group and their inbound and outbound rules. The security team wants to programmatically retrieve this information from the child accounts using an AWS Lambda function in the management account of the organization.\nWhich combination of access changes will meet these requirements? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 66,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 66 discussion",
    "answers": {
      "A": "Define an Amazon CloudWatch Events target, an AWS Lambda function, and a lifecycle hook attached to the Auto Scaling group. Configure CloudWatch Events to invoke Amazon SNS to send a message to the Systems Administrator group for remediation.",
      "B": "Define an AWS Lambda function and a lifecycle hook attached to the Auto Scaling group. Configure the lifecycle hook to invoke the Lambda function, which removes the entry of the private IP from the monitoring system upon instance termination.",
      "C": "Define an Amazon CloudWatch Events target, an AWS Lambda function, and a lifecycle hook attached to the Auto Scaling group. Configure CloudWatch Events to invoke the Lambda function, which removes the entry of the private IP from the monitoring system upon instance termination.",
      "D": "Define an AWS Lambda function that will run a script when instance termination occurs in an Auto Scaling group. The script will remove the entry of the private IP from the monitoring system."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/28616-exam-aws-devops-engineer-professional-topic-1-question-66/",
    "multiple_choice": false,
    "question_text": "An application is deployed on Amazon EC2 instances running in an Auto Scaling group. During the bootstrapping process, the instances register their private IP addresses with a monitoring system. The monitoring system performs health checks frequently by sending ping requests to those IP addresses and sending alerts if an instance becomes non-responsive.\nThe existing deployment strategy replaces the current EC2 instances with new ones. A DevOps Engineer has noticed that the monitoring system is sending false alarms during a deployment, and is tasked with stopping these false alarms.\nWhich solution will meet these requirements without affecting the current deployment method?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 67,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 67 discussion",
    "answers": {
      "A": "Create an Amazon SQS queue and send the tasks that should be decoupled from the Elastic Beanstalk web server environment to the SQS queue. Create a fleet of EC2 instances under an Auto Scaling group. Use an AMI that contains the application to process the asynchronous tasks, configure the application to listen for messages within the SQS queue, and create periodic tasks by placing those into the cron in the operating system. Create an environment variable within the Elastic Beanstalk environment with a value pointing to the SQS queue endpoint.",
      "B": "Create a second Elastic Beanstalk worker tier environment and deploy the application to process the asynchronous tasks there. Send the tasks that should be decoupled from the original Elastic Beanstalk web server environment to the auto-generated Amazon SQS queue by the Elastic Beanstalk worker environment. Place a cron.yaml file within the root of the application source bundle for the worker environment for periodic tasks. Use environment links to link the web server environment with the worker environment.",
      "C": "Create a second Elastic Beanstalk web server tier environment and deploy the application to process the asynchronous tasks. Send the tasks that should be decoupled from the original Elastic Beanstalk web server to the auto-generated Amazon SQS queue by the second Elastic Beanstalk web server tier environment. Place a cron.yaml file within the root of the application source bundle for the second web server tier environment with the necessary periodic tasks. Use environment links to link both web server environments.",
      "D": "Create an Amazon SQS queue and send the tasks that should be decoupled from the Elastic Beanstalk web server environment to the SQS queue. Create a fleet of EC2 instances under an Auto Scaling group. Install and configure the application to listen for messages within the SQS queue from UserData and create periodic tasks by placing those into the cron in the operating system. Create an environment variable within the Elastic Beanstalk web server environment with a value pointing to the SQS queue endpoint."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/8471-exam-aws-devops-engineer-professional-topic-1-question-67/",
    "multiple_choice": false,
    "question_text": "An e-commerce company is running a web application in an AWS Elastic Beanstalk environment. In recent months, the average load of the Amazon EC2 instances has been increased to handle more traffic.\nThe company would like to improve the scalability and resilience of the environment. The Development team has been asked to decouple long-running tasks from the environment if the tasks can be executed asynchronously. Examples of these tasks include confirmation emails when users are registered to the platform, and processing images or videos. Also, some of the periodic tasks that are currently running within the web server should be offloaded.\nWhat is the MOST time-efficient and integrated way to achieve this?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 68,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 68 discussion",
    "answers": {
      "A": "Deploy the application on an Amazon EC2 instance and create an AMI of this instance. Use this AMI to create an automatic scaling launch configuration that is used in an Auto Scaling group. Use an Elastic Load Balancer to distribute traffic. When changes are made to the application, a new AMI will be created, which will initiate an EC2 instance refresh.",
      "B": "Use Amazon Lightsail to deploy the application. Store the application in a zipped format in an Amazon S3 bucket. Use this zipped version to deploy new versions of the application to Lightsail. Use Lightsail deployment options to manage the deployment.",
      "C": "Use AWS CodeArtifact to store the application code. Use AWS CodeDeploy to deploy the application to a fleet of Amazon EC2 instances. Use Elastic Load Balancing to distribute the traffic to the EC2 instances. When making changes to the application, upload a new version to CodeArtifact and create a new CodeDeploy deployment.",
      "D": "Use AWS Elastic Beanstalk to host the application. Store a zipped version of the application in Amazon S3, and use that location to deploy new versions of the application using Elastic Beanstalk to manage the deployment options."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/78834-exam-aws-devops-engineer-professional-topic-1-question-68/",
    "multiple_choice": false,
    "question_text": "A company has an on-premises that is written in Go. A DevOps engineer must move the application to AWS. The company's development team wants to enable blue/green deployments and perform A/B testing.\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 69,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 69 discussion",
    "answers": {
      "A": "The appspec.yml file contains an invalid script to execute in the AllowTraffic lifecycle hook.",
      "B": "The user who initiated the deployment does not have the necessary permissions to interact with the ALB.",
      "C": "The health checks specified for the ALB target group are misconfigured.",
      "D": "The CodeDeploy agent was not installed in the EC2 instances that are part of the ALB target group."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/28040-exam-aws-devops-engineer-professional-topic-1-question-69/",
    "multiple_choice": false,
    "question_text": "An application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). A DevOps Engineer is using AWS CodeDeploy to release a new version. The deployment fails during the AllowTraffic lifecycle event, but a cause for the failure is not indicated in the deployment logs.\nWhat would cause this?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 70,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 70 discussion",
    "answers": {
      "A": "Create an AWS CodeCommit repository for each project, use the main branch for production code, and create a testing branch for code deployed to testing. Use feature branches to develop new features and pull requests to merge code to testing and main branches.",
      "B": "Create another S3 bucket for each project for testing code, and use an AWS Lambda function to promote code changes between testing and production buckets. Enable versioning on all buckets to prevent code conflicts.",
      "C": "Create an AWS CodeCommit repository for each project, and use the main branch for production and test code with different deployment pipelines for each environment. Use feature branches to develop new features.",
      "D": "Enable versioning and branching on each S3 bucket, use the main branch for production code, and create a testing branch for code deployed to testing. Have developers use each branch for developing in each environment."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/10086-exam-aws-devops-engineer-professional-topic-1-question-70/",
    "multiple_choice": false,
    "question_text": "A company has a single developer writing code for an automated deployment pipeline. The developer is storing source code in an Amazon S3 bucket for each project. The company wants to add more developers to the team but is concerned about code conflicts and lost work. The company also wants to build a test environment to deploy newer versions of code for testing and allow developers to automatically deploy to both environments when code is changed in the repository.\nWhat is the MOST efficient way to meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 71,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 71 discussion",
    "answers": {
      "A": "Create an Amazon Simple Queue Service (Amazon SQS) queue. On the SNS topic, configure a redrive policy that sends undelivered messages to the SQS queue. Create an Amazon CloudWatch alarm for the new SQS queue to notify the development team when messages are delivered to the queue.",
      "B": "Create an Amazon Simple Queue Service (Amazon SQS) queue. On the HTTP endpoint subscription of the SNS topic, configure a redrive policy that sends undelivered messages to the SQS queue. Create an Amazon CloudWatch alarm for the new SQS queue to notify the development team when messages are delivered to the queue.",
      "C": "On the SNS topic, configure an HTTPS delivery policy that will retry delivery until the order message is delivered successfully. Configure the backoffFunction parameter in the policy to notify the development team when a message cannot be delivered within the set constraints.",
      "D": "On the HTTP endpoint subscription of the SNS topic, configure an HTTPS delivery policy that will retry delivery until the order message is delivered successfully. Configure the backoffFunction parameter in the policy to notify the development team when a message cannot be delivered within the set constraints."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/80403-exam-aws-devops-engineer-professional-topic-1-question-71/",
    "multiple_choice": false,
    "question_text": "A development team is building an ecommerce application and is using Amazon Simple Notification Service (Amazon SNS) to send order messages to multiple endpoints. One of the endpoints is an external HTTP endpoint that is not always available. The development team needs to receive a notification if an order message is not delivered to the HTTP endpoint.\nWhat should a DevOps engineer do to meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 72,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 72 discussion",
    "answers": {
      "A": "Encrypt the password using AWS KMS. Store the encrypted password in the buildspec.yml file as an environment variable under the variables mapping. Reference the environment variable to initiate scanning.",
      "B": "Import the password into an AWS CloudHSM key. Reference the CloudHSM key in the buildpec.yml file as an environment variable under the variables mapping. Reference the environment variable to initiate scanning.",
      "C": "Store the password in the AWS Systems Manager Parameter Store as a secure string. Add the Parameter Store key to the buildspec.yml file as an environment variable under the parameter-store mapping. Reference the environment variable to initiate scanning.",
      "D": "Use the AWS Encryption SDK to encrypt the password and embed in the buildspec.yml file as a variable under the secrets mapping. Attach a policy to CodeBuild to enable access to the required decryption key."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/28041-exam-aws-devops-engineer-professional-topic-1-question-72/",
    "multiple_choice": false,
    "question_text": "A company is deploying a container-based application using AWS CodeBuild. The Security team mandates that all containers are scanned for vulnerabilities prior to deployment using a password-protected endpoint. All sensitive information must be stored securely.\nWhich solution should be used to meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 73,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 73 discussion",
    "answers": {
      "A": "Use AWS OpsWorks to automatically configure each new EC2 instance as it is launched. Configure the EC2 instances by using an Auto Scaling group behind an Application Load Balancer across multiple Availability Zones. Implement Amazon DynamoDB Auto Scaling. Use Amazon Route 53 to point the application DNS record to the Application Load Balancer.",
      "B": "Deploy a fleet of EC2 instances, doubling the current capacity, and place them behind an Application Load Balancer. Increase the Amazon DynamoDB read and write capacity units. Add an alias record that contains the Application Load Balancer endpoint to the existing Amazon Route 53 DNS record that points to the application.",
      "C": "Configure Amazon CloudFront and have its origin point to Amazon S3 to host the web application. Implement Amazon DynamoDB Auto Scaling. Use Amazon Route 53 to point the application DNS record to the CloudFront DNS name.",
      "D": "Use AWS Elastic Beanstalk with a custom AMI including all web components. Deploy the platform by using an Auto Scaling group behind an Application Load Balancer across multiple Availability Zones. Implement Amazon DynamoDB Auto Scaling. Use Amazon Route 53 to point the application DNS record to the Elastic Beanstalk load balancer."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/2748-exam-aws-devops-engineer-professional-topic-1-question-73/",
    "multiple_choice": false,
    "question_text": "An Engineering team manages a Node.js e-commerce application. The current environment consists of the following components:\n✑ Amazon S3 buckets for storing content\n✑ Amazon EC2 for the front-end web servers\n✑ AWS Lambda for image processing\n✑ Amazon DynamoDB for storing session-related data\nThe team expects a significant increase in traffic to the site. The application should handle the additional load without interruption. The team ran initial tests by adding new servers to the EC2 front-end to handle the larger load, but the instances took up to 20 minutes to become fully configured. The team wants to reduce this configuration time.\nWhat changes will the Engineering team need to implement to make the solution the MOST resilient and highly available while meeting the expected increase in demand?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 74,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 74 discussion",
    "answers": {
      "A": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule with a source of aws.cloudtrail and the event name AuthorizeSecurityGroupIngress. Define an Amazon Simple Notification Service (Amazon SNS) topic as the target.",
      "B": "Enable Amazon GuardDuty and check the findings for security group in AWS Security Hub. Configure an Amazon EventBridge (Amazon CloudWatch Events) rule with a custom pattern that matches GuardDuty events with an output of NON_COMPLIANT. Define an Amazon Simple Notification Service (Amazon SNS) topic as the target.",
      "C": "Create an AWS Config rule by using the restricted-ssh managed rule to check whether security groups disallow unrestricted incoming SSH traffic. Configure automatic remediation to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic.",
      "D": "Enable Amazon Inspector. Include the Common Vulnerabilities and Exposures-1.1 rules package to check the security groups that are associated with the bastion hosts. Configure Amazon Inspector to publish a message to an Amazon Simple Notification Service (Amazon SNS) topic."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/79093-exam-aws-devops-engineer-professional-topic-1-question-74/",
    "multiple_choice": false,
    "question_text": "A company's application development team uses Linux-based Amazon EC2 instances as bastion hosts. Inbound SSH access to the bastion hosts is restricted to specific IP addresses, as defined in the associated security groups. The company's security team wants to receive a notification if the security group rules are modified to allow SSH access from any IP address.\nWhat should a DevOps engineer do to meet this requirement?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 75,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 75 discussion",
    "answers": {
      "A": "Write a script to launch an Amazon EC2 instance from the previous golden image. Apply the patch updates. Install the new version of the Chef agent, generate a new golden image, and then modify the AMI permissions to share only the new image with the department's accounts.",
      "B": "Use Amazon EC2 Image Builder to create an image pipeline that consists of the base Linux AMI and components to install the Chef agent. Use AWS Resource Access Manager to share EC2 Image Builder images with the department's accounts.",
      "C": "Use an AWS Systems Manager Automation runbook to update the Linux AMI by using the previous image. Provide the URL for the script that will update the Chef agent. Use AWS Organizations to replace the previous golden image in the department's accounts.",
      "D": "Use Amazon EC2 Image Builder to create an image pipeline that consists of the base Linux AMI and components to install the Chef agent. Create a parameter in AWS Systems Manager Parameter Store to store the new AMI ID that can be referenced by the department's accounts."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/79103-exam-aws-devops-engineer-professional-topic-1-question-75/",
    "multiple_choice": false,
    "question_text": "A company is using AWS Organizations to create separate AWS accounts for each of its departments. The company needs to automate the following tasks:\n✑ Update the Linux AMIs with new patches periodically and generate a golden image\n✑ Install a new version of Chef agents in the golden image, if available\n✑ Provide the newly generated AMIs to the department's accounts\nWhich solution meets these requirements with the LEAST management overhead?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 76,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 76 discussion",
    "answers": {
      "A": "Configure a target tracking scaling policy that is based on the Auto Scaling group's average CPU utilization, and set a target of 75%. Create a scheduled action for the Auto Scaling group to adjust the desired capacity to six instances just before business hours begin.",
      "B": "Configure the Auto Scaling group with two scheduled actions for Amazon EC2 Auto Scaling. Configure one action to start nine EC2 instances at the start of business hours. Configure the other action to stop nine instances at the end of business hours.",
      "C": "Change to an AWS Application Auto Scaling group. Configure a target tracking scaling policy that is based on the Auto Scaling group's average CPU utilization, and set a target of 75%. Create a scheduled action for the Auto Scaling group to adjust the minimum number of instances to three instances at the end of business hours and to reset the number to six instances before business hours begin.",
      "D": "Change to an AWS Application Auto Scaling group. Configure a target tracking scaling policy that is based on the Auto Scaling group's average CPU utilization, and set a target of 75%. Create a scheduled action to terminate nine instances each evening at the end of business hours."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/79160-exam-aws-devops-engineer-professional-topic-1-question-76/",
    "multiple_choice": false,
    "question_text": "A company has an application that runs on 12 Amazon EC2 instances. The instances run in an Amazon EC2 Auto Scaling group across three Availability Zones.\nOn a typical day each EC2 instance has 30% CPU utilization during business hours and 10% CPU utilization after business hours. The CPU utilization increases suddenly in the first few minutes of business hours each day. Other increases in CPU utilization are gradual. A DevOps engineer needs to optimize costs while maintaining or improving the application's reliability.\nWhich solution meets these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 77,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 77 discussion",
    "answers": {
      "A": "Create an application in the AWS Amplify console, and connect the CodeCommit repository. Create a feature branch deployment for each of the environments. Connect the Route 53 domain to the application. Activate the automatic creation of subdomains.",
      "B": "Create a single AWS CodePipeline pipeline that uses the CodeCommit repository as a source. Configure the pipeline so that it deploys to different environments based on the changed branch. Create an AWS Lambda function that creates a new subdomain based on the source branch name. Invoke the Lambda function in the deployment workflow.",
      "C": "Create an application in AWS Elastic Beanstalk that uses the CodeCommit repository as a source. Configure Elastic Beanstalk so that it creates a new application environment based on the changed branch. Connect the Route 53 domain to the application. Activate the automatic creation of subdomains.",
      "D": "Create multiple AWS CodePipeline pipelines that use the CodeCommit repository as a source. Configure each pipeline so that it deploys to a specific environment based on the configured branch. Configure an AWS CodeDeploy step in the pipeline to deploy the application components and to create the Route 53 public hosted zone."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/79465-exam-aws-devops-engineer-professional-topic-1-question-77/",
    "multiple_choice": false,
    "question_text": "A development team is building a full-stack serverless web application. The serverless application will consist of a backend REST API and a front end that is built with a single-page application (SPA) framework.\nThe team wants to use a Git-based workflow to develop and deploy the application. The team has created an AWS CodeCommit repository to store the application code. The team wants to use multiple development branches to test new features. In addition, the team wants to ensure that code changes on the development branches are deployed to the different development environments. Code changes to the main branches must be released automatically to production.\nThe development deployments must be available as a subdomain of the main application website, which is hosted in an Amazon Route 53 public hosted zone.\nWhat should a DevOps engineer do to meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 78,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 78 discussion",
    "answers": {
      "A": "Configure CodePipeline to write actions to Amazon CloudWatch Logs.",
      "B": "Configure CodePipeline to write actions to an Amazon S3 bucket at the end of each pipeline stage.",
      "C": "Create an AWS CloudTrail trail to deliver logs to Amazon S3.",
      "D": "Create a CodePipeline custom action to invoke an AWS Lambda function for approval. Create a policy that gives the security team access to manage CodePipeline custom actions.",
      "E": "Create a CodePipeline manual approval action before the deployment step. Create a policy that grants the security team access to approve manual approval stages."
    },
    "suggested_answer": "CE",
    "answer": "CE",
    "link": "https://www.examtopics.com/discussions/amazon/view/79173-exam-aws-devops-engineer-professional-topic-1-question-78/",
    "multiple_choice": true,
    "question_text": "A company is using AWS CodePipeline to deploy an application. According to a new guideline, a member of the company's security team must sign off on any application changes before the changes are deployed into production. The approval must be recorded and retained.\nWhich combination of actions will meet these requirements? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 79,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 79 discussion",
    "answers": {
      "A": "Launch a replica environment of everything except Amazon RDS in a different Availability Zone. Create an RDS read replica in the new Availability Zone, and configure the new stack to point to the local RDS DB instance. Add the new stack to the Route 53 record set by using a health check to configure a failover routing policy.",
      "B": "Launch a replica environment of everything except Amazon RDS in a different AWS Region. Create an RDS read replica in the new Region, and configure the new stack to point to the local RDS DB instance. Add the new stack to the Route 53 record set by using a health check to configure a latency routing policy.",
      "C": "Launch a replica environment of everything except Amazon RDS in a different AWS Region. In the event of an outage, copy and restore the latest RDS snapshot from the primary Region to the DR Region. Adjust the Route 53 record set to point to the ALB in the DR Region.",
      "D": "Launch a replica environment of everything except Amazon RDS in a different AWS Region. Create an RDS read replica in the new Region, and configure the new environment to point to the local RDS DB instance. Add the new stack to the Route 53 record set by using a health check to configure a failover routing policy. In the event of an outage, promote the read replica to primary."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/79177-exam-aws-devops-engineer-professional-topic-1-question-79/",
    "multiple_choice": false,
    "question_text": "A company manages a web application that runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The EC2 instances run in an Auto\nScaling group across multiple Availability Zones. The application uses an Amazon RDS for MySQL DB instance to store the data. The company has configured\nAmazon Route 53 with an alias record that points to the ALB.\nAnew company guideline requires a geographically isolated disaster recovery (DR) site with an RTO of 4 hours and an RPO of 15 minutes.\nWhich DR strategy will meet these requirements with the LEAST change to the application stack?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 80,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 80 discussion",
    "answers": {
      "A": "Create an AWS Lambda function to delete the 1AM access key. Configure AWS CloudTrail logs to stream to Amazon CloudWatch Logs. Create a CloudWatch Logs metric filter for the AWS_RISK_CREDENTIALS_EXPOSED event with two actions. First, run the Lambda function. Second, use Amazon Simple Notification Service (Amazon SNS) to send a notification to the security team.",
      "B": "Create an AWS Lambda function to delete the IAM access key. Create an AWS Config rule for changes to \"aws.trustedadvisor\" and the \"Exposed Access Keys\" status with two actions. First, run the Lambda function. Second, use Amazon Simple Notification Service (Amazon SNS) to send a notification to the security team.",
      "C": "Create an AWS Lambda function that deletes the IAM access key and then uses Amazon Simple Notification Service (Amazon SNS) to notify the security team. Create an AWS Personal Health Dashboard rule for the AWS_RISK_CREDENTIALS_EXPOSED event. Set the target of the Personal Health Dashboard rule to the ARN of the Lambda function.",
      "D": "Create an AWS Lambda function that deletes the IAM access key. Create an Amazon EventBridge (Amazon CloudWatch Events) rule with an \"aws.trustedadvisor\" event source and the \"Exposed Access Keys\" status. Set the EventBridge (CloudWatch Events) rule to target the Lambda function and an Amazon Simple Notification Service (Amazon SNS) topic that notifies the security team."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/79389-exam-aws-devops-engineer-professional-topic-1-question-80/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer wants to implement an automated response that will occur if AWS Trusted Advisor detects an IAM access key in a public source code repository. The automated response must delete the exposed access key and must notify the security team.\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 81,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 81 discussion",
    "answers": {
      "A": "Create an AWS Lambda function to delete the IAM access key. Configure AWS CloudTrail logs to stream to Amazon CloudWatch Logs. Create a CloudWatch Logs metric filter for the AWS_RISK_CREDENTIALS_EXPOSED event with two actions. First, run the Lambda function. Second, use Amazon Simple Notification Service (Amazon SNS) to send a notification to the security team.",
      "B": "Create an AWS Lambda function to delete the IAM access key. Create an AWS Config rule for changes to \"aws.trustedadvisor\" and the \"Exposed Access Keys\" status with two actions. First, run the Lambda function. Second, use Amazon Simple Notification Service (Amazon SNS) to send a notification to the security team.",
      "C": "Create an AWS Lambda function that deletes the IAM access key and then uses Amazon Simple Notification Service (Amazon SNS) to notify the security team. Create an AWS Personal Health Dashboard rule for the AWS_RISK_CREDENTIALS_EXPOSED event. Set the target of the Personal Health Dashboard rule to the ARN of the Lambda function.",
      "D": "Create an AWS Lambda function that deletes the IAM access key. Create an Amazon EventBridge (Amazon CloudWatch Events) rule with an \"aws.trustedadvisor\" event source and the \"Exposed Access Keys\" status. Set the EventBridge (CloudWatch Events) rule to target the Lambda function and an Amazon Simple Notification Service (Amazon SNS) topic that notifies the security team."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/79394-exam-aws-devops-engineer-professional-topic-1-question-81/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer wants to implement an automated response that will occur if AWS Trusted Advisor detects an IAM access key in a public source code repository. The automated response must delete the exposed access key and must notify the security team.\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 82,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 82 discussion",
    "answers": {
      "A": "Create an Amazon DynamoDB table in Europe. Use DynamoDB Accelerator (DAX) to configure replication between the DB cluster and the DynamoDB table. Configure the users' machines to point to the DynamoDB table in Europe.",
      "B": "Create cross-Region Aurora Replicas in North America, and activate synchronous replication. Configure the users' machines to point to the Aurora reader endpoint in North America.",
      "C": "Create an Aurora global database. Use the existing DB cluster as the primary cluster, and add a secondary cluster in an AWS Region in Europe. Configure the users' machines to point to the Aurora reader endpoint in Europe.",
      "D": "Use Amazon DynamoDB global tables in an AWS Region in Europe. Set up continuous replication between the DB cluster and the DynamoDB table by using AWS Database Migration Service (AWS DMS). Configure the users' machines to point to the DynamoDB table in Europe."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/80264-exam-aws-devops-engineer-professional-topic-1-question-82/",
    "multiple_choice": false,
    "question_text": "A company hosts an application in North America. The application uses an Amazon Aurora PostgreSQL DB cluster. A team of analysts in Europe generates real- time reports by using the DB cluster. The analysts must have access to the most up-to-date data. A DevOps engineer discovers that the generation of reports is much slower for users in Europe than for users in North America.\nWhat should the DevOps engineer do to resolve this issue?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 83,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 83 discussion",
    "answers": {
      "A": "Enable SSE encryption on the S3 buckets and RDS database. Enable OS-based encryption of data on EBS volumes. Configure Amazon Inspector agents on EC2 instances to report on insecure encryption ciphers. Set up AWS Config rules to periodically check for non-encrypted S3 objects.",
      "B": "Configure the application to encrypt each file prior to storing on Amazon S3. Enable OS-based encryption of data on EBS volumes. Encrypt data on write to RDS. Run cron jobs on each instance to check for unencrypted data and notify via Amazon SNS. Use S3 Events to call an AWS Lambda function and verify if the file is encrypted.",
      "C": "Enable Secure Sockets Layer (SSL) on the load balancer, ensure that AWS Lambda is using SSL to communicate to the RDS database, and enable S3encryption. Configure the application to force SSL for incoming connections and configure RDS to only grant access if the session is encrypted. Configure Amazon Inspector agents on EC2 instances to report on insecure encryption ciphers.",
      "D": "Enable SSE encryption on the S3 buckets, EBS volumes, and the RDS database. Store RDS credentials in EC2 Parameter Store. Enable a policy on the S3 bucket to deny unencrypted puts. Set up AWS Config rules to periodically check for non-encrypted S3 objects and EBS volumes, and to ensure that RDS storage is encrypted."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/89500-exam-aws-devops-engineer-professional-topic-1-question-83/",
    "multiple_choice": false,
    "question_text": "A consulting company was hired to assess security vulnerabilities within a client company's application and propose a plan to remediate all identified issues. The architecture is identified as follows: Amazon S3 storage for content, an Auto Scaling group of Amazon EC2 instances behind an Elastic Load Balancer with attached Amazon EBS storage, and an Amazon RDS MySQL database. There are also several AWS Lambda functions that communicate directly with the RDS database using connection string statements in the code.\n\nThe consultants identified the top security threat as follows: the application is not meeting its requirement to have encryption at rest.\n\nWhat solution will address this issue with the LEAST operational overhead and will provide monitoring for potential future violations?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 84,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 84 discussion",
    "answers": {
      "A": "Deploy the application on AWS Elastic Beanstalk. Deploy an Amazon RDS for MySQL DB instance as part of the Elastic Beanstalk configuration.",
      "B": "Deploy the application on AWS Elastic Beanstalk. Deploy a separate Amazon RDS for MySQL DB instance outside of Elastic Beanstalk.",
      "C": "Configure a notification email address that alerts the application team in the AWS Elastic Beanstalk configuration.",
      "D": "Configure an Amazon EventBridge (Amazon CloudWatch Events) rule to monitor AWS Health events. Use an Amazon Simple Notification Service (Amazon SNS) topic as a target to alert the application team.",
      "E": "Use the immutable deployment method to deploy new application versions.",
      "F": "Use the rolling deployment method to deploy new application versions."
    },
    "suggested_answer": "BCE",
    "answer": "BCE",
    "link": "https://www.examtopics.com/discussions/amazon/view/88913-exam-aws-devops-engineer-professional-topic-1-question-84/",
    "multiple_choice": true,
    "question_text": "A DevOps engineer is planning to deploy a Ruby-based application to production. The application needs to interact with an Amazon RDS for MySQL database and should have automatic scaling and high availability. The stored data in the database is critical and should persist regardless of the state of the application stack.\n\nThe DevOps engineer needs to set up an automated deployment strategy for the application with automatic rollbacks. The solution also must alert the application team when a deployment fails.\n\nWhich combination of steps will meet these requirements? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 85,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 85 discussion",
    "answers": {
      "A": "Create an AWS Elastic Beanstalk environment and configure it to use Auto Scaling and an Elastic Load Balancer. Use rolling deployments with a batch size of 50%.",
      "B": "Create an AWS OpsWorks stack. Configure the application layer to use rolling deployments as a deployment strategy. Add an Elastic Load Balancing layer. Enable auto healing on the application layer.",
      "C": "Use AWS CodeDeploy with Auto Scaling and an Elastic Load Balancer. Use the CodeDeployDefault.HalfAtAtime deployment strategy. Enable an Elastic Load Balancing health check to report the status of the application, and set the Auto Scaling health check to ELB.",
      "D": "Use AWS CodeDeploy with Auto Scaling and an Elastic Load Balancer. Use a blue/green deployment strategy. Enable an Elastic Load Balancing health check to report the status of the application, and set the Auto Scaling health check to ELB."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/88915-exam-aws-devops-engineer-professional-topic-1-question-85/",
    "multiple_choice": false,
    "question_text": "An ecommerce company is looking for ways to deploy an application on AWS that satisfies the following requirements:\n\n• Has a simple and automated application deployment process.\n• Has minimal deployment costs while ensuring that at least half of the instances are available to receive end-user requests.\n• If the application fails, an automated healing mechanism will replace the affected instances.\n\nWhich deployment strategy will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 86,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 86 discussion",
    "answers": {
      "A": "Failed deploy and build actions across all the pipelines",
      "B": "All rejected or failed approval actions across all the pipelines",
      "C": "All the events across all pipelines",
      "D": "Approval actions across all pipelines"
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/88841-exam-aws-devops-engineer-professional-topic-1-question-86/",
    "multiple_choice": false,
    "question_text": "A company is implementing AWS CodePipeline to automate its testing process. The company wants to be notified when the execution state fails and used the following custom event pattern in Amazon CloudWatch:\n\n//IMG//\n\n\nWhich type of events will match this event pattern?",
    "answer_images": [],
    "question_images": [
      "https://img.examtopics.com/aws-devops-engineer-professional/image1.png"
    ]
  },
  {
    "topic_number": 1,
    "question_number": 87,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 87 discussion",
    "answers": {
      "A": "Create two Amazon Lightsail virtual private servers for Node.js; one for test and one for production. Build the Node.js application using existing processes and upload it to the new Lightsail test server using the AWS CLI. Test the application, and if it passes all tests, upload it to the production server. During the trial, monitor the production server usage, and if needed, increase performance by upgrading the instance type.",
      "B": "Develop an AWS CloudFormation template to create an Application Load Balancer and two Amazon EC2 instances with Amazon EBS (SSD) volumes in an Auto Scaling group with rolling updates enabled. Use AWS CodeBuild to build and test the Node.js application and store it in an Amazon S3 bucket. Use user-data scripts to install the application and the MySQL database on each EC2 instance. Update the stack to deploy new application versions.",
      "C": "Configure AWS Elastic Beanstalk to automatically build the application using AWS CodeBuild and to deploy it to a test environment that is configured to support auto scaling. Create a second Elastic Beanstalk environment for production. Use Amazon RDS to store data. When new versions of the applications have passed all tests, use Elastic Beanstalk 'swap cname' to promote the test environment to production.",
      "D": "Modify the application to use Amazon DynamoDB instead of a local MySQL database. Use AWS OpsWorks to create a stack for the application with a DynamoDB layer, an Application Load Balancer layer, and an Amazon EC2 instance layer. Use a Chef recipe to build the application and a Chef recipe to deploy the application to the EC2 instance layer. Use custom health checks to run unit tests on each instance with rollback on failure."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/88842-exam-aws-devops-engineer-professional-topic-1-question-87/",
    "multiple_choice": false,
    "question_text": "A company has developed a Node.js web application which provides REST services to store and retrieve time series data. The web application is built by the development team on company laptops, tested locally, and manually deployed to a single on-premises server, which accesses a local MySQL database. The company is starting a trial in two weeks, during which the application will undergo frequent updates based on customer feedback. The following requirements must be met:\n\n• The team must be able to reliably build, test, and deploy new updates on a daily basis, without downtime or degraded performance.\n• The application must be able to scale to meet an unpredictable number of concurrent users during the trial.\n\nWhich action will allow the team to quickly meet these objectives?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 88,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 88 discussion",
    "answers": {
      "A": "Use the Amazon CloudWatch agent to send logs from the EC2 instances to Amazon CloudWatch Logs. Configure AWS CloudTrail to deliver the API logs to Amazon S3. Use CloudWatch to query both sets of logs.",
      "B": "Use the Amazon CloudWatch agent to send logs from the EC2 instances to Amazon CloudWatch Logs. Configure AWS CloudTrail to deliver the API logs to CloudWatch Logs. Use CloudWatch Logs Insights to query both sets of logs.",
      "C": "Use the Amazon CloudWatch agent to send logs from the EC2 instances to Amazon Kinesis. Configure AWS CloudTrail to deliver the API logs to Kinesis. Use Kinesis to load the data into Amazon Redshift. Use Amazon Redshift to query both sets of logs.",
      "D": "Use the Amazon CloudWatch agent to send logs from the EC2 instances to Amazon S3. Use AWS CloudTrail to deliver the API logs to Amazon S3. Use Amazon Athena to query both sets of logs in Amazon S3."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/88843-exam-aws-devops-engineer-professional-topic-1-question-88/",
    "multiple_choice": false,
    "question_text": "A company is deploying a new application that uses Amazon EC2 instances. The company needs a solution to query application logs and AWS account API activity.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 89,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 89 discussion",
    "answers": {
      "A": "Create a pipeline in AWS CodePipeline with CodeCommit as a source provider. Create parallel pipeline stages to build and test the application. Pass the build artifact to AWS CodeDeploy.",
      "B": "Create a pipeline in AWS CodePipeline with CodeCommit as a source provider. Create separate pipeline stages to build and then test the application. Pass the build artifact to AWS CodeDeploy.",
      "C": "Create and use an AWS CodeDeploy application and deployment group to deploy code updates to the EC2 fleet. Select the Application Load Balancer for the deployment group.",
      "D": "Create individual Lambda functions to run all build, test, and deploy actions using AWS CodeDeploy instead of AWS Systems Manager.",
      "E": "Modify the Lambda function to build a single application package to be shared by all instances. Use AWS CodeDeploy instead of AWS Systems Manager to update the code on the EC2 fleet."
    },
    "suggested_answer": "BC",
    "answer": "BC",
    "link": "https://www.examtopics.com/discussions/amazon/view/88844-exam-aws-devops-engineer-professional-topic-1-question-89/",
    "multiple_choice": true,
    "question_text": "A DevOps engineer is tasked with creating a more stable deployment solution for a web application in AWS. Previous deployments have resulted in user-facing bugs, premature user traffic, and inconsistencies between web servers running behind an Application Load Balancer. The current strategy uses AWS CodeCommit to store the code for the application. When developers push to the main branch of the repository, CodeCommit triggers an AWS Lambda deploy function, which invokes an AWS Systems Manager run command to build and deploy the new code to all Amazon EC2 instances.\n\nWhich combination of actions should be taken to implement a more stable deployment solution? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 90,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 90 discussion",
    "answers": {
      "A": "Use AWS CodePipeline with Amazon ECS, Amazon EC2, and Lambda as deploy providers.",
      "B": "Use AWS CodePipeline with AWS CodeDeploy as the deploy provider.",
      "C": "Use AWS CodePipeline with AWS Elastic Beanstalk as the deploy provider.",
      "D": "Use AWS CodeDeploy with GitHub integration to deploy the application."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/88845-exam-aws-devops-engineer-professional-topic-1-question-90/",
    "multiple_choice": false,
    "question_text": "A company wants to set up a continuous delivery pipeline. The company stores application code in a private GitHub repository. The company needs to deploy the application components to Amazon Elastic Container Service (Amazon ECS), Amazon EC2, and AWS Lambda. The pipeline must support manual approval actions.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 91,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 91 discussion",
    "answers": {
      "A": "Use the AWS Service Catalog deploy action in AWS CodeDeploy to push new versions of products into the AWS Service Catalog with verification steps in the CodeDeploy AppSpec.",
      "B": "Use the AWS Service Catalog deploy action in AWS CodeBuild to verify and push new versions of products into the AWService Catalog.",
      "C": "Use an AWS Lambda action in CodePipeline to run a Lambda function to verify and push new versions of products into the AWS Service Catalog.",
      "D": "Use an AWS Lambda action in AWS CodeBuild to run a Lambda function to verify and push new versions of products into the AWS Service Catalog."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/89506-exam-aws-devops-engineer-professional-topic-1-question-91/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer is deploying an AWS Service Catalog portfolio using AWS CodePipeline. The pipeline should create products and templates based on a manifest file in either JSON or YAML, and should enforce security requirements on all AWS Service Catalog products managed through the pipeline.\n\nWhich solution will meet the requirements in an automated fashion?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 92,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 92 discussion",
    "answers": {
      "A": "Automate patching and upgrading using AWS Systems Manager on EC2 instances and encrypt Amazon EBS volumes by default.",
      "B": "Deploy Jenkins to an Amazon ECS cluster and copy build artifacts to an Amazon S3 bucket with default encryption enabled.",
      "C": "Leverage AWS CodePipeline with a build action and encrypt the artifacts using AWS Secrets Manager.",
      "D": "Use AWS CodeBuild with artifact encryption to replace the Jenkins instance running on Amazon EC2."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/88848-exam-aws-devops-engineer-professional-topic-1-question-92/",
    "multiple_choice": false,
    "question_text": "A company has containerized all of its in-house quality control applications. The company is running Jenkins on Amazon EC2, which requires patching and upgrading. The compliance officer has requested a DevOps engineer begin encrypting build artifacts since they contain company intellectual property.\n\nWhat should the DevOps engineer do to accomplish this in the MOST maintainable manner?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 93,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 93 discussion",
    "answers": {
      "A": "Create a CloudWatch Logs subscription to an AWS Step Functions application. Configure the function to add a tag to the EC2 instance that produced the login event and mark the instance to be decommissioned. Then create a CloudWatch Events rule to trigger a second AWS Lambda function once a day that will terminate all instances with this tag.",
      "B": "Create a CloudWatch alarm that will trigger on the login event. Send the notification to an Amazon SNS topic that the operations team is subscribed to, and have them terminate the EC2 instance within 24 hours.",
      "C": "Create a CloudWatch alarm that will trigger on the login event. Configure the alarm to send to an Amazon SQS queue. Use a group of worker instances to process messages from the queue, which then schedules the Amazon CloudWatch Events rule to trigger.",
      "D": "Create a CloudWatch Logs subscription in an AWS Lambda function. Configure the function to add a tag to the EC2 instance that produced the login event and mark the instance to be decommissioned. Create a CloudWatch Events rule to trigger a daily Lambda function that terminates all instances with this tag."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/88849-exam-aws-devops-engineer-professional-topic-1-question-93/",
    "multiple_choice": false,
    "question_text": "A production account has a requirement that any Amazon EC2 instance that has been logged into manually must be terminated within 24 hours. All applications in the production account are using Auto Scaling groups with Amazon CloudWatch Logs agent configured.\n\nHow can this process be automated?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 94,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 94 discussion",
    "answers": {
      "A": "Update the CloudFormation template to include the UpdatePolicy attribute with the AutoScalingRollingUpdate policy.",
      "B": "Update the CloudFormation template to include the UpdatePolicy attribute with the AutoScalingReplacingUpdate policy.",
      "C": "Use an Auto Scaling lifecycle hook to verify that the previous instance is operational before allowing the DevOps engineer's selected instance to terminate.",
      "D": "Use an Auto Scaling lifecycle hook to confirm there are at least four running instances before allowing the DevOps engineer's selected instance to terminate."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/88850-exam-aws-devops-engineer-professional-topic-1-question-94/",
    "multiple_choice": false,
    "question_text": "A company's application is running on Amazon EC2 instances in an Auto Scaling group. A DevOps engineer needs to ensure there are at least four application servers running at all times. Whenever an update has to be made to the application, the engineer creates a new AMI with the updated configuration and updates the AWS CloudFormation template with the new AMI ID. After the stack update finishes, the engineer manually terminates the old instances one by one, verifying that the new instance is operational before proceeding. The engineer needs to automate this process.\n\nWhich action will allow for the LEAST number of manual steps moving forward?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 95,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 95 discussion",
    "answers": {
      "A": "Commit to the development branch and trigger AWS CodePipeline from the development branch. Make an individual stage in CodePipeline for security review, unit tests, functional tests, and manual approval. Use Amazon CloudWatch metrics to detect changes in pipeline stages and Amazon SES for emailing devops-admin@xyz.com.",
      "B": "Commit to mainline and trigger AWS CodePipeline from mainline. Make an individual stage in CodePipeline for security review, unit tests, functional tests, and manual approval. Use AWS CloudTrail logs to detect changes in pipeline stages and Amazon SNS for emailing devops-admin@xyz.com.",
      "C": "Commit to the development branch and trigger AWS CodePipeline from the development branch. Make an individual stage in CodePipeline for security review, unit tests, functional tests, and manual approval. Use Amazon CloudWatch Events to detect changes in pipeline stages and Amazon SNS for emailing devops-admin@xyz.com.",
      "D": "Commit to mainline and trigger AWS CodePipeline from mainline. Make an individual stage in CodePipeline for security review, unit tests, functional tests, and manual approval. Use Amazon CloudWatch Events to detect changes in pipeline stages and Amazon SES for emailing devops-admin@xyz.com."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/89782-exam-aws-devops-engineer-professional-topic-1-question-95/",
    "multiple_choice": false,
    "question_text": "A company using AWS CodeCommit for source control wants to automate its continuous integration and continuous delivery pipeline on AWS in its development environment. The company has three requirements:\n\n1. There must be a legal and a security review of any code change to make sure sensitive information is not leaked through the source code.\n2. Every change must go through unit testing.\n3. Every change must go through a suite of functional testing to ensure functionality.\n\nIn addition, the company has the following requirements for automation:\n\n1. Code changes should automatically trigger the CI/CD pipeline.\n2. Any failure in the pipeline should notify devops-admin@xyz.com.\n3. There must be an approval to stage the assets to Amazon S3 after tests have been performed.\n\nWhat should a DevOps Engineer do to meet all of these requirements while following Cl/CD best practices?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 96,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 96 discussion",
    "answers": {
      "A": "Add the bucket name to the AllowedBuckets section of the CodeBuild project settings. Update the build spec to use the AWS CLI to download the database population script.",
      "B": "Modify the S3 bucket settings to enable HTTPS basic authentication and specify a token. Update the build spec to use cURL to pass the token and download the database population script.",
      "C": "Remove unauthenticated access from the S3 bucket with a bucket policy. Modify the service role for the CodeBuild project to include Amazon S3 access. Use the AWS CLI to download the database population script.",
      "D": "Remove unauthenticated access from the S3 bucket with a bucket policy. Use the AWS CLI to download the database population script using an IAM access key and a secret access key."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/88854-exam-aws-devops-engineer-professional-topic-1-question-96/",
    "multiple_choice": false,
    "question_text": "A security review has identified that an AWS CodeBuild project is downloading a database population script from an Amazon S3 bucket using an unauthenticated request. The security team does not allow unauthenticated requests to S3 buckets for this project.\n\nHow can this issue be corrected in the MOST secure manner?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 97,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 97 discussion",
    "answers": {
      "A": "Create an Amazon CloudWatch Event rule that runs periodically and targets an AWS Lambda function. Within the Lambda function, evaluate the current state of the AWS environment and compare deployed resource values to resource limits on the account. Notify the senior manager if the account is approaching a service limit.",
      "B": "Deploy an AWS Lambda function that refreshes AWS Trusted Advisor checks, and configure an Amazon CloudWatch Events rule to run the Lambda function periodically. Create another CloudWatch Events rule with an event pattern matching Trusted Advisor events and a target Lambda function. In the target Lambda function, notify the senior manager.",
      "C": "Deploy an AWS Lambda function that refreshes AWS Personal Health Dashboard checks, and configure an Amazon CloudWatch Events rule to run the Lambda function periodically. Create another CloudWatch Events rule with an event pattern matching Personal Health Dashboard events and a target Lambda function. In the target Lambda function, notify the senior manager.",
      "D": "Add an AWS Config custom rule that runs periodically, checks the AWS service limit status, and streams notifications to an Amazon SNS topic. Deploy an AWS Lambda function that notifies the senior manager, and subscribe the Lambda function to the SNS topic."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/88923-exam-aws-devops-engineer-professional-topic-1-question-97/",
    "multiple_choice": false,
    "question_text": "A company has multiple development groups working in a single shared AWS account. The senior manager of the groups wants to be alerted via a third-party API call when the creation of resources approaches the service limits for the account.\n\nWhich solution will accomplish this with the LEAST amount of development effort?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 98,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 98 discussion",
    "answers": {
      "A": "Create a single AWS CodePipeline pipeline that deploys the application in parallel using unique AWS CodeDeploy applications and deployment groups created for each ALB-Auto Scaling group pair.",
      "B": "Create a single AWS CodePipeline pipeline that deploys the application using a single AWS CodeDeploy application and single deployment group.",
      "C": "Create a single AWS CodePipeline pipeline that deploys the application in parallel using a single AWS CodeDeploy application and unique deployment group for each ALB-Auto Scaling group pair.",
      "D": "Create an AWS CodePipeline pipeline for each ALB-Auto Scaling group pair that deploys the application using an AWS CodeDeploy application and deployment group created for the same ALB-Auto Scaling group pair."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/89512-exam-aws-devops-engineer-professional-topic-1-question-98/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer is architecting a continuous development strategy for a company's software as a service (SaaS) web application running on AWS. For application and security reasons, users subscribing to this application are distributed across multiple Application Load Balancers (ALBs), each of which has a dedicated Auto Scaling group and fleet of Amazon EC2 instances. The application does not require a build stage, and when it is committed to AWS CodeCommit, the application must trigger a simultaneous deployment to all ALBs, Auto Scaling groups, and EC2 fleets.\n\nWhich architecture will meet these requirements with the LEAST amount of configuration?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 99,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 99 discussion",
    "answers": {
      "A": "Update the Amazon EC2 Auto Scaling service-linked role to allow access to both S3 buckets.",
      "B": "Set up S3 Cross-Region Replication from the S3 bucket in the primary Region to the S3 bucket in the backup Region.",
      "C": "Update the instance user data to reference the S3 bucket in the primary Region.",
      "D": "Increase the timeout for the target group health check.",
      "E": "Update the EC2 instance profile to allow s3:list* actions.",
      "F": "Update the EC2 instance profile to allow read access to both S3 buckets."
    },
    "suggested_answer": "BDF",
    "answer": "BDF",
    "link": "https://www.examtopics.com/discussions/amazon/view/89786-exam-aws-devops-engineer-professional-topic-1-question-99/",
    "multiple_choice": true,
    "question_text": "A company's primary AWS Region contains the following infrastructure:\n\n• An Amazon S3 bucket that contains an object package that is used in instance user data to configure an application.\n• Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer (ALB) with an instance profile that grants s3:Get* access on the S3 bucket.\n\nThe company has the following infrastructure in a backup Region:\n\n• An S3 bucket with the same configuration as the S3 bucket in the primary AWS Region, but without any objects.\n• EC2 instances in an Auto Scaling group behind an ALB that run with the same configuration as in the primary AWS Region.\n\nTo simulate a disaster recovery scenario, the company turns off all access to Amazon S3 and sets the Auto Scaling group's minimum, maximum, and desired instances to 0 in the primary Region. When the instances in the backup Region scale out, they do not pass Amazon Route 53 health checks.\n\nWhich combination of steps should the company take to resolve this issue? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 100,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 100 discussion",
    "answers": {
      "A": "Create a stack export from the database CloudFormation template and import those references into the web application CloudFormation template.",
      "B": "Create a CloudFormation nested stack to make cross-stack resource references and parameters available in both stacks.",
      "C": "Create a CloudFormation stack set to make cross-stack resource references and parameters available in both stacks.",
      "D": "Create input parameters in the web application CloudFormation template and pass resource names and IDs from the database stack."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/89418-exam-aws-devops-engineer-professional-topic-1-question-100/",
    "multiple_choice": false,
    "question_text": "A company is developing a web application's infrastructure using AWS CloudFormation. The database engineering team maintains the database resources in a CloudFormation template, and the software development team maintains the web application resources in a separate CloudFormation template. As the scope of the application grows, the software development team needs to use resources maintained by the database engineering team. However, both teams have their own review and lifecycle management processes that they want to keep. Both teams also require resource-level change-set reviews. The software development team would like to deploy changes to this template using their CI/CD pipeline.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 101,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 101 discussion",
    "answers": {
      "A": "Enable AWS CloudTrail and configure automatic remediation using AWS Lambda.",
      "B": "Enable AWS Config rules and configure automatic remediation using AWS Systems Manager documents.",
      "C": "Enable AWS Trusted Advisor and configure automatic remediation using Amazon CloudWatch Events.",
      "D": "Enable AWS Systems Manager and configure automatic remediation using Systems Manager documents."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/89516-exam-aws-devops-engineer-professional-topic-1-question-101/",
    "multiple_choice": false,
    "question_text": "A company uses Amazon S3 to store proprietary information. The development team creates buckets for new projects on a daily basis. The security team wants to ensure that all existing and future buckets have encryption, logging, and versioning enabled. Additionally, no buckets should ever be publicly read or write accessible.\n\nWhat should a DevOps engineer do to meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 102,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 102 discussion",
    "answers": {
      "A": "Create an Amazon CloudWatch alarm for the StatusCheckFailed metric. Use the recover action to stop and start the instance. Use an S3 event notification to push the metadata to the instance when the instance is back up and running.",
      "B": "Configure AWS OpsWorks, and use the auto healing feature to stop and start the instance. Use a lifecycle event in OpsWorks to pull the metadata from Amazon S3 and update it on the instance.",
      "C": "Use EC2 Auto Recovery to automatically stop and start the instance in case of a failure. Use an S3 event notification to push the metadata to the instance when the instance is back up and running.",
      "D": "Use AWS CloudFormation to create an EC2 instance that includes the UserData property for the EC2 resource. Add a command in UserData to retrieve the application metadata from Amazon S3."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/89072-exam-aws-devops-engineer-professional-topic-1-question-102/",
    "multiple_choice": false,
    "question_text": "A company runs an application on one Amazon EC2 instance. Application metadata is stored in Amazon S3 and must be retrieved if the instance is restarted. The instance must restart or relaunch automatically if the instance becomes unresponsive.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 103,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 103 discussion",
    "answers": {
      "A": "Create a secure string with AWS KMS and choose a KMS encryption key. Reference the ARN of the secure string, and give AWS CloudFormation permission to the KMS key for decryption.",
      "B": "Create secrets using the AWS Secrets Manager AWS::SecretsManager::Secret resource type. Reference the secret resource return attributes in resources that need a password, such as an Amazon RDS database.",
      "C": "Store sensitive static data as secure strings in the AWS Systems Manager Parameter Store. Use dynamic references in the resources that need access to the data.",
      "D": "Store sensitive static data in the AWS Systems Manager Parameter Store as strings. Reference the stored value using types of Systems Manager parameters.",
      "E": "Use AWS KMS to encrypt the CloudFormation template.",
      "F": "Use the CloudFormation NoEcho parameter property to mask the parameter value."
    },
    "suggested_answer": "BCF",
    "answer": "BCF",
    "link": "https://www.examtopics.com/discussions/amazon/view/89074-exam-aws-devops-engineer-professional-topic-1-question-103/",
    "multiple_choice": true,
    "question_text": "A devops team uses AWS CloudFormation to build their infrastructure. The security team is concerned about sensitive parameters, such as passwords, being exposed.\n\nWhich combination of steps will enhance the security of AWS CloudFormation? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 104,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 104 discussion",
    "answers": {
      "A": "Use AWS CloudFormation to create an AWS Step Functions state machine and Auto Scaling lifecycle hooks to move to one instance at a time into a wait state. Use AWS Systems Manager automation to deploy the update to each instance and move it back into the Auto Scaling group using the heartbeat timeout.",
      "B": "Use AWS CodeDeploy with Amazon EC2 Auto Scaling. Configure an alarm tied to the CPU utilization metric. Use the CodeDeployDefault.OneAtAtime configuration as a deployment strategy. Configure automatic rollbacks within the deployment group to roll back the deployment if the alarm thresholds are breached.",
      "C": "Use AWS Elastic Beanstalk for load balancing and AWS Auto Scaling. Configure an alarm tied to the CPU utilization metric. Configure rolling deployments with a fixed batch size of one instance. Enable enhanced health to monitor the status of the deployment and roll back based on the alarm previously created.",
      "D": "Use AWS Systems Manager to perform a blue/green deployment with Amazon EC2 Auto Scaling. Configure an alarm tied to the CPU utilization metric. Deploy updates one at a time. Configure automatic rollbacks within the Auto Scaling group to roll back the deployment if the alarm thresholds are breached."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/89748-exam-aws-devops-engineer-professional-topic-1-question-104/",
    "multiple_choice": false,
    "question_text": "A company has a mission-critical application on AWS that uses automatic scaling. The company wants the deployment lifecycle to meet the following parameters:\n\n• The application must be deployed one instance at a time to ensure the remaining fleet continues to serve traffic.\n• The application is CPU intensive and must be closely monitored.\n• The deployment must automatically roll back if the CPU utilization of the deployment instance exceeds 85%.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 105,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 105 discussion",
    "answers": {
      "A": "Attach an Organizations SCP with an explicit deny for all iam:CreateAccessKey actions with a condition that excludes StringEquals for aws:username with a value of the exception list.",
      "B": "Attach an Organizations SCP with an explicit deny for all iam:CreateUser actions with a condition that includes StringNotLike for aws:username with a value of the exception list.",
      "C": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule with a pattern that matches the iam:CreateAccessKey action with an AWS Lambda function target. The function will check the user name and account against an exception list. If the user is not on the exception list, the function will delete the user.",
      "D": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule with a pattern that matches the iam:CreateUser action with an AWS Lambda function target. The function will check the user name and account against an exception list. If the user is not on the exception list, the function will delete the user."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/89519-exam-aws-devops-engineer-professional-topic-1-question-105/",
    "multiple_choice": false,
    "question_text": "A company's legacy application uses IAM user credentials to access resources in the company's AWS Organizations organization. A DevOps engineer must ensure that new IAM users cannot be created unless the employee who creates the IAM user is on an exception list.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 106,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 106 discussion",
    "answers": {
      "A": "Implement Amazon DocumentDB (with MongoDB compatibility) in each of the six Regions.",
      "B": "Implement Amazon DynamoDB global tables in each of the six Regions.",
      "C": "Implement Amazon ElastiCache for Redis replication groups in each of the six Regions.",
      "D": "Implement Amazon Elasticsearch Service (Amazon ES) in each of the six Regions."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/89840-exam-aws-devops-engineer-professional-topic-1-question-106/",
    "multiple_choice": false,
    "question_text": "A company must collect user consent to a privacy agreement. The company deploys an application in six AWS Regions: two Regions in North America, two Regions in Europe, and two Regions in Asia. The application has a user base of 20 million to 30 million users.\n\nThe company needs to read and write data that is related to each user's response. The company also must ensure that the responses are available in all six Regions.\n\nWhich solution will meet these requirements with the LOWEST latency of reads and writes?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 107,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 107 discussion",
    "answers": {
      "A": "Enable smart sessions on the load balancer and modify the application to check for an existing session.",
      "B": "Enable session sharing on the load balancer and modify the application to read from the session store.",
      "C": "Store user session information in an Amazon S3 bucket and modify the application to read session information from the bucket.",
      "D": "Modify the application to store user session information in an Amazon ElastiCache cluster."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/89520-exam-aws-devops-engineer-professional-topic-1-question-107/",
    "multiple_choice": false,
    "question_text": "A company is testing a web application that runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones. The company uses a blue/green deployment process with immutable instances when deploying new software.\n\nDuring testing, users are being automatically logged out of the application at random times. Testers also report that, when a new version of the application is deployed, all users are logged out. The development team needs a solution to ensure users remain logged in across scaling events and application deployments.\n\nWhat is the MOST efficient way to ensure users remain logged in?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 108,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 108 discussion",
    "answers": {
      "A": "Increase the instance grace period from 60 seconds to 180 seconds, and the consecutive health check requirement from 2 to 3.",
      "B": "Increase the instance grace period from 60 seconds to 120 seconds, and change the response code requirement from 200 to 204.",
      "C": "Modify the deployment script to create a /health-check.php file when the deployment begins, then modify the health check path to point to that file.",
      "D": "Modify the deployment script to create a /health-check.php file when all tasks are complete, then modify the health check path to point to that file."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/89749-exam-aws-devops-engineer-professional-topic-1-question-108/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer is troubleshooting deployments to a new application that runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones. Instances sometimes come online before they are ready, which is leading to increased error rates among users. The current health check configuration gives instances a 60-second grace period and considers instances healthy after two 200 response codes from /index.php, a page that may respond intermittently during the deployment process. The development team wants instances to come online as soon as possible.\n\nWhich strategy would address this issue?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 109,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 109 discussion",
    "answers": {
      "A": "Create an AWS CodeCommit repository to store the source code. Create an AWS CodePipeline pipeline that has a source of the CodeCommit repository.",
      "B": "Create an S3 bucket to act as the source for developers to upload their source code. Create an AWS CodePipeline pipeline that has the S3 bucket as the source.",
      "C": "In the CodePipeline pipeline, configure an AWS CodeBuild phase that compiles the source code and produces build artifacts.",
      "D": "In the CodePipeline pipeline, configure an AWS CodeDeploy phase that compiles the source code, produces build artifacts, and then deploys the website.",
      "E": "In the CodePipeline pipeline, configure an AWS AppConfig deploy action that deploys the build artifacts to the S3 website bucket.",
      "F": "In the CodePipeline pipeline, configure an S3 deploy action that deploys the build artifacts to the S3 website bucket."
    },
    "suggested_answer": "ACF",
    "answer": "ACF",
    "link": "https://www.examtopics.com/discussions/amazon/view/88859-exam-aws-devops-engineer-professional-topic-1-question-109/",
    "multiple_choice": true,
    "question_text": "A company has a single-page application that was developed in Angular. A DevOps engineer needs to automate deployments of the application to a website that the company hosts on Amazon S3. The solution must provide version control of the source code and must give developers the ability to perform peer review.\n\nWhich combination of steps will meet these requirements? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 110,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 110 discussion",
    "answers": {
      "A": "Create a health check endpoint in the web application that tests connectivity to the data and middleware tiers. Use this endpoint as the health check URL for the load balancer.",
      "B": "Create an approval step for the quality assurance team to validate connectivity. Reject changes in the pipeline if there is an issue with connecting to the dependent tiers.",
      "C": "Use an Amazon RDS active connection count and an Amazon CloudWatch ELB metric to alarm on a significant change to the number of open connections.",
      "D": "Use Amazon Route 53 health checks to detect issues with the web service and roll back the Cl/CD pipeline if there is an error."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/89522-exam-aws-devops-engineer-professional-topic-1-question-110/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer is creating a CI/CD pipeline for an Amazon ECS service. The ECS container instances run behind an Application Load Balancer as the web tier of a three-tier application. An acceptance criterion for a successful deployment is the verification that the web tier can communicate with the database and middleware tiers of the application upon deployment.\n\nHow can this be accomplished in an automated fashion?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 111,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 111 discussion",
    "answers": {
      "A": "Change the deployment configuration to CodeDeployDefault.AllAtOnce to speed up the deployment process by deploying to all of the instances at the same time.",
      "B": "Create a CodeDeploy trigger for the deployment failure event and make the deployment fail as soon as a single health check failure is detected.",
      "C": "Reduce the HealthCheckIntervalSeconds and UnhealthyThresholdCount values within the target group health checks to decrease the amount of time it takes for the application to be considered unhealthy.",
      "D": "Use the appspec.yml file to run a script on the AllowTraffic hook to perform lighter health checks on the application instead of making CodeDeploy wait for the target group health checks to pass.",
      "E": "Use the appspec.yml file to run a script on the BeforeAllowTraffic hook to perform health checks on the application and fail the deployment if the health checks performed by the script are not successful."
    },
    "suggested_answer": "BE",
    "answer": "BE",
    "link": "https://www.examtopics.com/discussions/amazon/view/89752-exam-aws-devops-engineer-professional-topic-1-question-111/",
    "multiple_choice": true,
    "question_text": "A development team manages website deployments using AWS CodeDeploy blue/green deployments. The application is running on Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group.\n\nWhen deploying a new revision, the team notices the deployment eventually fails, but it takes a long time to fail. After further inspection, the team discovers the AllowTraffic lifecycle event ran for an hour and eventually failed without providing any other information. The team wants to ensure failure notices are delivered more quickly while maintaining application availability even upon failure.\n\nWhich combination of actions should be taken to meet these requirements? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 112,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 112 discussion",
    "answers": {
      "A": "Allow developers to check the code into a code repository. Using Amazon CloudWatch Events, on every pull into master, trigger an AWS Lambda function to build the artifact and store it in Amazon S3.",
      "B": "Create a custom script to clear the cache. Specify the script in the Beforelnstall lifecycle hook in the AppSpec file.",
      "C": "Create user data for each Amazon EC2 instance that contains the clear cache script. Once deployed, test the application. If it is not successful, deploy it again.",
      "D": "Set up AWS CodePipeline to deploy the application. Allow developers to check the code into a code repository as a source for the pipeline.",
      "E": "Use AWS CodeBuild to build the artifact and place it in Amazon S3. Use AWS CodeDeploy to deploy the artifact to Amazon EC2 instances.",
      "F": "Use AWS Systems Manager to fetch the artifact from Amazon S3 and deploy it to all the instances."
    },
    "suggested_answer": "BDE",
    "answer": "BDE",
    "link": "https://www.examtopics.com/discussions/amazon/view/88918-exam-aws-devops-engineer-professional-topic-1-question-112/",
    "multiple_choice": true,
    "question_text": "A development team manually builds an artifact locally and then places it in an Amazon S3 bucket. The application has a local cache that must be cleared when a deployment occurs. The team executes a command to do this, downloads the artifact from Amazon S3, and unzips the artifact to complete the deployment.\n\nA DevOps team wants to migrate to a CI/CD process and build in checks to stop and roll back the deployment when a failure occurs. This requires the team to track the progression of the deployment.\n\nWhich combination of actions will accomplish this? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 113,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 113 discussion",
    "answers": {
      "A": "Configure Amazon Route 53 to point to API Gateway APIs in North America and Europe using health checks. Configure the APIs to forward requests to a Lambda function in that Region. Configure the Lambda functions to retrieve and update the data in a DynamoDB table in the same Region as the Lambda function.",
      "B": "Configure Amazon Route 53 to point to API Gateway APIs in North America and Europe using latency-based routing and health checks. Configure the APIs to forward requests to a Lambda function in that Region. Configure the Lambda functions to retrieve and update the data in a DynamoDB global table.",
      "C": "Configure Amazon Route 53 to point to API Gateway in North America, create a disaster recovery API in Europe, and configure both APIs to forward requests to the Lambda functions in that Region. Retrieve the data from a DynamoDB global table. Deploy a Lambda function to check the North America API health every 5 minutes. In the event of a failure, update Route 53 to point to the disaster recovery API.",
      "D": "Configure Amazon Route 53 to point to API Gateway API in North America using latency-based routing. Configure the API to forward requests to the Lambda function in the Region nearest to the user. Configure the Lambda function to retrieve and updathe data in a DynamoDB table."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/88920-exam-aws-devops-engineer-professional-topic-1-question-113/",
    "multiple_choice": false,
    "question_text": "A company is implementing a well-architected design for its globally accessible API stack. The design needs to ensure both high reliability and fast response times for users located in North America and Europe.\n\nThe API stack contains the following three tiers:\n\n• Amazon API Gateway\n• AWS Lambda\n• Amazon DynamoDB\n\nWhich solution will meet the requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 114,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 114 discussion",
    "answers": {
      "A": "Configure a CloudWatch Logs subscription filter to use AWS Glue to transfer all logs to an S3 bucket.",
      "B": "Configure a CloudWatch Logs subscription filter to use Amazon Kinesis Data Firehose to stream all logs to an S3 bucket.",
      "C": "Configure a CloudWatch Logs subscription filter to stream all logs to an S3 bucket.",
      "D": "Configure the S3 bucket lifecycle policy to transition logs to S3 Glacier after 90 days and to expire logs after 3,650 days.",
      "E": "Configure the S3 bucket lifecycle policy to transition logs to Reduced Redundancy after 90 days and to expire logs after 3,650 days."
    },
    "suggested_answer": "BD",
    "answer": "BD",
    "link": "https://www.examtopics.com/discussions/amazon/view/88919-exam-aws-devops-engineer-professional-topic-1-question-114/",
    "multiple_choice": true,
    "question_text": "A company manages an application that stores logs in Amazon CloudWatch Logs. The company wants to archive the logs in Amazon S3. Logs are rarely accessed after 90 days and must be retained for 10 years.\n\nWhich combination of steps should a DevOps engineer take to meet these requirements? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 115,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 115 discussion",
    "answers": {
      "A": "Use an AWS Serverless Application Model (AWS SAM) template to define the serverless application. Use AWS CodeDeploy to deploy the Lambda functions with the Canary10Percent15Minutes Deployment Preference Type. Use Amazon CloudWatch alarms to monitor the health of the functions.",
      "B": "Use AWS CloudFormation to publish a new stack update, and include Amazon CloudWatch alarms on all resources. Set up an AWS CodePipeline approval action for a developer to verify and approve the AWS CloudFormation change set.",
      "C": "Use AWS CloudFormation to publish a new version on every stack update, and include Amazon CloudWatch alarms on all resources. Use the RoutingConfig property of the AWS:: Lambda:: Alias resource to update the traffic routing during the stack update.",
      "D": "Use AWS CodeBuild to add sample event payloads for testing to the Lambda functions. Publish a new version of the functions, and include Amazon CloudWatch alarms. Update the production alias to point to the new version. Configure rollbacks to occur when an alarm is in the ALARM state."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/88922-exam-aws-devops-engineer-professional-topic-1-question-115/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer is building a continuous deployment pipeline for a serverless application that uses AWS Lambda functions. The company wants to reduce the customer impact of an unsuccessful deployment. The company also wants to monitor for issues.\n\nWhich deploy stage configuration will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 116,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 116 discussion",
    "answers": {
      "A": "Retrieve an access key from an AWS Systems Manager SecureString parameter to access AWS services. Retrieve the database credentials from a Systems Manager SecureString parameter.",
      "B": "Launch the EC2 instances with an EC2 IAM role to access AWS services. Retrieve the database credentials from AWS Secrets Manager.",
      "C": "Retrieve an access key from an AWS Systems Manager plaintext parameter to access AWS services. Retrieve the database credentials from a Systems Manager SecureString parameter.",
      "D": "Launch the EC2 instances with an EC2 IAM role to access AWS services. Store the database passwords in an encrypted config file with the application artifacts."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/88921-exam-aws-devops-engineer-professional-topic-1-question-116/",
    "multiple_choice": false,
    "question_text": "A large enterprise is deploying a web application on AWS. The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones. The application stores data in an Amazon RDS Oracle DB instance and Amazon DynamoDB. There are separate environments for development, testing, and production.\n\nWhat is the MOST secure and flexible way to obtain password credentials during deployment?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 117,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 117 discussion",
    "answers": {
      "A": "Use AWS OpsWorks Stacks to layer the server nodes of that cluster. Create a Chief recipe that populates the content of the /etc/cluster/nodes.config file and restarts the service by using the current members of the layers. Assign that recipe to the Configure lifecycle event.",
      "B": "Put the file nodes.config in version control. Create an AWS CodeDeploy deployment configuration and deployment group based on an Amazon EC2 tag value for the cluster nodes. When adding a new node to the cluster, update the file with all tagged instances, and make a commit in version control. Deploy the new file and restart the services.",
      "C": "Create an Amazon S3 bucket and upload a version of the /etc/cluster/nodes.config file. Create a crontab script that will poll for that S3 file and download it frequently. Use a process manager, such as Monit or systemd, to restart the cluster services when it detects that the new file was modified. When adding a node to the cluster, edit the file’s most recent members. Upload the new file to the S3 bucket.",
      "D": "Create a user data script that lists all members of the current security group of the cluster and automatically updates the /etc/cluster/nodes.config file whenever a new instance is added to the cluster."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/93046-exam-aws-devops-engineer-professional-topic-1-question-117/",
    "multiple_choice": false,
    "question_text": "A company wants to use a grid system for proprietary enterprise in-memory data store on top of AWS. The system can run in multiple server nodes in any Linux-based distribution. The system must be able to reconfigure the entire cluster every time a node is added or removed. When adding or removing nodes, an /etc/cluster/nodes.config file must be updated listing the IP addresses of the current node member of that cluster.\n\nThe company wants to automate the task of adding new nodes to a cluster.\n\nWhat can a DevOps engineer do to meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 118,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 118 discussion",
    "answers": {
      "A": "Use Amazon EFS for checkpoint data. To complete the job, use an EC2 Auto Scaling group and an On-Demand pricing model to provision EC2 instances temporarily.",
      "B": "Use GlusterFS on EC2 instances for checkpoint data. To run the batch job, configure EC2 instances manually. When the job completes, shut down the instances manually.",
      "C": "Use Amazon EFS for checkpoint data. Use EC2 Fleet to launch EC2 Spot Instances, and utilize user data to configure the EC2 Linux instance on startup.",
      "D": "Use Amazon EFS for checkpoint data. Use EC2 Fleet to launch EC2 Spot Instances. Create a custom AMI for the cluster and use the latest AMI when creating instances."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/92576-exam-aws-devops-engineer-professional-topic-1-question-118/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer is researching the least expensive way to implement an image batch processing cluster on AWS. The application cannot run in Docker containers and must run on Amazon EC2. The batch job stores checkpoint data on an NFS and can tolerate interruptions. Configuring the cluster software from a generic EC2 Linux image takes 30 minutes.\n\nWhat is the MOST cost-effective solution?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 119,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 119 discussion",
    "answers": {
      "A": "Install the Amazon CloudWatch agent on all instances to push the application logs to CloudWatch Logs. Use metric filters to count the error messages every minute, and initiate a CloudWatch alarm if the count exceeds 10 errors.",
      "B": "Install the Amazon CloudWatch agent on all instances to push the access logs to CloudWatch Logs. Create an Amazon EventBridge (Amazon CloudWatch Events) rule to count the error messages every minute, and initiate a CloudWatch alarm if the count exceeds 10 errors.",
      "C": "Install the Amazon CloudWatch agent on all instances to push the application logs to CloudWatch Logs. Use a metric filter to generate a custom CloudWatch metric that records the number of failures and initiates a CloudWatch alarm if the custom metric reaches 10 errors in a 1-minute period.",
      "D": "Deploy a custom script on all instances to check application logs regularly in a cron job. Count the number of error messages every minute, and push a data point to a custom CloudWatch metric. Initiate a CloudWatch alarm if the custom metric reaches 10 errors in a 1-minute period."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/92516-exam-aws-devops-engineer-professional-topic-1-question-119/",
    "multiple_choice": false,
    "question_text": "A mobile application running on eight Amazon EC2 instances is relying on a third-party API endpoint. The third-party service has a high failure rate because of limited capacity which is expected to be resolved in a few weeks.\n\nIn the meantime, the mobile application developers have added a retry mechanism and are logging failed API requests. A DevOps engineer must automate the monitoring of application logs and count the specific error messages, if there are more than 10 errors within a 1-minute window the system must issue an alert.\n\nHow can the requirements be met with MINIMAL management overhead?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 120,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 120 discussion",
    "answers": {
      "A": "Create a new AWS account in AWS Organizations. Create a VPC in this account and use AWS Resource Access Manager to share the private subnets of this VPC with the organization. Instruct the service teams to launch a new Network Load Balancer (NLB) and EC2 instances that use the shared private subnets. Use the NLB DNS names for communication between microservices.",
      "B": "Create a Network Load Balancer (NLB) in each of the microservice VPCs. Use AWS PrivateLink to create VPC endpoints in each AWS account for the NLBs. Create subscriptions to each VPC endpoint in each of the other AWS accounts. Use the VPC endpoint DNS names for communication between microservices.",
      "C": "Create a Network Load Balancer (NLB) in each of the microservice VPCs. Create VPC peering connections between each of the microservice VPCs. Update the route tables for each VPC to use the peering links. Use the NLB DNS names for communication between microservices.",
      "D": "Create a new AWS account in AWS Organizations. Create a transit gateway in this account. and use AWS Resource Access Manager to share the transit gateway with the organization. In each of the microservice VPCs, create a transit gateway attachment to the shared transit gateway. Update the route tables of each VPC to use the transit gateway. Create a Network Load Balancer (NLB) in each of the microservice VPCs. Use the NLB DNS names for communication between microservices."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/92577-exam-aws-devops-engineer-professional-topic-1-question-120/",
    "multiple_choice": false,
    "question_text": "A company has 20 service teams. Each service team is responsible for its own microservice. Each service team uses a separate AWS account for its microservice and a VPC with the 192.168.0.0/22 CIDR block. The company manages the AWS accounts with AWS Organizations.\n\nEach service team hosts its microservice on multiple Amazon EC2 instances behind an Application Load Balancer. The microservices communicate with each other across the public Internet. The company's security team has issued a new guideline that all communication between microservices must use HTTPS over private network connections and cannot traverse the public Internet.\n\nA DevOps engineer must implement a solution that fulfills these obligations and minimizes the number of changes for each service team.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 121,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 121 discussion",
    "answers": {
      "A": "Tag the Amazon EC2 instances depending on the deployment group. Then place a script into the application revision that calls the metadata service and the EC2 API to identify which deployment group the instance is part of. Use this information to configure the log level settings. Reference the script as part of the Afterinstall lifecycle hook in the appspec.yml file.",
      "B": "Create a script that uses the CodeDeploy environment variable DEPLOYMENT_GROUP_NAME to identify which deployment group the instance is part of. Use this information to configure the log level settings. Reference this script as part of the Beforelnstall lifecycle hook in the appspec.yml file.",
      "C": "Create a CodeDeploy custom environment variable for each environment Then place a script into the application revision that checks this environment variable to identify which deployment group the instance is part of. Use this information to configure the log level settings. Reference this script as part of the ValidateService lifecycle hook in the appspec.yml file.",
      "D": "Create a script that uses the CodeDeploy environment variable DEPLOYMENT_GROUP_ID to identify which deployment group the instance is part of to configure the log level settings. Reference this script as part of the Install lifecycle hook in the appspec.yml file."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/92580-exam-aws-devops-engineer-professional-topic-1-question-121/",
    "multiple_choice": false,
    "question_text": "A company is adopting AWS CodeDeploy to automate its application deployments for a Java-Apache Tomcat application with an Apache webserver The development team started with a proof of concept, created a deployment group for a developer environment, and performed functional tests within the application After completion, the team will create additional deployment groups for staging and production.\n\nThe current log level is configured within the Apache settings, but the team wants to change this configuration dynamically when the deployment occurs, so that they can set different log level configurations depending on the deployment group without having a different application revision for each group.\n\nHow can these requirements be met with the LEAST management overhead and without requiring different script versions for each deployment group?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 122,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 122 discussion",
    "answers": {
      "A": "Create a web application to write records to Amazon S3. Use S3 Event Notifications to publish to an Amazon Simple Notification Service (Amazon SNS) topic. Use an EC2 instance to poll Amazon SNS and start processing. Save intermediate results to Amazon S3 to pass on to the next step.",
      "B": "Perform the processing steps by using logic in the application. Convert the application code to run in a container. Use AWS Fargate to manage the container instances. Configure the container to invoke itself to pass the state from one step to the next.",
      "C": "Create a web application to pass records to an Amazon Kinesis data stream. Decouple the processing by using the Kinesis data stream and AWS Lambda functions.",
      "D": "Create a web application to pass records to AWS Step Functions. Decouple the processing into Step Functions tasks and AWS Lambda functions."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/92581-exam-aws-devops-engineer-professional-topic-1-question-122/",
    "multiple_choice": false,
    "question_text": "A company is running a custom-built application that processes records. All the components run on Amazon EC2 instances that run in an Auto Scaling group. Each record's processing is a multistep sequential action that is compute-intensive. Each step is always completed in 5 minutes or less.\n\nA limitation of the current system is that if any steps fail, the application has to reprocess the record from the beginning. The company wants to update the architecture so that the application must reprocess only the failed steps.\n\nWhat is the MOST operationally efficient solution that meets these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 123,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 123 discussion",
    "answers": {
      "A": "Launch an RDS DB instance in the failover Region. Use AWS Database Migration Service (AWS DMS) to configure ongoing replication from the source database.",
      "B": "Upon failover, update the AWS CloudFormation stack in the failover Region to increase the desired number of instances in the Auto Scaling group. When the stack update is complete, change the DNS records to point to the failover Region's ALB.",
      "C": "Upon failover, launch the AWS CloudFormation template in the failover Region with the DB snapshot ID as an input parameter. When the stack creation is complete, change the DNS records to point to the failover Region's ALB.",
      "D": "Use AWS Backup to take a snapshot of the DB instance every hour and to copy the snapshot to the failover Region.",
      "E": "Create an Amazon EventBridge (Amazon CloudWatch Events) event that invokes an AWS Lambda function to copy the RDS automated snapshot to the failover Region."
    },
    "suggested_answer": "CD",
    "answer": "CD",
    "link": "https://www.examtopics.com/discussions/amazon/view/92419-exam-aws-devops-engineer-professional-topic-1-question-123/",
    "multiple_choice": true,
    "question_text": "A DevOps engineer is designing a multi-Region disaster recovery strategy for an application. The application requires an RPO of 1 hour and requires an RTO of 4 hours. The application is deployed with an AWS CloudFormation template that creates an Application Load Balancer (ALB), Amazon EC2 instances in an Auto Scaling group and an Amazon RDS Multi-AZ DB instance with 20 GB of allocated storage. The AMI of the application instance does not contain data and has been copied to the destination Region.\n\nWhich combination of actions will meet the recovery objectives at the LOWEST cost? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 124,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 124 discussion",
    "answers": {
      "A": "Use CloudFormation to deploy an additional staging environment and configure the Route 53 DNS with weighted records. During cutover change the Route 53 A record weights to achieve an even traffic distribution between the two environments. Validate the traffic in the new environment and immediately terminate the old environment if tests are successful.",
      "B": "Use a single AWS Elastic Beanstalk environment to deploy the staging and production environments. Update the environment by uploading the ZIP file with the new application code. Swap the Elastic Beanstalk environment CNAME. Validate the traffic in the new environment and immediately terminate the old environment if tests are successful.",
      "C": "Use a single AWS Elastic Beanstalk environment and an AWS OpsWorks environment to deploy the staging and production environments. Update the environment by uploading the ZIP file with the new application code into the Elastic Beanstalk environment deployed with the OpsWorks stack. Validate the traffic in the new environment and immediately terminate the old environment if tests are successful.",
      "D": "Use AWS CloudFormation to deploy an additional staging environment, and configure the Route 53 DNS with weighted records. During cutover, increase the weight distribution to have more traffic directed to the new staging environment as workloads are successfully validated. Keep the old production environment in place until the new staging environment handles all traffic."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/93073-exam-aws-devops-engineer-professional-topic-1-question-124/",
    "multiple_choice": false,
    "question_text": "A company runs a three-tier web application in its production environment, which is built on a single AWS CloudFormation template made up of Amazon EC2 instances behind an ELB Application Load Balancer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones. Data is stored in an Amazon RDS Multi-AZ DB instance with read replicas. Amazon Route 53 manages the application's public DNS record.\n\nA DevOps engineer must create a workflow to mitigate a failed software deployment by rolling back changes in the production environment when a software cutover occurs for new application software.\n\nWhat steps should the engineer perform to meet these requirements with the LEAST amount of downtime?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 125,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 125 discussion",
    "answers": {
      "A": "Add a DeletionPolicy attribute to the S3 bucket resource, with the value Delete forcing the bucket to be removed when the stack is deleted.",
      "B": "Add a custom resource with an AWS Lambda function with the DependsOn attribute specifying the S3 bucket, and an IAM role. Write the Lambda function to delete all objects from the bucket when RequestType is Delete.",
      "C": "Identify the resource that was not deleted. From the S3 console, empty the S3 bucket and then delete it.",
      "D": "Replace the EC2 and S3 bucket resources with a single AWS OpsWorks Stacks resource. Define a custom recipe for the stack to create and delete the EC2 instance and the S3 bucket."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/92414-exam-aws-devops-engineer-professional-topic-1-question-125/",
    "multiple_choice": false,
    "question_text": "An IT team has built an AWS CloudFormation template so others in the company can quickly and reliably deploy and terminate an application. The template creates an Amazon EC2 instance with a user data script to install the application and an Amazon S3 bucket that the application uses to serve static webpages while it is running.\n\nAll resources should be removed when the CloudFormation stack is deleted. However, the team observes that CloudFormation reports an error during stack deletion, and the S3 bucket created by the stack is not deleted.\n\nHow can the team resolve the error in the MOST efficient manner to ensure that all resources are deleted without errors?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 126,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 126 discussion",
    "answers": {
      "A": "Build a pipeline in AWS CodePipeline to download and save the latest operating system Open Virtualization Format (OVF) image to an Amazon S3 bucket. Customize the image by using the guestfish utility. Use the virtual machine (VM) import command to convert the OVF to an AMI. Store the AMI identification output as an AWS Systems Manager Parameter Store parameter.",
      "B": "Create an AWS Systems Manager Automation runbook with values instructing how the image should be created. Build a pipeline in AWS CodePipeline to execute the runbook to create the AMI. Store the AMI identification output as a Systems Manager Parameter Store parameter.",
      "C": "Build a pipeline in AWS CodePipeline to take a snapshot of an Amazon EC2 instance running the latest version of the application. Start a new EC2 instance from the snapshot and update the running instance by using an AWS Lambda function. Take a snapshot of the updated instance and convert it to an AMI. Store the AMI identification output in an Amazon DynamoDB table.",
      "D": "Launch an Amazon EC2 instance and install Packer. Configure a Packer build with values defining how the image should be created. Build a Jenkins pipeline to invoke the Packer build to create an AMI. Store the AMI identification output in an Amazon DynamoDB table."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/92417-exam-aws-devops-engineer-professional-topic-1-question-126/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer must create a Linux AMI in an automated fashion. The newly created AMI identification must be stored in a location where other build pipelines can access the new identification programmatically.\n\nWhat is the MOST cost-effective way to do this?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 127,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 127 discussion",
    "answers": {
      "A": "In the CloudFormation template, add an AWS Config rule. Place the configuration file content in the rule's InputParameters property, and set the Scope property to the EC2 Auto Scaling group. Add an AWS Systems Manager Resource Data Sync resource to the template to poll for updates to the configuration.",
      "B": "In the CloudFormation template, add an EC2 launch template resource. Place the configuration file content in the launch template. Configure the cfn-init script to run when the instance is launched, and configure the cfn-hup script to poll for updates to the configuration.",
      "C": "In the CloudFormation template add an EC2 launch template resource. Place the configuration file content in the launch template. Add an AWS Systems Manager Resource Data Sync resource to the template to poll for updates to the configuration.",
      "D": "In the CloudFormation template, add CloudFormation init metadata. Place the configuration file content in the metadata. Configure the cfn-init script to run when the instance is launched, and configure the cfn-hup script to poll for updates to the configuration."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/92995-exam-aws-devops-engineer-professional-topic-1-question-127/",
    "multiple_choice": false,
    "question_text": "An application running on a set of Amazon EC2 instances in an Auto Scaling group requires a configuration file to operate. The instances are created and maintained with AWS CloudFormation. A DevOps engineer wants the instances to have the latest configuration file when launched, and wants changes to the configuration file to be reflected on all the instances with a minimal delay when the CloudFormation template is updated. Company policy requires that application configuration files be maintained along with AWS infrastructure configuration files in source control.\n\nWhich solution will accomplish this?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 128,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 128 discussion",
    "answers": {
      "A": "Create an Amazon CloudWatch Logs subscription that filters on CodePipeline Pipeline Execution State Change. Publish subscription events to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the chat webhook URL to the SNS topic, and complete the subscription validation.",
      "B": "Create an AWS Lambda function that is invoked by AWS CloudTrail events. When a CodePipeline Pipeline Execution State Change event is detected, send the event details to the chat webhook URL.",
      "C": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule that filters on CodePipeline Pipeline Execution State Change. Publish the events to an Amazon Simple Notification Service (Amazon SNS) topic. Create an AWS Lambda function that sends event details to the chat webhook URL. Subscribe the function to the SNS topic.",
      "D": "Modify the pipeline code to send the event details to the chat webhook URL at the end of each stage. Parameterize the URL so that each pipeline can send to a different URL based on the pipeline environment."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/92168-exam-aws-devops-engineer-professional-topic-1-question-128/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer is building a multistage pipeline with AWS CodePipeline to build, verify, stage, test, and deploy an application. A manual approval stage is required between the test stage and the deploy stage. The development team uses a custom chat tool with webhook support that requires near-real-time notifications.\n\nHow should the DevOps engineer configure status updates for pipeline activity and approval requests to post to the chat tool?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 129,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 129 discussion",
    "answers": {
      "A": "Use Amazon Athena to query AWS CloudTrail logs to check for any associate-address attempts. Create an AWS Lambda function to disassociate the Elastic IP address from the instance, and alert the security team.",
      "B": "Attach an IAM policy to the developers' IAM group to deny associate-address permissions. Create a custom AWS Config rule to check whether an Elastic IP address is associated with any instance tagged as production, and alert the security team.",
      "C": "Ensure that all IAM groups associated with developers do not have associate-address permissions. Create a scheduled AWS Lambda function to check whether an Elastic IP address is associated with any instance tagged as production, and alert the security team if an instance has an Elastic IP address associated with it.",
      "D": "Create an AWS Config rule to check that all production instances have EC2 IAM roles that include deny associate-address permissions. Verify whether there is an Elastic IP address associated with any instance, and alert the security team if an instance has an Elastic IP address associated with it."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/92583-exam-aws-devops-engineer-professional-topic-1-question-129/",
    "multiple_choice": false,
    "question_text": "A security team is concerned that a developer can unintentionally attach an Elastic IP address to an Amazon EC2 instance in production. No developer should be allowed to attach an Elastic IP address to an instance. The security team must be notified if any production server has an Elastic IP address at any time.\n\nHow can this task be automated?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 130,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 130 discussion",
    "answers": {
      "A": "Configure AWS Control Tower to publish to the SNS topic when the automatic drift detection feature identifies that a new account has been added to the service.",
      "B": "Configure the AWS Control Tower Account Factory product in AWS Service Catalog to publish to the SNS topic when a new account product is launched with the service.",
      "C": "Configure an Amazon EventBridge (Amazon CloudWatch Events) rule that reacts to the AWS Service Catalog ProvisionProduct event and publishes to the SNS topic.",
      "D": "Configure an Amazon EventBridge (Amazon CloudWatch Events) rule that reacts to the AWS Control Tower CreateManagedAccount event and publishes to the SNS topic."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/92584-exam-aws-devops-engineer-professional-topic-1-question-130/",
    "multiple_choice": false,
    "question_text": "A company uses AWS Control Tower to manage its multi-account AWS environment. The company has historically created AWS accounts by using AWS Control Tower through the AWS Management Console. The company wants to implement an automated solution that will create new AWS accounts by using AWS Control Tower Account Factory.\n\nA DevOps engineer is testing a new approach in which employees will upload a csv file into an Amazon S3 bucket. The .csv file will contain the information that is necessary to create a new AWS account. An AWS Lambda function will process event notifications from Amazon S3 when new files are created in the S3 bucket. The Lambda function will create the AWS account by using the AWS Service Catalog APIs.\n\nThe DevOps engineer needs to implement a solution to publish a notification to an Amazon Simple Notification Service (Amazon SNS) topic when the account creation process ends successfully.\n\nWhat should the DevOps engineer do to automate the SNS notification?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 131,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 131 discussion",
    "answers": {
      "A": "Create an AWS CodePipeline configuration and set up a post-commit hook to trigger the pipeline after tests have passed. Use AWS CodeDeploy and create a Canary deployment configuration that specifies the percentage of traffic and interval.",
      "B": "Create an AWS CodeBuild configuration that triggers when the test code is pushed. Use AWS CloudFormation to trigger an AWS CodePipeline configuration that deploys the new Lambda versions and specifies the traffic shift percentage and interval.",
      "C": "Create an AWS CodePipeline configuration and set up the source code step to trigger when code is pushed. Set up the build step to use AWS CodeBuild to run the tests. Set up an AWS CodeDeploy configuration to deploy, then select the CodeDeployDefault.LambdaLinea10PercentEvery3Minutes option.",
      "D": "Use the AWS CLI to set up a post-commit hook that uploads the code to an Amazon S3 bucket after tests have passed. Set up an S3 event trigger that runs a Lambda function that deploys the new version. Use an interval in the Lambda function to deploy the code over time at the required percentage."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/92585-exam-aws-devops-engineer-professional-topic-1-question-131/",
    "multiple_choice": false,
    "question_text": "A company has microservices running in AWS Lambda that read data from Amazon DynamoDB. The Lambda code is manually deployed by developers after successful testing. The company now needs the tests and deployments be automated and run in the cloud. Additionally, traffic to the new versions of each microservice should be incrementally shifted over time after deployment.\n\nWhat solution meets all the requirements, ensuring the MOST developer velocity?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 132,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 132 discussion",
    "answers": {
      "A": "Create an IAM policy that allows the developers to provision the required resources. Attach the policy to the developer IAM role.",
      "B": "Create an IAM policy that allows full access to AWS CloudFormation. Attach the policy to the developer IAM role.",
      "C": "Create an AWS CloudFormation service role that has the required permissions. Grant the developer IAM role a cloudforrnation:* action. Use the new service role during stack deployments.",
      "D": "Create an AWS CloudFormation service role that has the required permissions. Grant the developer IAM role the iam:PassRole permission. Use the new service role during stack deployments."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/93084-exam-aws-devops-engineer-professional-topic-1-question-132/",
    "multiple_choice": false,
    "question_text": "A development team wants to use AWS CloudFormation stacks to deploy an application. However, the developer IAM role does not have the required permissions to provision the resources that are specified in the AWS CloudFormation template. A DevOps engineer needs to implement a solution that allows the developers to deploy the stacks. The solution must follow the principle of least privilege.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 133,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 133 discussion",
    "answers": {
      "A": "Use Auto Scaling lifecycle hooks to put instances in a Pending:Wait state. Create an Amazon CloudWatch alarm for EC2 Instance Terminate Successful and trigger an AWS Lambda function that invokes an SSM Run Command script to collect logs, push them to Amazon S3, and complete the lifecycle action once logs are collected.",
      "B": "Use Auto Scaling lifecycle hooks to put instances in a Terminating:Wait state. Create an AWS Config rule for EC2 instance-terminate Lifecycle Action and trigger a step function that invokes a script to collect logs, push them to Amazon S3, and complete the lifecycle action once logs are collected.",
      "C": "Use Auto Scaling lifecycle hooks to put instances in a Terminating:Wait state. Create an Amazon CloudWatch subscription filter for EC2 Instance Terminate Successful and trigger a CloudWatch agent that invokes a script to collect logs, push them to Amazon S3, and complete the lifecycle action once logs are collected.",
      "D": "Use Auto Scaling lifecycle hooks to put instances in a Terminating:Wait state. Create an Amazon EventBridge rule for EC2 Instance-terminate Lifecycle Action and trigger an AWS Lambda function that invokes an SSM Run Command script to collect logs, push them to Amazon S3, and complete the lifecycle action once logs are collected."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/93126-exam-aws-devops-engineer-professional-topic-1-question-133/",
    "multiple_choice": false,
    "question_text": "A developer is maintaining a fleet of 50 Amazon EC2 Linux servers. The servers are part of an Amazon EC2 Auto Scaling group, and also use Elastic Load Balancing for load balancing.\n\nOccasionally, some application servers are being terminated after failing ELB HTTP health checks. The developer would like to perform a root cause analysis on the issue, but before being able to access application logs, the server is terminated.\n\nHow can log collection be automated?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 134,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 134 discussion",
    "answers": {
      "A": "Configure a new AWS CodePipeline service. Create a CodeCommit repository for each environment. Set up CodePipeline to retrieve the source code from the appropriate repository. Set up the deployment step to deploy the Lambda functions with AWS CloudFormation.",
      "B": "Create two AWS CodePipeline configurations for test and production environments. Configure the production pipeline to have a manual approval step. Create a CodeCommit repository for each environment. Set up each CodePipeline to retrieve the source code from the appropriate repository. Set up the deployment step to deploy the Lambda functions with AWS CloudFormation.",
      "C": "Create two AWS CodePipeline configurations for test and production environments. Configure the production pipeline to have a manual approval step. Create one CodeCommit repository with a branch for each environment. Set up each CodePipeline to retrieve the source code from the appropriate branch in the repository. Set up the deployment step to deploy the Lambda functions with AWS CloudFormation.",
      "D": "Create an AWS CodeBuild configuration for test and production environments. Configure the production pipeline to have a manual approval step. Create one CodeCommit repository with a branch for each environment. Push the Lambda function code to an Amazon S3 bucket. Set up the deployment step to deploy the Lambda functions from the S3 bucket."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/92560-exam-aws-devops-engineer-professional-topic-1-question-134/",
    "multiple_choice": false,
    "question_text": "A company is building a web and mobile application that uses a serverless architecture powered by AWS Lambda and Amazon API Gateway. The company wants to fully automate the backend Lambda deployment based on code that is pushed to the appropriate environment branch in an AWS CodeCommit repository.\n\nThe deployment must have the following:\n• Separate environment pipelines for testing and production\n• Automatic deployment that occurs for test environments only\n\nWhich steps should be taken to meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 135,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 135 discussion",
    "answers": {
      "A": "Direct the security team to use CloudFormation to create new versions of the AMIs and to list the AMI ARNs in an encrypted Amazon S3 object as part of the stack's Outputs section. Instruct the developers to use a cross-stack reference to load the encrypted S3 object and obtain the most recent AMI ARNs.",
      "B": "Direct the security team to use a CloudFormation stack to create an AWS CodePipeline pipeline that builds new AMIs and places the latest AMI ARNs in an encrypted Amazon S3 object as part of the pipeline output. Instruct the developers to use a cross-stack reference within their own CloudFormation template to obtain the S3 object location and the most recent AMI ARNs.",
      "C": "Direct the security team to use Amazon EC2 Image Builder to create new AMIs and to place the AMI ARNs as parameters in AWS Systems Manager Parameter Store. Instruct the developers to specify a parameter of type SSM in their CloudFormation stack to obtain the most recent AMI ARNs from Parameter Store.",
      "D": "Direct the security team to use Amazon EC2 Image Builder to create new AMIs and to create an Amazon Simple Notification Service (Amazon SNS) topic so that every development team can receive notifications. When the development teams receive a notification, instruct them to write an AWS Lambda function that will update their CloudFormation stack with the most recent AMI ARNs."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/92563-exam-aws-devops-engineer-professional-topic-1-question-135/",
    "multiple_choice": false,
    "question_text": "A company has a guideline that every Amazon EC2 instance must be launched from an AMI that the company's security team produces. Every month, the security team sends an email message with the latest approved AMIs to all the development teams.\n\nThe development teams use AWS CloudFormation to deploy their applications. When developers launch a new service, they have to search their email for the latest AMIs that the security department sent. A DevOps engineer wants to automate the process that the security team uses to provide the AMI IDs to the development teams.\n\nWhat is the MOST scalable solution that meets these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 136,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 136 discussion",
    "answers": {
      "A": "Reference the EC2 instances in the AWS::ECS::Cluster resource and reference the ECS cluster in the AWS::ECS::Service resource.",
      "B": "Reference the ECS cluster in the AWS::AutoScaling::LaunchConfiguration resource of the UserData property.",
      "C": "Reference the ECS cluster in the AWS::EC2::Instance resource of the UserData property.",
      "D": "Reference the ECS cluster in the AWS::CloudFormation::CustomResource resource to trigger an AWS Lambda function that registers the EC2 instances with the appropriate ECS cluster."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/92564-exam-aws-devops-engineer-professional-topic-1-question-136/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer is setting up a container-based architecture. The engineer has decided to use AWS CloudFormation to automatically provision an Amazon ECS cluster and an Amazon EC2 Auto Scaling group to launch the EC2 container instances. After successfully creating the CloudFormation stack, the engineer noticed that, even though the ECS cluster and the EC2 instances were created successfully and the stack finished the creation, the EC2 instances were associating with a different cluster.\n\nHow should the DevOps engineer update the CloudFormation template to resolve this issue?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 137,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 137 discussion",
    "answers": {
      "A": "Configure the Systems Manager document to use the AWS-RunShellScript command to copy the files from GitHub to Amazon S3, then use the aws-downloadContent plugin with a sourceType of S3.",
      "B": "Configure the Systems Manager document to use the aws-configurePackage plugin with an install action and point to the Git repository.",
      "C": "Configure the Systems Manager document to use the aws-downloadContent plugin with a sourceType of GitHub and sourcelnfo with the repository details.",
      "D": "Configure the Systems Manager document to use the aws:softwarelnventory plugin and run the script from the Git repository."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/93116-exam-aws-devops-engineer-professional-topic-1-question-137/",
    "multiple_choice": false,
    "question_text": "A company wants to use AWS Systems Manager documents to bootstrap physical laptops for developers. The bootstrap code is stored in GitHub. A DevOps engineer has already created a Systems Manager activation, installed the Systems Manager agent with the registration code, and installed an activation ID on all the laptops.\n\nWhich set of steps should be taken next?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 138,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 138 discussion",
    "answers": {
      "A": "Use AWS Systems Manager to create a new patch baseline including the custom repository. Run the AWS-RunPatchBaseline document using the run command to verify and install patches.",
      "B": "Use AWS Direct Connect to integrate the corporate repository and deploy the patches using Amazon CloudWatch scheduled events, then use the CloudWatch dashboard to create reports.",
      "C": "Use yum-config-manager to add the custom repository under /etc/yum.repos.d and run yum-config-manager-enable to activate the repository.",
      "D": "Use AWS Systems Manager to create a new patch baseline including the corporate repository. Run the AWS-AmazonLinuxDefaultPatchBaseline document using the run command to verify and install patches."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/92587-exam-aws-devops-engineer-professional-topic-1-question-138/",
    "multiple_choice": false,
    "question_text": "A company that uses electronic health records is running a fleet of Amazon EC2 instances with an Amazon Linux operating system. As part of patient privacy requirements, the company must ensure continuous compliance for patches for operating system and applications running on the EC2 instances.\n\nHow can the deployments of the operating system and application patches be automated using a default and custom repository?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 139,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 139 discussion",
    "answers": {
      "A": "Add additional logging to the application code. Use the Amazon CloudWatch agent to stream the application logs into Amazon OpenSearch Service. Query the log data in OpenSearch Service.",
      "B": "Instrument the application to use the AWS X-Ray SDK. Post trace data to an Amazon OpenSearch Service cluster. Query the trace data for calls to the HTTP client and the MySQL client.",
      "C": "On the AWS Elastic Beanstalk management page for the application, enable the AWS X-Ray daemon. View the trace data in the X-Ray console.",
      "D": "Instrument the application using the AWS X-Ray SDK. On the AWS Elastic Beanstalk management page for the application, enable the X-Ray daemon. View the trace data in the X-Ray console."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/93027-exam-aws-devops-engineer-professional-topic-1-question-139/",
    "multiple_choice": false,
    "question_text": "A web application has been deployed using an AWS Elastic Beanstalk application. The application developers are concerned that they are seeing high latency in two different areas of the application:\n\n• HTTP client requests to a third-party API\n• MySQL client library queries to an Amazon RDS database\n\nA DevOps engineer must gather trace data to diagnose the issues.\n\nWhich steps will gather the trace information with the LEAST amount of changes and performance impacts to the application?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 140,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 140 discussion",
    "answers": {
      "A": "Allow users to deploy CloudFormation stacks using a CloudFormation service role only. Use CloudFormation drift detection to detect when resources have drifted from their expected state.",
      "B": "Allow users to deploy CloudFormation stacks using a CloudFormation service role only. Use AWS Config rules to detect when resources have drifted from their expected state.",
      "C": "Allow users to deploy CloudFormation stacks using AWS Service Catalog only. Enforce the use of a launch constraint. Use AWS Config rules to detect when resources have drifted from their expected state.",
      "D": "Allow users to deploy CloudFormation stacks using AWS Service Catalog only. Enforce the use of a template constraint. Use Amazon EventBridge notifications to detect when resources have drifted from their expected state."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/92828-exam-aws-devops-engineer-professional-topic-1-question-140/",
    "multiple_choice": false,
    "question_text": "A company requires its internal business teams to launch resources through pre-approved AWS CloudFormation templates only. The security team requires automated monitoring when resources drift from their expected state.\n\nWhich strategy should be used to meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 141,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 141 discussion",
    "answers": {
      "A": "Configure AWS Lambda to poll the SOS queue and invoke a Lambda function to check whether the queue messages are valid. If validation fails, send a copy of the data that is not valid to an Amazon S3 bucket so that the scientists can review and correct the data. When the data is corrected, amend the message in the SOS queue by using a replay Lambda function with the corrected data",
      "B": "Convert the SQS standard queue to an SQS FIFO queue. Configure AWS Lambda to poll the SQS queue every 10 minutes by using an Amazon EventBridge schedule. Invoke the Lambda function to identify any messages with a SentTimestamp value that is older than 5 minutes, push the data to the same location as the application's output location, and remove the messages from the queue.",
      "C": "Create an SOS dead-letter queue. Modify the existing queue by including a redrive policy that sets the Maximum Receives setting to 1 and sets the dead-letter queue ARN to the ARN of the newly created queue. Instruct the scientists to use the dead-letter queue to review the data that is not valid. Reprocess this data at a later time.",
      "D": "Configure API Gateway to send messages to different SOS virtual queues that are named for each of the satellites. Update the application to use a new virtual queue for any data that it cannot transform, and send the message to the new virtual queue. Instruct the scientists to use the virtual queue to review the data that is not valid. Reprocess this data at a later time."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/92779-exam-aws-devops-engineer-professional-topic-1-question-141/",
    "multiple_choice": false,
    "question_text": "A space exploration company receives telemetry data from multiple satellites. Small packets of data are received through Amazon API Gateway and are placed directly into an Amazon Simple Queue Service (Amazon SOS) standard queue. A custom application is subscribed to the queue and transforms the data into a standard format.\n\nBecause of inconsistencies in the data that the satellites produce, the application is occasionally unable to transform the data. In these cases, the messages remain in the SQS queue. A DevOps engineer must develop a solution that retains the failed messages and makes them available to scientists for review and future processing.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 142,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 142 discussion",
    "answers": {
      "A": "In the organization's management account, configure an AWS account as the Amazon GuardDuty administrator account. In the GuardDuty administrator account, add the company's existing AWS accounts to GuardDuty as members. In the GuardDuty administrator account, create an Amazon EventBridge (Amazon CloudWatch Events) rule with an event pattern to match GuardDuty events and to forward matching events to the SNS topic.",
      "B": "In the organization's management account, configure Amazon GuardDuty to add newly created AWS accounts by invitation and to send invitations to the existing AWS accounts. Create an AWS CloudFormation stack set that accepts the GuardDuty invitation and creates an Amazon EventBridge (Amazon CloudWatch Events) rule. Configure the rule with an event pattern to match GuardDuty events and to forward matching events to the SNS topic. Configure the CloudFormation stack set to deploy into all AWS accounts in the organization.",
      "C": "In the organization's management account, create an AWS CloudTrail organization trail. Activate the organization trail in all AWS accounts in the organization. Create an SCP that enables VPC Flow Logs in each account in the organization Configure AWS Security Hub for the organization. Create an Amazon EventBridge (Amazon CloudWatch Events) rule with an event pattern to match Security Hub events and to forward matching events to the SNS topic.",
      "D": "In the organization's management account, configure an AWS account as the AWS CloudTrail administrator account. In the CloudTrail administrator account, create a CloudTrail organization trail. Add the company's existing AWS accounts to the organization trail. Create an SCP that enables VPC Flow Logs in each account in the organization. Configure AWS Security Hub for the organization. Create an Amazon EventBridge (Amazon CloudWatch Events) rule with an event pattern to match Security Hub events and to forward matching events to the SNS topic."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/95469-exam-aws-devops-engineer-professional-topic-1-question-142/",
    "multiple_choice": false,
    "question_text": "A company runs applications in AWS accounts that are in an organization in AWS Organizations. The applications use Amazon EC2 instances and Amazon S3.\n\nThe company wants to detect potentially compromised EC2 instances, suspicious network activity, and unusual API activity in its existing AWS accounts and in any AWS accounts that the company creates in the future. When the company detects one of these events, the company wants to use an existing Amazon Simple Notification Service (Amazon SNS) topic to send a notification to its operational support team for investigation and remediation.\n\nWhich solution will meet these requirements in accordance with AWS best practices?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 143,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 143 discussion",
    "answers": {
      "A": "Use rolling deployments with a fixed amount of one instance at a time and set the healthy threshold to OK.",
      "B": "Use rolling deployments with additional batch with a fixed amount of one instance at a time and set the healthy threshold to OK.",
      "C": "Launch a new environment and deploy the new application version there, then perform a CNAME swap between environments.",
      "D": "Use immutable environment updates to meet all the necessary requirements."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/95163-exam-aws-devops-engineer-professional-topic-1-question-143/",
    "multiple_choice": false,
    "question_text": "A retail company wants to use AWS Elastic Beanstalk to host its online sales website running on Java. Since this will be the production website the CTO has the following requirements for the deployment strategy:\n• Zero downtime. While the deployment is ongoing the current Amazon EC2 instances in service should remain in service. No deployment or any other action should be performed on the EC2 instances because they serve production traffic.\n• A new fleet of instances should be provisioned for deploying the new application version.\n• Once the new application version is deployed successfully in the new fleet of instances, the new instances should be placed in service and the old ones should be removed.\n• The rollback should be as easy as possible. If the new fleet of instances fails to deploy the new application version, they should be terminated and the current instances should continue serving traffic as normal.\n• The resources within the environment (EC2 Auto Scaling group, Elastic Load Balancing, Elastic Beanstalk DNS CNAME) should remain the same and no DNS change should be made.\n\nWhich deployment strategy will meet the requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 144,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 144 discussion",
    "answers": {
      "A": "Configure automatic remediation to run the AWSConfigRemediation-DetachIAMPolicy AWS Systems Manager Automation runbook.",
      "B": "Configure automatic remediation to invoke a custom AWS Lambda function to detach the IAM policy from the affected resources.",
      "C": "Configure automatic remediation to use AWS Systems Manager Run Command to detach the IAM policy from the affected resources.",
      "D": "Turn on AWS Config by using an AWS CloudFormation stack set that is created in a central account. Configure automatic deployment for the stack set, and specify the organization as the target. Configure the iam-policy-no-statements-with-full-access AWS Config managed rule in the central account.",
      "E": "Turn on AWS Config for the organization. Create a new AWS account. Configure the account as a delegated administrator account for AWS Config. Configure the iam-policy-no-statements-with-full-access AWS Config managed rule in the delegated administrator account."
    },
    "suggested_answer": "AD",
    "answer": "AD",
    "link": "https://www.examtopics.com/discussions/amazon/view/95468-exam-aws-devops-engineer-professional-topic-1-question-144/",
    "multiple_choice": true,
    "question_text": "A company has AWS accounts that are members of the same organization in AWS Organizations. According to the company's security policy, IAM customer managed policies must be scoped to specific actions and must not include wildcard actions on wildcard resources.\n\nIf an IAM customer managed policy is created or modified in any of the company's AWS accounts to grant wildcard actions on resources that also specify wildcards, the policy must be detached from any IAM user, role, or group that the policy is attached to Individual AWS account administrators must not be able to prevent the removal of the policies.\n\nWhich combination of steps will meet these requirements? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 145,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 145 discussion",
    "answers": {
      "A": "Use Amazon Inspector to add a test action to the pipeline. Use the Amazon Inspector Runtime Behavior Analysis Inspector rules package to check that the deployed code complies with company security standards before deploying it to production.",
      "B": "Using AWS CodeBuild to add a test action to the pipeline to replicate common user activities and ensure that the results are as expected before progressing to production deployment.",
      "C": "Create an AWS CodeDeploy action in the pipeline with a deployment configuration that automatically deploys the application code to a limited number of instances. The action then pauses the deployment so that the QA team can review the application functionality. When the review is complete, CodeDeploy resumes and deploys the application to the remaining production Amazon EC2 instances.",
      "D": "After the deployment process is complete, run a testing activity on an Amazon EC2 instance in a different region that accesses the application to simulate user behavior. If unexpected results occur the testing activity sends a warning to an Amazon SNS topic. Subscribe to the topic to get updates.",
      "E": "Add an AWS CodeDeploy action in the pipeline to deploy the latest version of the development code to pre-production Add a manual approval action in the pipeline so that the QA team can test and confirm the expected functionality. After the manual approval action, add a second CodeDeploy action that deploys the approved code to the production environment."
    },
    "suggested_answer": "BE",
    "answer": "BE",
    "link": "https://www.examtopics.com/discussions/amazon/view/95097-exam-aws-devops-engineer-professional-topic-1-question-145/",
    "multiple_choice": true,
    "question_text": "An application team has three environments for their application: development, pre-production, and production. The team recently adopted AWS CodePipeline. However, the team has had several deployments of misconfigured or nonfunctional development code into the production environment, resulting in user disruption and downtime. The DevOps engineer must review the pipeline and add steps to identify problems with the application before it is deployed.\n\nWhat should the engineer do to identify functional issues during the deployment process? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 146,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 146 discussion",
    "answers": {
      "A": "Use an Application Load Balancer and an in-place deployment. Associate the Auto Scaling group with the deployment group. Use the Automatically copy Auto Scaling group option, and use CodeDeployDefault.OneAtAtime as the deployment configuration. Instruct AWS CodeDeploy to terminate the original instances in the deployment group, and use the AllowTraffic hook within appspec.yml to delete the temporary files.",
      "B": "Use an Application Load Balancer and a blue/green deployment. Associate the Auto Scaling group and Application Load Balancer target group with the deployment group. Use the Automatically copy Auto scaling group option, create a custom deployment configuration with minimum healthy hosts defined as 50%, and assign the configuration to the deployment group. Instruct AWS CodeDeploy to terminate the original instances in the deployment group, and use the BeforeBlockTraffic hook within appspec.yml to delete the temporary files.",
      "C": "Use an Application Load Balancer and a blue/green deployment. Associate the Auto Scaling group and the Application Load Balancer target group with the deployment group. Use the Automatically copy Auto Scaling group option, and use CodeDeployDefault.HalfAtAtime as the deployment configuration. Instruct AWS CodeDeploy to terminate the original instances in the deployment group, and use the BeforeAllowTraffic hook within appspec.yml to delete the temporary files.",
      "D": "Use an Application Load Balancer and an in-place deployment. Associate the Auto Scaling group and Application Load Balancer target group with the deployment group. Use the Automatically copy Auto Scaling group option, and use CodeDeployDefault AllatOnce as a deployment configuration. Instruct AWS CodeDeploy to terminate the original instances in the deployment group, and use the BlockTraffic hook within appspec.yml to delete the temporary files."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/95164-exam-aws-devops-engineer-professional-topic-1-question-146/",
    "multiple_choice": false,
    "question_text": "A company is using AWS CodeDeploy to automate software deployment. The deployment must meet these requirements:\n\n• A number of instances must be available to serve traffic during the deployment. Traffic must be balanced across those instances, and the instances must automatically heal in the event of failure.\n• A new fleet of instances must be launched for deploying a new revision automatically, with no manual provisioning.\n• Traffic must be rerouted to the new environment to half of the new instances at a time. The deployment should succeed if traffic is rerouted to at least half of the instances; otherwise, it should fail.\n• Before routing traffic to the new fleet of instances, the temporary files generated during the deployment process must be deleted.\n• At the end of a successful deployment, the original instances in the deployment group must be deleted immediately to reduce costs.\n\nHow can a DevOps engineer meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 147,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 147 discussion",
    "answers": {
      "A": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule for the CloudTrail StopLogging event. Create an AWS Lambda function that uses the AWS SDK to call StartLogging on the ARN of the resource in which StopLogging was called. Add the Lambda function ARN as a target to the EventBridge (CloudWatch Events) rule.",
      "B": "Deploy the AWS-managed CloudTrail-enabled AWS Config rule, set with a periodic interval of 1 hour. Create an Amazon EventBridge (Amazon CloudWatch Events) rule for AWS Config rules compliance change. Create an AWS Lambda function that uses the AWS SDK to call StartLogging on the ARN of the resource in which StopLogging was called. Add the Lambda function ARN as a target to the EventBridge (CloudWatch Events) rule.",
      "C": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule for a scheduled event every 5 minutes. Create an AWS Lambda function that uses the AWS SDK to call StartLogging on a CloudTrail trail in the AWS account. Add the Lambda function ARN as a target to the EventBridge (CloudWatch Events) rule.",
      "D": "Launch a t2.nano instance with a script running every 5 minutes that uses the AWS SDK to query CloudTrail in the current account. If the CloudTrail trail is disabled, have the script re-enable the trail."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/95098-exam-aws-devops-engineer-professional-topic-1-question-147/",
    "multiple_choice": false,
    "question_text": "The security team depends on AWS CloudTrail to detect sensitive security issues in the company's AWS account The DevOps engineer needs a solution to auto-remediate CloudTrail being turned off in an AWS account.\n\nWhat solution ensures the LEAST amount of downtime for the CloudTrail log deliveries?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 148,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 148 discussion",
    "answers": {
      "A": "Create an AWS Config conformance pack that contains a rule that checks for S3 buckets that have public ACLs. Configure the conformance pack to use an AWS Systems Manager Automation runbook to block public access to the S3 buckets. Deploy the conformance pack across the organization.",
      "B": "Configure AWS Config rules that detect S3 buckets that have public ACLs. Configure a remediation action that uses AWS Lambda to block public access to the S3 buckets. Use AWS CloudFormation StackSets to deploy the rules across the organization.",
      "C": "Configure AWS Config rules that detect S3 buckets that have public ACLs. Configure a remediation action that uses an AWS Systems Manager Automation runbook to block public access to the S3 buckets. Use AWS CloudFormation StackSets to deploy the rules across the organization.",
      "D": "Create an AWS Config conformance pack that contains a rule that checks for 53 buckets that have public ACLs. Configure the conformance pack to use an AWS Lambda function to block public access to the S3 buckets. Deploy the conformance pack across the organization."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/95099-exam-aws-devops-engineer-professional-topic-1-question-148/",
    "multiple_choice": false,
    "question_text": "A DevOps team supports many accounts across an organization in AWS Organizations. The DevOps team has decided to use AWS Coring across the organization to implement centralized automatic remediation of Amazon S3 buckets that have public ACLs. Individual accounts must not be able to modify the remediation strategy.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 149,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 149 discussion",
    "answers": {
      "A": "Check the returned response for the Versionld. Compare the returned VersionId against the MD5 checksum.",
      "B": "Include the MD5 checksum within the Content-MD5 parameter. Check the operation call's return status to find out if an error was returned.",
      "C": "Include the checksum digest within the tagging parameter as a URL query parameter.",
      "D": "Check the returned response for the ETag. Compare the returned ETag against the MD5 checksum.",
      "E": "Include the checksum digest within the Metadata parameter as a name-value pair. After upload, use the S3 HeadObject operation to retrieve metadata from the object."
    },
    "suggested_answer": "BD",
    "answer": "BD",
    "link": "https://www.examtopics.com/discussions/amazon/view/95094-exam-aws-devops-engineer-professional-topic-1-question-149/",
    "multiple_choice": true,
    "question_text": "A DevOps engineer is working on a data archival project that requires the migration of on-premises data to an Amazon S3 bucket. The DevOps engineer develops a script that incrementally archives on-premises data that is older than 1 month to Amazon S3. Data that is transferred to Amazon S3 is deleted from the on-premises location. The script uses the S3 PutObject operation.\n\nDuring a code review, the DevOps engineer notices that the script does not verify whether the data was successfully copied to Amazon S3. The DevOps engineer must update the script to ensure that data is not corrupted during transmission. The script must use MD5 checksums to verify data integrity before the on-premises data is deleted.\n\nWhich solutions for the script will meet these requirements? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 150,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 150 discussion",
    "answers": {
      "A": "Create an additional policy to include a Deny rule for the GitPush and PutFile actions. Include a restriction for the specific repositories in the policy statement with a condition that references the main branch.",
      "B": "Remove the IAM policy, and add an AWSCodeCommitReadOnly managed policy. Add an Allow rule for the GitPush and PutFile actions for the specific repositories in the policy statement with a condition that references the main branch.",
      "C": "Modify the IAM policy. Include a Deny rule for the GitPush and PutFile actions for the specific repositories in the policy statement with a condition that references the main branch.",
      "D": "Create an additional policy to include an Allow rule for the GitPush and PutFile actions. Include a restriction for the specific repositories in the policy statement with a condition that references the feature branches."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/95101-exam-aws-devops-engineer-professional-topic-1-question-150/",
    "multiple_choice": false,
    "question_text": "A company uses AWS CodeCommit for source code control. Developers apply their changes to various feature branches and create pull requests to move those changes to the main branch when the changes are ready for production.\n\nThe developers should not be able to push changes directly to the main branch. The company applied the AWSCodeCommitPowerUser managed policy to the developers' IAM role, and now these developers can push changes to the main branch directly on every repository in the AWS account.\n\nWhat should the company do to restrict the developers' ability to push changes to the main branch directly?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 151,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 151 discussion",
    "answers": {
      "A": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule that matches an AWS Config evaluation result of NON_COMPLIANT for the restricted-ssh rule. Configure an input transformer for the EventBridge (CloudWatch Events) rule. Configure the EventBridge (CloudWatch Events) rule to publish a notification to the SNS topic.",
      "B": "Configure AWS Config to send all evaluation results for the restricted-ssh rule to the SNS topic. Configure a filter policy on the SNS topic to send only notifications that contain the text of NON_COMPLIANT in the notification to subscribers.",
      "C": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule that matches an AWS Config evaluation result of NON_COMPLIANT for the restricted-ssh rule. Configure the EventBridge (CloudWatch Events) rule to invoke AWS Systems Manager Run Command on the SNS topic to customize a notification and to publish the notification to the SNS topic.",
      "D": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule that matches all AWS Config evaluation results of NON_COMPLIANT. Configure an input transformer for the restricted-ssh rule. Configure the EventBridge (CloudWatch Events) rule to publish a notification to the SNS topic."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/95102-exam-aws-devops-engineer-professional-topic-1-question-151/",
    "multiple_choice": false,
    "question_text": "A company uses a single AWS account to test applications on Amazon EC2 instances. The company has turned on AWS Config in the AWS account and has activated the restricted-ssh AWS Config managed rule.\n\nThe company needs an automated monitoring solution that will provide a customized notification in real time if any security group in the account is not compliant with the restricted-ssh rule. The customized notification must contain the name and ID of the noncompliant security group.\n\nA DevOps engineer creates an Amazon Simple Notification Service (Amazon SNS) topic in the account and subscribes the appropriate personnel to the topic.\n\nWhat should the DevOps engineer do next to meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 152,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 152 discussion",
    "answers": {
      "A": "In AWS SSO, configure always-on MFBlock user sign-in when a user does not yet have a registered MFA device.",
      "B": "In AWS SSO, configure always-on MFA. Require a user to register an MFA device at sign-in when the user does not yet have a registered MFA device.",
      "C": "In AWS SSO, configure context-aware MFA. Update the trust policy of all permission sets to include the aws:MultiFactorAuthPresent condition on the sts:AssumeRole action.",
      "D": "In AWS SSO, configure context-aware MFA. Block user sign-in when a user does not yet have a registered MFA device."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/95103-exam-aws-devops-engineer-professional-topic-1-question-152/",
    "multiple_choice": false,
    "question_text": "A company has an organization in AWS Organizations. The company has configured AWS Single Sign-On (AWS SSO) to centrally manage access to the AWS accounts in the organization. A DevOps engineer needs to ensure that all users sign in by using multi-factor authentication (MFA). Users must be allowed to manage their own MFA devices. Users also must be prompted for MFA every time they sign in.\n\nWhat should the DevOps engineer do to meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 153,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 153 discussion",
    "answers": {
      "A": "Create an AWS CloudFormation template that defines the standard account resources. Deploy the template to all accounts from the organization's management account by using CloudFormation StackSets. Set the stack policy to deny Update Delete actions.",
      "B": "Enable AWS Control Tower. Enroll the existing accounts in AWS Control Tower. Grant the individual account administrators access to CloudTrail and AWS Config.",
      "C": "Designate an AWS Config management account. Create AWS Config recorders in all accounts by using AWS CloudFormation StackSets. Deploy AWS Config rules to the organization by using the AWS Config management account. Create a CloudTrail organization trail in the organization's management account. Deny modification or deletion of the AWS Config recorders by using an SCP.",
      "D": "Create an AWS CloudFormation template that defines the standard account resources. Deploy the template to all accounts from the organization's management account by using CloudFormation StackSets. Create an SCP that prevents updates or deletions to CloudTrail resources or AWS Config resources unless the principal is an administrator of the organization's management account."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/95165-exam-aws-devops-engineer-professional-topic-1-question-153/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer needs to apply a core set of security controls to an existing set of AWS accounts. The accounts are in an organization in AWS Organizations. Individual teams will administer individual accounts by using the AdministratorAccess AWS managed policy. For all accounts, AWS CloudTrail and AWS Config must be turned on in all available AWS Regions. Individual account administrators must not be able to edit or delete any of the baseline resources. However, individual account administrators must be able to edit or delete their own CloudTrail trails and AWS Config rules.\n\nWhich solution will meet these requirements in the MOST operationally efficient way?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 154,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 154 discussion",
    "answers": {
      "A": "Create IAM policies that include the required permissions. Include the aws PrincipalTag condition key.",
      "B": "Create permission sets. Attach an inline policy that includes the required permissions and uses the aws:PrincipalTag condition key to scope the permissions.",
      "C": "Create a group in the IdP. Place users in the group. Assign the group to accounts and the permission sets in AWS SSO.",
      "D": "Create a group in the IdP. Place users in the group. Assign the group to OUs and IAM policies.",
      "E": "Enable attributes for access control in AWS SSO. Apply tags to users. Map the tags as key-value pairs.",
      "F": "Enable attributes for access control in AWS SSO. Map attributes from the IdP as key-value pairs."
    },
    "suggested_answer": "BCF",
    "answer": "BCF",
    "link": "https://www.examtopics.com/discussions/amazon/view/95751-exam-aws-devops-engineer-professional-topic-1-question-154/",
    "multiple_choice": true,
    "question_text": "An ecommerce company has chosen AWS to host its new platform. The company's DevOps team has started building an AWS Control Tower landing zone. The DevOps team has set the identity store within AWS Single Sign-On (AWS SSO) to external identity provider (IdP) and has configured SAML 2 0.\n\nThe DevOps team wants a robust permission model that applies the principle of least privilege. The model must allow the team to build and manage only the team's own resources.\n\nWhich combination of steps will meet these requirements? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 155,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 155 discussion",
    "answers": {
      "A": "Set the –parameter-overrides option in the sam deploy command when the CodeBuild stage is invoked.",
      "B": "Add all parameters in AWS Systems Manager Parameter Store. Use dynamic references to specify template values in Parameter Store.",
      "C": "In the deployment stage where the \"Create or replace a change set\" action mode resides, apply the JSON object in the ParameterOverrides property.",
      "D": "In the deployment stage where the \"Execute a change set\" action mode resides, apply the JSON object in the ParameterOverrides property."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/95456-exam-aws-devops-engineer-professional-topic-1-question-155/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer is using AWS CodePipeline and AWS CodeBuild to create a CI/CD pipeline for a serverless application that is based on the AWS Serverless Application Model (AWS SAM). The source, build and test steps have been completed. The DevOps engineer has also created two pipeline deployment stages that use AWS CloudFormation as the action provider. One stage uses the \"Create or replace a change set\" action mode. The other stage uses the \"Execute a change set\" action mode.\n\nThe DevOps engineer needs to pass some parameters to a CloudFormation stack during the deployment without changing the code and pipeline structure.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 156,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 156 discussion",
    "answers": {
      "A": "Create a CodeBuild project to run the unit and integration tests. Create a CodeCommit approval rule template. Configure the template to require the successful invocation of the CodeBuild project. Attach the approval rule to the project's CodeCommit repository.",
      "B": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule to match pullRequestCreated events from CodeCommit. Create a CodeBuild project to run the unit and integration tests. Configure the CodeBuild project as a target of the EventBridge (CloudWatch Events) rule that includes a custom event payload with the CodeCommit repository and branch information from the event.",
      "C": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule to match pullRequestCreated events from CodeCommit. Modify the existing CodePipeline pipeline to not run the deploy steps if the build is started from a pull request. Configure the EventBridge (CloudWatch Events) rule to run the pipeline with a custom payload that contains the CodeCommit repository and branch information from the event.",
      "D": "Create a CodeBuild project to run the unit and integration tests. Create a CodeCommit notification rule that matches when a pull request is created or updated. Configure the notification rule to invoke the CodeBuild project."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/95450-exam-aws-devops-engineer-professional-topic-1-question-156/",
    "multiple_choice": false,
    "question_text": "A development team uses AWS CodeCommit, AWS CodePipeline, and AWS CodeBuild to develop and deploy an application. Changes to the code are submitted by pull requests. The development team reviews and merges the pull requests, and then the pipeline builds and tests the application.\n\nOver time, the number of pull requests has increased. The pipeline is frequently blocked because of failing tests. To prevent this blockage, the development team wants to run the unit and integration tests on each pull request before it is merged.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 157,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 157 discussion",
    "answers": {
      "A": "The two affected instances failed to fetch the new deployment.",
      "B": "A failed AfterInstall lifecycle event hook caused the CodeDeploy agent to roll back to the previous version on the affected instances.",
      "C": "The CodeDeploy agent was not installed in two affected instances.",
      "D": "EC2 Auto Scaling launched two new instances while the new deployment had not yet finished, causing the previous version to be deployed on the affected instances."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/95446-exam-aws-devops-engineer-professional-topic-1-question-157/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer is using AWS CodeDeploy across a fleet of Amazon EC2 Instances in an EC2 Auto Scaling group. The associated CodeDeploy deployment group, which is integrated with EC2 Auto Scaling, is configured to perform in-place deployments with CodeDeplcyDefault.OneAtATime. During an ongoing new deployment, the engineer discovers that although the overall deployment finished successfully, two out of five instances have the previous application revision deployed. The other three instances have the newest application revision.\n\nWhat is likely causing this issue?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 158,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 158 discussion",
    "answers": {
      "A": "Create a new version of the common AMI with the CodeDeploy agent installed. Update the IAM role of the EC2 instances to allow access to CodeDeploy.",
      "B": "Create a new version of the common AMI with the CodeDeploy agent installed. Create an AppSpec file that contains application deployment scripts and grants access to CodeDeploy.",
      "C": "Create an application in CodeDeploy. Configure an in-place deployment type. Specify the Auto Scaling group as the deployment target. Add a step to the CodePipeline pipeline to use EC2 Image Builder to create a new AMI. Configure CodeDeploy to deploy the newly created AMI.",
      "D": "Create an application in CodeDeploy. Configure an in-place deployment type. Specify the Auto Scaling group as the deployment target. Update the CodePipeline pipeline to use the CodeDeploy action to deploy the application.",
      "E": "Create an application in CodeDeploy. Configure an in-place deployment type. Specify the EC2 instances that are launched from the common AMI as the deployment target. Update the CodePipeline pipeline to use the CodeDeploy action to deploy the application."
    },
    "suggested_answer": "AD",
    "answer": "AD",
    "link": "https://www.examtopics.com/discussions/amazon/view/96103-exam-aws-devops-engineer-professional-topic-1-question-158/",
    "multiple_choice": true,
    "question_text": "A company uses AWS CodePipeline pipelines to automate releases of its application. A typical pipeline consists of three stages: build, test, and deployment. The company has been using a separate AWS CodeBuild project to run scripts for each stage. However, the company now wants to use AWS CodeDeploy to handle the deployment stage of the pipelines.\n\nThe company has packaged the application as an RPM package and must deploy the application to a fleet of Amazon EC2 instances. The EC2 instances are in an EC2 Auto Scaling group and are launched from a common AMI.\n\nWhich combination of steps should a DevOps engineer perform to meet these requirements? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 159,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 159 discussion",
    "answers": {
      "A": "Update the EFS file system policy to provide Account B with access to mount and write to the EFS file system in Account A.",
      "B": "Create SCPs to set permission guardrails with fine-grained control for Amazon EFS.",
      "C": "Create a new EFS file system in Account B. Use AWS Database Migration Service (AWS DMS) to keep data from Account A and Account B synchronized.",
      "D": "Update the Lambda execution roles with permission to access the VPC and the EFS file system. E. Create a VPC peering connection to connect Account A to Account B.",
      "E": "Configure the Lambda functions in Account B to assume an existing IAM role in Account A."
    },
    "suggested_answer": "ADF",
    "answer": "ADF",
    "link": "https://www.examtopics.com/discussions/amazon/view/95441-exam-aws-devops-engineer-professional-topic-1-question-159/",
    "multiple_choice": true,
    "question_text": "A company is using an organization in AWS Organizations to manage multiple AWS accounts. The company's development team wants to use AWS Lambda functions to meet resiliency requirements and is rewriting all applications to work with Lambda functions that are deployed in a VPC. The development team is using Amazon Elastic File System (Amazon EFS) as shared storage in Account A in the organization.\n\nThe company wants to continue to use Amazon EFS with Lambda. Company policy requires all serverless projects to be deployed in Account B.\n\nA DevOps engineer needs to reconfigure an existing EFS file system to allow Lambda functions to access the data through an existing EFS access point.\n\nWhich combination of steps should the DevOps engineer take to meet these requirements? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 160,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 160 discussion",
    "answers": {
      "A": "Create a SysAdmin role in the operations account. Attach the AdministratorAccess policy to the role. Modify the trust relationship to allow the sts:AssumeRole action from the workload accounts.",
      "B": "Create a SysAdmin role in each workload account. Attach the AdministratorAccess policy to the role. Modify the trust relationship to allow the sts:AssumeRole action from the operations account.",
      "C": "Create an Amazon Cognito identity pool in the operations account. Attach the SysAdmin role as an authenticated role.",
      "D": "In the operations account, create an IAM user for each operations team member.",
      "E": "In the operations account, create an IAM user group that is named SysAdmins. Add an IAM policy that allows the sts:AssumeRole action for the SysAdmin role in each workload account. Add all operations team members to the group.",
      "F": "Create an Amazon Cognito user pool in the operations account. Create an Amazon Cognito user for each operations team member."
    },
    "suggested_answer": "BDE",
    "answer": "BDE",
    "link": "https://www.examtopics.com/discussions/amazon/view/95439-exam-aws-devops-engineer-professional-topic-1-question-160/",
    "multiple_choice": true,
    "question_text": "A company has an organization in AWS Organizations. The organization includes workload accounts that contain enterprise applications. The company centrally manages users from an operations account. No users can be created in the workload accounts. The company recently added an operations team and must provide the operations team members with administrator access to each workload account.\n\nWhich combination of actions will provide this access? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 161,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 161 discussion",
    "answers": {
      "A": "Create an AWS Config rule to detect stacks that do not have termination protection enabled. Add a remediation action to the rule to enable termination protection. Deploy the rule across the organization by using the PutOrganizationConfigRule API operation.",
      "B": "Create a CloudFormation template that deploys an AWS Config rule to detect stacks that do not have termination protection enabled. Add a remediation action to the rule to enable termination protection. Deploy the template to the OU of the production accounts by using CloudFormation StackSets.",
      "C": "Create an SCP that denies cloudformation:DeleteStack actions. Apply the SCP to the OU of the production accounts by using CloudFormation StackSets.",
      "D": "Create a CloudFormation stack policy that denies Update:Delete actions. Apply the policy to the OU of the production accounts by using CloudFormation StackSets."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/95434-exam-aws-devops-engineer-professional-topic-1-question-161/",
    "multiple_choice": false,
    "question_text": "A company's DevOps engineer manages an organization in AWS Organizations. The organization includes many accounts. The company needs all AWS CloudFormation stacks in production accounts to have termination protection enabled. Non-production accounts do not need termination protection.\n\nThe company has designated a centralized account for AWS Config aggregation and has configured all accounts to support the use of CloudFormation and AWS Config. The company also has grouped all production accounts into an OU.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 162,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 162 discussion",
    "answers": {
      "A": "Create a log group in Amazon CloudWatch Logs. Configure the VPC flow log to capture accepted traffic and to send the data to the log group. Create an Amazon CloudWatch metric filter for IP addresses on the deny list. Create a CloudWatch alarm with the metric filter as input. Set the period to 5 minutes and the datapoints to alarm to 1. Use an Amazon Simple Notification Service (Amazon SNS) topic to send alarm notices to the security team.",
      "B": "Create an Amazon S3 bucket for log files. Configure the VPC flow log to capture all traffic and to send the data to the S3 bucket. Configure Amazon Athena to return all log files in the S3 bucket for IP addresses on the deny list. Configure Amazon QuickSight to accept data from Athena and to publish the data as a dashboard that the security team can access. Create a threshold alert of 1 for successful access. Configure the alert to automatically notify the security team as frequently as possible when the alert threshold is met.",
      "C": "Create an Amazon S3 bucket for log files. Configure the VPC flow log to capture accepted traffic and to send the data to the S3 bucket. Configure an Amazon OpenSearch Service duster and domain for the log files. Create an AWS Lambda function to retrieve the logs from the S3 bucket, format the logs, and load the logs into the OpenSearch Service cluster. Schedule the Lambda function to run every 5 minutes. Configure an alert and condition in OpenSearch Service to send alerts to the security team through an Amazon Simple Notification Service (Amazon SNS) topic when access from the IP addresses on the deny list is detected.",
      "D": "Create a log group in Amazon CloudWatch Logs. Create an Amazon S3 bucket to hold query results. Configure the VPC flow log to capture all traffic and to send the data to the log group. Deploy an Amazon Athena CloudWatch connector in AWS Lambda. Connect the connector to the log group. Configure Athena to periodically query for all accepted traffic from the IP addresses on the deny list and to store the results in the S3 bucket. Configure an S3 event notification to automatically notify the security team through an Amazon Simple Notification Service (Amazon SNS) topic when new objects are added to the S3 bucket."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/95430-exam-aws-devops-engineer-professional-topic-1-question-162/",
    "multiple_choice": false,
    "question_text": "A company has deployed an application in a production VPC in a single AWS account. The application is popular and is experiencing heavy usage. The company's security team wants to add additional security, such as AWS WAF, to the application deployment. However, the application's product manager is concerned about cost and does not want to approve the change unless the security team can prove that additional security is necessary.\n\nThe security team believes that some of the application's demand might come from users that have IP addresses that are on a deny list. The security team provides the deny list to a DevOps engineer. If any of the IP addresses on the deny list access the application, the security team wants to receive automated notification in near real time so that the security team can document that the application needs additional security. The DevOps engineer creates a VPC flow log for the production VPC.\n\nWhich set of additional steps should the DevOps engineer take to meet these requirements MOST cost-effectively?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 163,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 163 discussion",
    "answers": {
      "A": "Enable Amazon CodeGuru Profiler. Decorate the handler function with @with_lambda_profiler(). Manually review the recommendation report. Write the secret to AWS Systems Manager Parameter Store as a secure string. Update the SAM templates and the Python code to pull the secret from Parameter Store.",
      "B": "Associate the CodeCommit repository with Amazon CodeGuru Reviewer. Manually check the code review for any recommendations. Choose the option to protect the secret. Update the SAM templates and the Python code to pull the secret from AWS Secrets Manager.",
      "C": "Enable Amazon CodeGuru Profiler. Decorate the handler function with @with lambda profiler(). Manually review the recommendation report. Choose the option to protect the secret. Update the SAM templates and the Python code to pull the secret from AWS Secrets Manager.",
      "D": "Associate the CodeCommit repository with Amazon CodeGuru Reviewer. Manually check the code review for any recommendations. Write the secret to AWS Systems Manager Parameter Store as a string. Update the SAM templates and the Python code to pull the secret from Parameter Store."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/95426-exam-aws-devops-engineer-professional-topic-1-question-163/",
    "multiple_choice": false,
    "question_text": "A company has developed a serverless web application that is hosted on AWS. The application consists of Amazon S3. Amazon API Gateway, several AWS Lambda functions, and an Amazon RDS for MySQL database. The company is using AWS CodeCommit to store the source code. The source code is a combination of AWS Serverless Application Model (AWS SAM) templates and Python code.\n\nA security audit and penetration test reveal that user names and passwords for authentication to the database are hardcoded within CodeCommit repositories. A DevOps engineer must implement a solution to automatically detect and prevent hardcoded secrets.\n\nWhat is the MOST secure solution that meets these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 164,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 164 discussion",
    "answers": {
      "A": "Create a target tracking auto scaling policy for the Redis cluster's ElastiCachePrimaryEngineCPUUtilization metric. Configure the auto scaling policy to increase and decrease shards to the Redis cluster. Update the recommendation applications to use the clusters configuration endpoint to access Redis.",
      "B": "Create a target tracking auto scaling policy for the Redis cluster's ElastiCachePrimaryEngineCPUUtilization metric. Configure the auto scaling policy to increase and decrease shards to the Redis cluster. Update the recommendation applications to use the cluster's read replica endpoint to access Redis.",
      "C": "Create a scheduled auto scaling policy for the Redis cluster's ElastiCachePrimaryEngineCPUUtilization metric. Configure the auto scaling policy to add read replicas to the Redis cluster. Update the recommendation applications to use the clusters configuration endpoint to access Redis.",
      "D": "Create a scheduled auto scaling policy for the Redis cluster's ElastiCachePrimaryEngineCPUUtilization metric. Configure the auto scaling policy to add read replicas to the Redis cluster. Update the recommendation applications to use the database's read replica endpoint instead of Redis."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/95748-exam-aws-devops-engineer-professional-topic-1-question-164/",
    "multiple_choice": false,
    "question_text": "A company has an application that monitors user activity on the company's website and mobile apps. The application uses Amazon ElastiCache for Redis as a write-through cache and uses an Amazon RDS for PostgreSQL database for longer storage. When the application receives a request to record a user's action, the application writes to the Redis cluster and the database at the same time. Internal recommendation applications consume the data to produce content recommendations for each user.\n\nDuring peak periods, the recommendation applications cannot generate recommendations for users because of stale and missing data. The Redis cache is configured with cluster mode turned off, and the database is configured with a single read replica.\n\nThe company wants to ensure that the recommendation applications can generate content recommendations during peak periods. A DevOps engineer already has created a new ElastiCache for Redis cluster with cluster mode enabled.\n\nWhat should the DevOps engineer do next to meet the company's requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 165,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 165 discussion",
    "answers": {
      "A": "Create an Amazon EventBridge event bus. Create a new Lambda function that uses the existing DynamoDB stream as an event source. Configure the new Lambda function to post those events to the event bus. Update the original Lambda functions to react to events in the event bus. As other applications need the events, configure the applications to use the event bus as an event source.",
      "B": "Create an Amazon Simple Queue Service (Amazon SOS) queue. Create a new Lambda function that uses the existing DynamoDB stream as an event source. Configure the new Lambda function to post those events to the SOS queue. Update the original Lambda functions to react to entries in the SOS queue. As other applications need the events, configure the applications to use the SOS queue as an event source.",
      "C": "Create an Amazon Kinesis data stream. Create a new Lambda function that uses the existing DynamoDB stream as an event source. Configure the new Lambda function to post those events to the Kinesis data stream. Update the original Lambda functions to subscribe to records in the Kinesis data stream. As other applications need the events, configure the applications to use the Kinesis data stream as an event source.",
      "D": "Configure the DynamoDB table to use on-demand capacity mode. Increase the memory of the Lambda functions. Configure the Lambda functions to use provisioned concurrency."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/95414-exam-aws-devops-engineer-professional-topic-1-question-165/",
    "multiple_choice": false,
    "question_text": "A company stores purchase history in an Amazon DynamoDB table. The company needs other workloads that run on AWS to react to data changes in the table.\n\nThe company has enabled a DynamoDB stream on the table. Three existing AWS Lambda functions have an event source mapping configured for the DynamoDB stream. The company's application developers plan to add other applications that will need to react to changes in the table. A DevOps engineer must design an architecture that will give the additional consumers this functionality.\n\nWhich solution will meet these requirements in the MOST operationally efficient way?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 166,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 166 discussion",
    "answers": {
      "A": "Integrate AWS Trusted Advisor with AWS Config. Configure a custom AWS Config rule to invoke an AWS Lambda function to publish notifications to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe a Slack channel endpoint and the shared inbox to the topic.",
      "B": "Use Amazon EventBridge to monitor for AWS Health events. Configure the maintenance events to target an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe an AWS Lambda function to the SNS topic to send notifications to the Slack channel and the shared inbox.",
      "C": "Create an AWS Lambda function that sends EC2 maintenance notifications to the Slack channel and the shared inbox. Monitor EC2 health events by using Amazon CloudWatch metrics. Configure a CloudWatch alarm that invokes the Lambda function when a maintenance notification is received.",
      "D": "Configure AWS Support integration with AWS CloudTrail. Create a CloudTrail lookup event to invoke an AWS Lambda function to pass EC2 maintenance notifications to Amazon Simple Notification Service (Amazon SNS). Configure Amazon SNS to target the Slack channel and the shared inbox."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/95413-exam-aws-devops-engineer-professional-topic-1-question-166/",
    "multiple_choice": false,
    "question_text": "A media company has several thousand Amazon EC2 instances in an AWS account. The company is using Slack and a shared email inbox for team communications and important updates. A DevOps engineer needs to send all AWS-scheduled EC2 maintenance notifications to the Slack channel and the shared inbox. The solution must include the instances' Name and Owner tags.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 167,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 167 discussion",
    "answers": {
      "A": "Copy data from the source database to Amazon S3 by using AWS DataSync. Configure AWS Lambda functions to copy the data to the target database. Configure Amazon CloudWatch alarms to monitor the Lambda functions for errors and throttles. Use an Amazon Simple Notification Service (Amazon SNS) topic for email notification.",
      "B": "Create Amazon CloudWatch alarms to monitor DMS replication task metrics and host metrics. Use an Amazon Simple Notification Service (Amazon SNS) topic for email notification and to invoke an AWS Lambda function to configure a standby DMS replication instance in a different AWS Region.",
      "C": "Create Amazon CloudWatch alarms to monitor DMS replication task metrics and host metrics. Use an Amazon Simple Notification Service (Amazon SNS) topic for email notification. After receiving the notification, configure a new DMS replication task in the same AWS Region.",
      "D": "Modify the DMS replication instance by tuming on Multi-AZ support. Create Amazon CloudWatch alarms to monitor DMS replication task metrics and host metrics. Use an Amazon Simple Notification Service (Amazon SNS) topic for email notification."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/95412-exam-aws-devops-engineer-professional-topic-1-question-167/",
    "multiple_choice": false,
    "question_text": "A company is using AWS Database Migration Service (AWS DMS) to replicate data from a source database in a data center to a target Amazon Aurora PostgreSQL database. The company has created a DMS replication task with change data capture (CDC).\n\nThe replication instance sometimes gets interrupted and affects critical functionality. The company must improve the replication instance's resiliency and receive notifications about interruptions.\n\nWhich solution will meet these requirements with the LEAST operational overhead?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 168,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 168 discussion",
    "answers": {
      "A": "Switch to a rolling deployment strategy for future application updates.",
      "B": "Switch to a rolling deployment with additional batch strategy for future application updates.",
      "C": "Switch to an immutable deployment strategy for future application updates.",
      "D": "Switch to a blue/green deployment strategy for future application updates."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/95375-exam-aws-devops-engineer-professional-topic-1-question-168/",
    "multiple_choice": false,
    "question_text": "A company has deployed an application on AWS Elastic Beanstalk by using an all-at-once deployment method. The deployment failed recently because of an application misconfiguration and resulted in significant downtime.\n\nTo prevent such downtime in the future, a DevOps engineer needs to revise the deployment method while maintaining the application performance. The DevOps engineer must ensure that application versions are consistently configured across all instances without creating new environments.\n\nWhich deployment solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 169,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 169 discussion",
    "answers": {
      "A": "Add the NAT instance to an EC2 Auto Scaling group that spans multiple Availability Zones. Update the route tables.",
      "B": "Create additional EC2 instances spanning multiple Availability Zones. Add an Application Load Balancer to split the load between them.",
      "C": "Configure an Application Load Balancer in front of the EC2 instance. Configure Amazon Cloud Watch alarms to recover the EC2 instance upon host failure.",
      "D": "Replace the NAT instance with a NAT gateway in each Availability Zone. Update the route tables.",
      "E": "Replace the NAT instance with a NAT gateway that spans multiple Availability Zones. Update the route tables."
    },
    "suggested_answer": "BD",
    "answer": "BD",
    "link": "https://www.examtopics.com/discussions/amazon/view/95050-exam-aws-devops-engineer-professional-topic-1-question-169/",
    "multiple_choice": true,
    "question_text": "A company requires that its internally facing web application be highly available. The architecture is made up of one Amazon EC2 web server instance and one NAT instance that provides outbound internet access for updates and accessing public data.\n\nWhich combination of architecture adjustments should the company implement to achieve high availability? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 170,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 170 discussion",
    "answers": {
      "A": "Configure the unified Amazon CloudWatch agent on the EC2 instances to publish the application logs files to a CloudWatch log group. Configure a metric filter on the CloudWatch log group to detect the critical errors and to create a custom metric. Create an Amazon Simple Notification Service (Amazon SNS) topic. Configure a CloudWatch alarm to use the custom metric to notify the SNS topic. Subscribe the application team's email address to the SNS topic.",
      "B": "Install the Amazon Kinesis agent on the EC2 instances. Configure the Kinesis agent with the location of the log files. Stream the logs to a Kinesis Data Firehose delivery stream with an Amazon CloudWatch metrics stream as a destination. Configure an AWS Lambda function to detect the error message and to create a custom metric. Associate the Lambda function with the stream. Create an Amazon Simple Notification Service (Amazon SNS) topic. Configure a CloudWatch alarm to use the custom metric to notify the SNS topic. Subscribe the application team's email address to the SNS topic.",
      "C": "Install the AWS X-Ray daemon on the EC2 instances. Instrument the application with the AWS Distro for OpenTelemetry (ADOT). Configure the ADOT collector with the location of the custom log files and the name of an Amazon CloudWatch log group. Use the CloudWatch embedded metric format to generate a custom metric that is based on the error message. Create an Amazon Simple Notification Service (Amazon SNS) topic. Configure a CloudWatch alarm to use the custom metric to notify the SNS topic. Subscribe the application team's email address to the SNS topic.",
      "D": "Configure the unified Amazon CloudWatch agent on the EC2 instances to publish the application logs files to a CloudWatch log group. Create an Amazon OpenSearch Service domain. Subscribe the CloudWatch log group to the OpenSearch Service domain. Create an Amazon Simple Notification Service (Amazon SNS) topic. Configure an OpenSearch Service alert monitor to notify the SNS topic. Subscribe the application team's email address to the SNS topic."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/95410-exam-aws-devops-engineer-professional-topic-1-question-170/",
    "multiple_choice": false,
    "question_text": "A company is running an application on Amazon EC2 instances. A DevOps engineer needs to aggregate the application logs to a central system for the company's application team to search. A critical error message periodically appears in the log files. The DevOps engineer needs to notify the application team by email when these error messages occur.\n\nWhich solution will meet these requirements in the MOST operationally efficient manner?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 171,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 171 discussion",
    "answers": {
      "A": "Increase the read capacity of the DynamoDB table. Use AWS Application Auto Scaling to manage provisioned concurrency for the Lambda function.",
      "B": "Enable caching in API Gateway. Stop using provisioned concurrency for the Lambda function.",
      "C": "Delete the DAX cluster for the DynamoDB table. Use AWS Application Auto Scaling to manage provisioned concurrency for the Lambda function.",
      "D": "Enable caching in API Gateway. Use AWS Application Auto Scaling to manage provisioned concurrency for the Lambda function"
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/95409-exam-aws-devops-engineer-professional-topic-1-question-171/",
    "multiple_choice": false,
    "question_text": "A company has deployed a new Amazon API Gateway API that retrieves the cost of items for the company's online store. An AWS Lambda function supports the API and retrieves the data from an Amazon DynamoDB table. The API's latency increases during times of peak usage each day. However, the latency of the DynamoDB table reads is constant throughout the day.\n\nA DevOps engineer configures DynamoDB Accelerator (DAX) for the DynamoDB table, and the API latency decreases throughout the day. The DevOps engineer then configures Lambda provisioned concurrency with a limit of two concurrent invocations. This change reduces the latency during normal usage. However, the company is still experiencing higher latency during times of peak usage than during times of normal usage.\n\nWhich set of additional steps should the DevOps engineer take to produce the LARGEST decrease in API latency?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 172,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 172 discussion",
    "answers": {
      "A": "Use the cfn-signal helper script to signal success or failure to CloudFormation. Use the WaitOnResourceSignals update policy within the CloudFormation template. Set an appropriate timeout for the update policy.",
      "B": "Create an Amazon CloudWatch alarm for the UnhealthyHostCount metric. Include an appropriate alarm threshold for the target group. Create an Amazon Simple Notification Service (Amazon SNS) topic as the target to signal success or failure to CloudFormation.",
      "C": "Create a lifecycle hook on the Auto Scaling group by using the AWS::AutoScaling::LifecycleHook resource. Create an Amazon Simple Notification Service (Amazon SNS) topic as the target to signal success or failure to CloudFormation. Set an appropriate timeout on the lifecycle hook.",
      "D": "Use the Amazon CloudWatch agent to stream the cloud-init logs. Create a subscription filter that includes an AWS Lambda function with an appropriate invocation timeout. Configure the Lambda function to use the SignalResource API operation to signal success or failure to CloudFormation."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/95408-exam-aws-devops-engineer-professional-topic-1-question-172/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer has implemented a Cl/CD pipeline to deploy an AWS CloudFormation template that provisions a web application. The web application consists of an Application Load Balancer (ALB), a target group, a launch template that uses an Amazon Linux 2 AMI, an Auto Scaling group of Amazon EC2 instances, a security group, and an Amazon RDS for MySOL database. The launch template includes user data that specifies a script to install and start the application.\n\nThe initial deployment of the application was successful. The DevOps engineer made changes to update the version of the application with the user data. The CI/CD pipeline has deployed a new version of the template. However, the health checks on the ALB are now failing. The health checks have marked all targets as unhealthy.\n\nDuring investigation, the DevOps engineer notices that the CloudFormation stack has a status of UPDATE_COMPLETE. However, when the DevOps engineer connects to one of the EC2 instances and checks /var/log/messages, the DevOps engineer notices that the Apache web server failed to start successfully because of a configuration error.\n\nHow can the DevOps engineer ensure that the CloudFormation deployment will fail if the user data fails to successfully finish running?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 173,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 173 discussion",
    "answers": {
      "A": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule to send notifications to the security team whenever a user logs in to an EC2 instance. Use EC2 Instance Connect to log in to the instances. Deploy Auto Scaling groups by using AWS CloudFormation. Use the cfn-init helper script to deploy appropriate VPC routes for external access. Rebuild the custom AMI so that the custom AMI includes AWS Systems Manager Agent.",
      "B": "Deploy a NAT gateway and a bastion host that has internet access. Create a security group that allows incoming traffic on all the EC2 instances from the bastion host. Install AWS Systems Manager Agent on all the EC2 instances. Use Auto Scaling group lifecycle hooks for monitoring and auditing access. Use Systems Manager Session Manager to log in to the instances. Send logs to a log group in Amazon CloudWatch Logs. Export data to Amazon 83 for auditing. Send notifications to the security team by using S3 event notifications.",
      "C": "Use EC2 Image Builder to rebuild the custom AMI. Include the most recent version of AWS Systems Manager Agent in the image. Configure the Auto Scaling group to attach the AmazonSSMManagedlnstanceCore role to all the EC2 instances. Use Systems Manager Session Manager to log in to the instances. Enable logging of session details to Amazon S3. Create an S3 notification for new file uploads to send a message to the security team through an Amazon Simple Notification Service (Amazon SNS) topic.",
      "D": "Use AWS Systems Manager Automation to build Systems Manager Agent into the custom AMI. Configure AWS Config to attach an SCP to the root organization account to allow the EC2 instances to connect to Systems Manager. Use Systems Manager Session Manager to log in to the instances. Enable logging of session details to Amazon S3. Create an S3 notification for new file uploads to send a message to the security team through an Amazon Simple Notification Service (Amazon SNS) topic."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/95406-exam-aws-devops-engineer-professional-topic-1-question-173/",
    "multiple_choice": false,
    "question_text": "A company has a data ingestion application that runs across multiple AWS accounts. The accounts are in an organization in AWS Organizations. The company needs to monitor the application and consolidate access to the application. Currently, the company is running the application on Amazon EC2 instances from several Auto Scaling groups. The EC2 instances have no access to the internet because the data is sensitive. Engineers have deployed the necessary VPC endpoints. The EC2 instances run a custom AMI that is built specifically for the application.\n\nTo maintain and troubleshoot the application, system administrators need the ability to log in to the EC2 instances. This access must be automated and controlled centrally. The company's security team must receive a notification whenever the instances are accessed.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 174,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 174 discussion",
    "answers": {
      "A": "The CodePipeline IAM service role does not have the required IAM permissions to use Parameter Store.",
      "B": "The CodePipeline IAM service role does not have the required IAM permissions to use the aws/ssm KMS key.",
      "C": "The CodeBuild IAM service role does not have the required IAM permissions to use Parameter Store.",
      "D": "The CodeBuild IAM service role does not have the required IAM permissions to use the aws/ssm KMS key."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/95405-exam-aws-devops-engineer-professional-topic-1-question-174/",
    "multiple_choice": false,
    "question_text": "During the next CodePipeline run, the pipeline exits with a FAILED state during the build stage. The DevOps engineer verifies that the correct Systems Manager parameter path is in place for the environment variable values that were changed. The DevOps engineer also validates that the environment variable type is Parameter.\n\nWhy did the pipeline fail?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 175,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 175 discussion",
    "answers": {
      "A": "",
      "B": "",
      "C": "",
      "D": ""
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/95038-exam-aws-devops-engineer-professional-topic-1-question-175/",
    "multiple_choice": false,
    "question_text": "A company has multiple AWS accounts. The company uses AWS Single Sign-On (AWS SSO) that is integrated with AWS Toolkit for Microsoft Azure DevOps. The attributes for access control feature is enabled in AWS SSO.\n\nThe attribute mapping list contains two entries. The department key is mapped to ${path:enterprise.department}. The costCenter key is mapped to ${path:enterprise.costCenter}.\n\nAll existing Amazon EC2 instances have a department tag that corresponds to three company departments (d1, d2, d3). A DevOps engineer must create policies based on the matching attributes. The policies must minimize administrative effort and must grant each Azure AD user access to only the EC2 instances that are tagged with the user's respective department name.\n\nWhich condition key should the DevOps engineer include in the custom permissions policies to meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 176,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 176 discussion",
    "answers": {
      "A": "Create a CodePipeline action immediately after the deployment stage of the API. Configure the action to invoke an AWS Lambda function. Configure the Lambda function to download the SDK from API Gateway, upload the SDK to the S3 bucket, and create a CloudFront invalidation for the SDK path.",
      "B": "Create a CodePipeline action immediately after the deployment stage of the API. Configure the action to use the CodePipeline integration with API Gateway to export the SDK to Amazon S3. Create another action that uses the CodePipeline integration with Amazon S3 to invalidate the cache for the SDK path.",
      "C": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule that reacts to UpdateStage events from aws.apigateway. Configure the rule to invoke an AWS Lambda function to download the SDK from API Gateway, upload the SDK to the S3 bucket, and call the CloudFront API to create an invalidation for the SDK path.",
      "D": "Create an Amazon EventBridge (Amazon CloudWatch Events) rule that reacts to CreateDeployment events from aws.apigateway. Configure the rule to invoke an AWS Lambda function to download the SDK from API Gateway, upload the SDK to the S3 bucket, and call the S3 API to invalidate the cache for the SDK path."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/95692-exam-aws-devops-engineer-professional-topic-1-question-176/",
    "multiple_choice": false,
    "question_text": "A company deploys updates to its Amazon API Gateway API several times a week by using an AWS CodePipeline pipeline. As part of the update process, the company exports the JavaScript SDK for the API from the API Gateway console and uploads the SDK to an Amazon S3 bucket.\n\nThe company has configured an Amazon CloudFront distribution that uses the S3 bucket as an origin. Web clients then download the SDK by using the CloudFront distribution's endpoint. A DevOps engineer needs to implement a solution to make the new SDK available automatically during new API deployments.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 177,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 177 discussion",
    "answers": {
      "A": "Configure an Amazon EventBridge (Amazon CloudWatch Events) rule that reacts to EC2 RunInstances API calls. Configure the rule to invoke an AWS Lambda function to attach the default instance profile to the EC2 instances.",
      "B": "Configure the ec2-instance-profile-attached AWS Config managed rule with a trigger type of configuration changes. Configure an automatic remediation action that invokes an AWS Systems Manager Automation runbook to attach the default instance profile to the EC2 instances.",
      "C": "Configure an Amazon EventBridge (Amazon CloudWatch Events) rule that reacts to EC2 Startlnstances API calls. Configure the rule to invoke an AWS Systems Manager Automation runbook to attach the default instance profile to the EC2 instances.",
      "D": "Configure the iam-role-managed-policy-check AWS Config managed rule with a trigger type of configuration changes. Configure an automatic remediation action that invokes an AWS Lambda function to attach the default instance profile to the EC2 instances."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/95358-exam-aws-devops-engineer-professional-topic-1-question-177/",
    "multiple_choice": false,
    "question_text": "A company has a single AWS account that runs hundreds of Amazon EC2 instances in a single AWS Region. New EC2 instances are launched and terminated each hour in the account. The account also includes existing EC2 instances that have been running for longer than a week.\n\nThe company's security policy requires all running EC2 instances to use an EC2 instance profile. If an EC2 instance does not have an instance profile attached, the EC2 instance must use a default instance profile that has no IAM permissions assigned.\n\nA DevOps engineer reviews the account and discovers EC2 instances that are running without an instance profile. During the review, the DevOps engineer also observes that new EC2 instances are being launched without an instance profile.\n\nWhich solution will ensure that an instance profile is attached to all existing and future EC2 instances in the Region?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 178,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 178 discussion",
    "answers": {
      "A": "Configure an Amazon EventBridge (Amazon CloudWatch Events) rule that detects GuardDuty findings. Use an input transformer to detect high-severity event patterns. Configure the rule to publish a message to the SNS topic.",
      "B": "Configure an Amazon EventBridge (Amazon CloudWatch Events) rule that detects noncompliance with the guardduty-non-archived-findings AWS Config managed rule for high-severity GuardDuty findings. Configure the EventBridge (CloudWatch Events) rule to publish a message to the SNS topic.",
      "C": "Configure an Amazon EventBridge (Amazon CloudWatch Events) rule with an event pattern that matches GuardDuty ListFindings API calls with a high severity level. Configure the rule to publish a message to the SNS topic.",
      "D": "Configure an Amazon EventBridge (Amazon CloudWatch Events) rule with an event pattern that matches GuardOuty findings that have a high severity level within the event. Configure the rule to publish a message to the SNS topic."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/95029-exam-aws-devops-engineer-professional-topic-1-question-178/",
    "multiple_choice": false,
    "question_text": "A company has a single AWS account where active development occurs. The company's security team has implemented Amazon GuardDuty, AWS Config, and AWS CloudTrail within the account. The security team wants to receive notifications in near real time for only high-severity findings from GuardDuty. The security team uses an Amazon Simple Notification Service (Amazon SNS) topic for notifications from other security tools in the account.\n\nHow can a DevOps engineer meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 179,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 179 discussion",
    "answers": {
      "A": "Create an Amazon EventBridge rule that runs daily and invokes an AWS Lambda function. Configure the Lambda function to retrieve the most recent list of external IP ranges from the S3 bucket. For each IP range in the list, configure the Lambda function to create a GuardDuty finding filter on the publicIp filter attribute.",
      "B": "Configure a threat list in GuardDuty. Set the source as the list of external IP ranges in the S3 bucket. Create an Amazon EventBridge rule that runs daily and invokes an AWS Lambda function. Configure the Lambda function to refresh the threat list in GuardDuty to match the list of external IP ranges in the S3 bucket.",
      "C": "Configure a trusted IP list in GuardDuty. Set the source as the list of external IP ranges in the S3 bucket. Create an Amazon EventBridge rule that runs daily and invokes an AWS Lambda function. Configure the Lambda function to refresh the trusted IP list in GuardDuty to match the list of external IP ranges in the S3 bucket.",
      "D": "Create an Amazon EventBridge rule that runs daily and invokes an AWS Lambda function. Configure the Lambda function to retrieve the most recent list of external IP ranges from the S3 bucket. For each IP range in the list, configure the Lambda function to create a GuardDuty finding filter on the localIp filter attribute."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/100642-exam-aws-devops-engineer-professional-topic-1-question-179/",
    "multiple_choice": false,
    "question_text": "A company has a VPC that consists of a public subnet and a private subnet. The company has an application that runs on Amazon EC2 instances that are in the private subnet. An Application Load Balancer is in the public subnet and distributes traffic to the EC2 instances.\n\nThe company has enabled Amazon GuardDuty for the account. The company’s DevOps team has a list of external IP ranges that is updated each day. The list is stored in an Amazon S3 bucket in the account. A DevOps engineer needs to configure GuardDuty to create a GuardDuty finding when traffic to the application originates from an IP range in the external IP range list.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 180,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 180 discussion",
    "answers": {
      "A": "Enable caching for API Gateway stages. Use DynamoDB Accelerator (DAX) for the DynamoDB table.",
      "B": "Enable caching tor API Gateway stages. Use Amazon ElastiCache for Memcached caching for the DynamoDB table.",
      "C": "Use provisioned concurrency for the Lambda function. Use DynamoDB Accelerator (DAX) for the DynamoDB table.",
      "D": "Use provisioned concurrency for the Lambda function. Increase the RCUs for the DynamoDB table."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/100498-exam-aws-devops-engineer-professional-topic-1-question-180/",
    "multiple_choice": false,
    "question_text": "A company is using an Amazon API Gateway API and an AWS Lambda function to host a microservice. The microservice accesses pricing data in an Amazon DynamoDB table for the company’s online store.\n\nInterest in the online store has increased. As a result, latency issues and throttling on the DynamoDB table are occurring when a specific query runs. Some internal services access the DynamoDB table directly. No caching is enabled for the current solution.\n\nA DevOps engineer notices that repeat requests to the API are taking the same amount of time as unique requests. The DevOps engineer must reduce the latency for the repeat requests to the API and must reduce the throttling on the DynamoDB table.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 181,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 181 discussion",
    "answers": {
      "A": "Create a CloudWatch Logs subscription to an AWS Step Functions application. Configure an AWS Lambda function to add a tag to the EC2 instance that produced the login event and mark the instance to be decommissioned. Create an Amazon EventBridge rule to invoke a second Lambda function once a day that will terminate all instances with this tag.",
      "B": "Create an Amazon CloudWatch alarm that will be invoked by the login event. Send the notification to an Amazon Simple Notification Service (Amazon SNS) topic that the operations team is subscribed to, and have them terminate the EC2 instance within 24 hours.",
      "C": "Create an Amazon CloudWatch alarm that will be invoked by the login event. Configure the alarm to send to an Amazon Simple Queue Service (Amazon SQS) queue. Use a group of worker instances to process messages from the queue, which then schedules an Amazon EvantBridge rule to be invoked.",
      "D": "Create a CloudWatch Logs subscription in an AWS Lambda function. Configure the function to add a tag to the EC2 instance that produced the login event and mark the instance to be decommissioned. Create an Amazon EventBridge rule to invoke a daily Lambda function that terminates all instances with this tag."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/100637-exam-aws-devops-engineer-professional-topic-1-question-181/",
    "multiple_choice": false,
    "question_text": "A production account has a requirement that any Amazon EC2 instance that has been logged in to manually must be terminated within 24 hours. All applications in the production account are using Auto Scaling groups with the Amazon CloudWatch Logs agent configured.\n\nHow can this process be automated?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 182,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 182 discussion",
    "answers": {
      "A": "Create an AWS Lambda function to scan the images in each repository for the number of versions present. Configure the Lambda function to delete older versions of images if the number of images is greater than the desired number of images. Schedule the Lambda function to run automatically at regular intervals,",
      "B": "Create a repository policy that assesses the number of images and deletes older versions if the number of images is greater than the desired number of images. Apply the repository policy to each private repository.",
      "C": "Create an AWS Step Functions state machine Express Workflow to scan the images in each repository for the number of versions present. Configure the Express Workflow to delete older versions of images if the number of images is greater than the desired number of images. Configure the state machine to run every time an image is pushed to a repository.",
      "D": "Push an image into each private repository. In each private repository, create a lifecycle policy preview to delete older versions of images if the number of images is greater than the desired number of images. Test the lifecycle policy and validate the impact. Apply the lifecycle policy to manage the images."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/100639-exam-aws-devops-engineer-professional-topic-1-question-182/",
    "multiple_choice": false,
    "question_text": "A company is migrating Docker repositories to Amazon Elastic Container Registry (Amazon ECR) in an existing AWS account. A DevOps engineer needs to automate the management of images that are uploaded to the repositories. The solution must limit the number of image versions. As a first step, the DevOps engineer creates a private repository in Amazon ECR for each repository that the company will migrate.\n\nWhat should the DevOps engineer do next to meet the requirements in the MOST operationally efficient manner?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 183,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 183 discussion",
    "answers": {
      "A": "Update the UserData attribute to use the cfn-signal helper script.",
      "B": "Update the AutoScalingGroup resource with a DependsOn LaunchConfig.",
      "C": "Update the LaunchConfig resource type to AWS::EC2::LaunchTemplate.",
      "D": "Increase the CreationPolicy ResourceSignal Timeout.",
      "E": "Remove the CreationPolicy attribute. Create new WaitHandle and WaitCondition resources."
    },
    "suggested_answer": "AD",
    "answer": "AD",
    "link": "https://www.examtopics.com/discussions/amazon/view/100640-exam-aws-devops-engineer-professional-topic-1-question-183/",
    "multiple_choice": true,
    "question_text": "A DevOps engineer has created an AWS CloudFormation template. The template includes the following snippet:\n\n//IMG//\n\n\nWhen the template is launched, CloudFormation performs a rollback and reports the following error message: Received 0 SUCCESS signal(s) cut of 1.\n\nWhich combination of steps should the DevOps engineer take to resolve this error? (Choose two.)",
    "answer_images": [],
    "question_images": [
      "https://img.examtopics.com/aws-devops-engineer-professional/image6.png"
    ]
  },
  {
    "topic_number": 1,
    "question_number": 184,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 184 discussion",
    "answers": {
      "A": "Create an S3 event notification to invoke an AWS Lambda function when the license file is updated in the S3 bucket. Configure the Lambda function to invoke AWS Systems Manager Run Command to run the AWS-RunRemoteScript document to download the updated license file. Specify the command from Lambda to run on the application's resource group with 50% concurrency. Configure Amazon Simple Email Service (Amazon SES) notifications for event notifications of SUCCESS and FAILED to send email notifications to the operations team.",
      "B": "Create an S3 event notification to invoke an AWS Lambda function when the license file is updated in the S3 bucket. Configure the Lambda function to invoke AWS Systems Manager Run Command to run the AWS-RunPowerShellScript document to download the updated license file. Specify the command from Lambda to run on the application's resource group with 50% concurrency. Configure an Amazon Simple Notification Service (Amazon SNS) topic to send event notifications of SUCCESS and FAILED. Subscribe the email addresses of the operations team members to the SNS topic.",
      "C": "Create an Amazon EventBridge scheduled rule that runs each hour to invoke an AWS Lambda function. Configure the Lambda function to invoke AWS Systems Manager Run Command to run the AWS-RunPowerShellScript document to download the updated license file. Specify the command from Lambda to run on the application's resource group with 50% concurrency. Configure an Amazon Simple Notification Service (Amazon SNS) topic to send event notifications of SUCCESS and FAILED. Subscribe the email addresses of the operations team members to the SNS topic.",
      "D": "Create an Amazon EventBridge scheduled rule that runs each hour to invoke an AWS Lambda function. Configure the Lambda function to invoke AWS Systems Manager Run Command to run the AWS-RunRemoteScript document to download the updated license file. Specify the command from Lambda to run on the application's resource group with 50% concurrency. Configure Amazon Simple Email Service (Amazon SES) notifications for event notifications of SUCCESS and FAILED to send email notifications to the operations team."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/100500-exam-aws-devops-engineer-professional-topic-1-question-184/",
    "multiple_choice": false,
    "question_text": "A company hosts a multi-tenant application on Amazon EC2 instances behind an Application Load Balancer. The instances run Windows Server and are in an Auto Scaling group. The application uses a license file on the instances that can be updated on the instances without customer disruption. When a new customer purchases access to the application, the company's licensing team adds a new license key to a file in an Amazon S3 bucket. After the license file is updated, the operations team manually updates the EC2 instances.\n\nA DevOps engineer needs to automate the EC2 instance file update process. The automated process must decrease the time for EC2 instances to get the updated license file and must notify the operations team about success or failure of the update process.\n\nThe DevOps engineer creates a resource group in AWS Resource Groups. The resource group uses a tag that the Auto Sealing group applies to the EC2 instances.\n\nWhat should the DevOps engineer do next to meet the requirements MOST cost-effectively?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 185,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 185 discussion",
    "answers": {
      "A": "Ensure that the AWS Region is the same for the stack sets and the target resources.",
      "B": "Ensure that the delegated administrator account has a trust relationship with the target account.",
      "C": "Ensure that the resources in the stacks do not have termination protection enabled by default.",
      "D": "Ensure that the CloudFormation template is creating unique global resources.",
      "E": "Deploy the stack sets from the management account and not from the delegated administrator account."
    },
    "suggested_answer": "BD",
    "answer": "BD",
    "link": "https://www.examtopics.com/discussions/amazon/view/100643-exam-aws-devops-engineer-professional-topic-1-question-185/",
    "multiple_choice": true,
    "question_text": "A company uses AWS Organizations to manage its AWS accounts. A DevOps engineer wants to deploy a new AWS Lambda function to all accounts in the organization by using AWS CloudFormation StackSets. The DevOps engineer uses a delegated administrator account to deploy the stack sets to the member accounts. The stack operation keeps failing, and the stack instance status is OUTDATED.\n\nWhich actions should the DevOps engineer take to remediate this error? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 186,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 186 discussion",
    "answers": {
      "A": "Create a landing zone in the security OU of the large company's AWS Control Tower landing zone. Provide the account's email address, the account owners first and last name, and the name of the landing zone created in the security OU to complete the AWS Control Tower Account Factory enrollment request.",
      "B": "Create and apply SCPs in the destination OU to restrict the types of resources that can be created in the small company’s account. Assess the impact of the applied SCPs on the small company's account. Delete existing SCPs in the small company’s account.",
      "C": "Create an AWS Config conformance pack that contains the policies that are currently applied to the large company's account. Use AWS Config to assess the impact that enrollment in AWS Control Tower will have on the small company's account. Delete the configuration recorder and delivery channels from the AWS Config settings of the small company's account.",
      "D": "Enroll the OU of the small company's account in the large company’s AWS Control Tower environment. Specify the destination OU in the large company's AWS Control Tower landing zone as the receiving OU in the request.",
      "E": "Create an AWSControlTowerExecution role in the small company's account. Provide the account's email address, the account owner's first and last name, and the destination OU to complete the AWS Control Tower Account Factory enrollment request."
    },
    "suggested_answer": "BE",
    "answer": "BE",
    "link": "https://www.examtopics.com/discussions/amazon/view/100698-exam-aws-devops-engineer-professional-topic-1-question-186/",
    "multiple_choice": true,
    "question_text": "A large company has acquired a small company. The large company has an organization in AWS Organizations. The large company needs to integrate the small company’s single AWS account into the organization with minimal impact to the applications that are deployed in the small company's account.\n\nThe large company has deployed AWS Control Tower in its organization and wants to enroll the small company’s account in AWS Control Tower. The large company’s AWS Control Tower configuration includes a security OU, a sandbox OU, and a new destination OU that is set up for the small company's migration. Each company is using AWS Config as part of its account management strategy.\n\nWhich combination of steps should a DevOps engineer take lo meet these requirements? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 187,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 187 discussion",
    "answers": {
      "A": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the email addresses of all operations team members to the SNS topic. Apply a notification configuration for the autoscaling:EC2_INSTANCE_LAUNCH notification type to all the existing Auto Scaling groups.",
      "B": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Add an AWS Lambda function trigger to the SQS queue. Apply a notification configuration for the autoscaling:EC2_INSTANCE_LAUNCH notification type to all the existing Auto Scaling groups.",
      "C": "Create an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe the email addresses of all operations team members to the SNS topic. Apply a notification configuration for the autoscaling:EC2_INSTANCE_TERMINATE notification type to all the existing Auto Scaling groups.",
      "D": "Create an Amazon Simple Queue Service (Amazon SQS) queue. Add an AWS Lambda function trigger to the SQS queue. Apply a notification configuration for the autoscaling:EC2_INSTANCE_TERMINATE notification type to all the existing Auto Scaling groups."
    },
    "suggested_answer": "C",
    "answer": "C",
    "link": "https://www.examtopics.com/discussions/amazon/view/100645-exam-aws-devops-engineer-professional-topic-1-question-187/",
    "multiple_choice": false,
    "question_text": "A software-as-a-service (SaaS) company is using AWS Elastic Beanstalk to deploy its primary .NET application. The Elastic Beanstalk environment is configured to use Amazon EC2 Auto Scaling and Elastic Load Balancing (ELB) for its underlying Amazon EC2 instances.\n\nThe company is experiencing incidents in which EC2 instances are marked unhealthy and are terminated by Auto Scaling groups after a failed ELB health check. The company's DevOps team must build a solution that will notify the operations team whenever an Auto Scaling group terminates EC2 instances for any existing client environments.\n\nWhat should the DevOps team do to meet this requirement?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 188,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 188 discussion",
    "answers": {
      "A": "In both regions, deploy the application on AWS Elastic Beanstalk and use Amazon DynamoDB global tables for session data. Use an Amazon Route 53 weighted routing policy with health checks to distribute the traffic across the regions.",
      "B": "In both regions, launch the application in Auto Scaling groups and use DynamoDB for session data. Use a Route 53 failover routing policy with health checks to distribute the traffic across the regions.",
      "C": "In both regions, deploy the application in AWS Lambda, exposed by Amazon API Gateway, and use Amazon RDS PostgreSQL with cross-region replication for session data. Deploy the web application with client-side logic to call the API Gateway directly.",
      "D": "In both regions, launch the application in Auto Scaling groups and use DynamoDB global tables for session data. Enable an Amazon CloudFront weighted distribution across regions. Point the Amazon Route 53 DNS record at the CloudFront distribution."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/101271-exam-aws-devops-engineer-professional-topic-1-question-188/",
    "multiple_choice": false,
    "question_text": "A company is hosting a web application in an AWS Region. For disaster recovery purposes, a second region is being used as a standby. Disaster recovery requirements state that session data must be replicated between regions in near-real time and 1% of requests should route to the secondary region to continuously verify system functionality. Additionally, if there is a disruption in service in the main region, traffic should be automatically routed to the secondary region, and the secondary region must be able to scale up to handle all traffic.\n\nHow should a DevOps engineer meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 189,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 189 discussion",
    "answers": {
      "A": "Download the Amazon CloudWatch Logs container instance from AWS. Configure this instance as a task. Update the application service definitions to include the logging task",
      "B": "Install the Amazon CloudWatch Logs agent on the ECS instances. Change the logging driver in the ECS task definition to awslogs.",
      "C": "Use Amazon EventBridge to schedule an AWS Lambda function that will run every 60 seconds and will run the Amazon CloudWatch Logs create-export-task command. Then point the output to the logging S3 bucket.",
      "D": "Activate access logging on the ALB. Then point the ALB directly to the logging S3 bucket.",
      "E": "Activate access logging on the target groups that the ECS services use. Then send the logs directly to the logging S3 bucket.",
      "F": "Create an Amazon Kinesis Data Firehose delivery stream that has a destination of the logging S3 bucket. Then create an Amazon CloudWatch Logs subscription filter for Kinesis Data Firehose."
    },
    "suggested_answer": "BDF",
    "answer": "BDF",
    "link": "https://www.examtopics.com/discussions/amazon/view/101272-exam-aws-devops-engineer-professional-topic-1-question-189/",
    "multiple_choice": true,
    "question_text": "A company is implementing an Amazon Elastic Container Service (Amazon ECS) cluster to run its workload. The company architecture will run multiple ECS services on the cluster. The architecture includes an Application Load Balancer on the front end and uses multiple target groups to route traffic.\n\nA DevOps engineer must collect application and access logs. The DevOps engineer then needs to send the logs to an Amazon S3 bucket for near-real-time analysis.\n\nWhich combination of steps must the DevOps engineer take to meet these requirements? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 190,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 190 discussion",
    "answers": {
      "A": "Deletion has failed because the S3 bucket has an active website configuration. Modify the CloudFormation template to remove the WebsiteConfiguration property from the S3 bucket resource",
      "B": "Deletion has failed because the S3 bucket is not empty. Modify the custom resource's AWS Lambda function code to recursively empty the bucket when RequestType is Delete.",
      "C": "Deletion has failed because the custom resource does not define a deletion policy. Add a DeletionPolicy property to the custom resource definition with a value of RemoveOnDeletion.",
      "D": "Deletion has failed because the S3 bucket is not empty. Modify the S3 bucket resource in the CloudFormation template to add a DeletionPolicy property with a value of Empty."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/101273-exam-aws-devops-engineer-professional-topic-1-question-190/",
    "multiple_choice": false,
    "question_text": "A company has developed a static website hosted on an Amazon S3 bucket. The website is deployed using AWS CloudFormation. The Cloud Formation template defines an S3 bucket and a custom resource that copies content into the bucket from a source location.\n\nThe company has decided that it needs to move the website to a new location, so the existing CloudFormation stack must be deleted and re-created. However, CloudFormation reports that the stack could not be deleted cleanly.\n\nWhat is the MOST likely cause and how can the DevOps engineer mitigate this problem for this and future versions of the website?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 191,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 191 discussion",
    "answers": {
      "A": "Add the following conditional expression:",
      "B": "Change “Resource”: “*” to “Resource”: “arn:aws:ec2:*:*:instance/*”",
      "C": "Add the following conditional expression:",
      "D": "Add the following conditional expression:",
      "E": "Change “Action”: “ec2:*” to “Action”: “ec2:StopInstances”",
      "F": "Add the following conditional expression:"
    },
    "suggested_answer": "BDE",
    "answer": "BDE",
    "link": "https://www.examtopics.com/discussions/amazon/view/101263-exam-aws-devops-engineer-professional-topic-1-question-191/",
    "multiple_choice": true,
    "question_text": "A company is reviewing its IAM policies. One policy written by the DevOps engineer has been flagged as too permissive. The policy is used by an AWS Lambda function that issues a stop command to Amazon EC2 instances tagged with Environment: NonProduction over the weekend. The current policy is:\n\n//IMG//\n\n\nWhat changes should the engineer make to achieve a policy of least permission? (Choose three.)",
    "answer_images": [],
    "question_images": [
      "https://img.examtopics.com/aws-devops-engineer-professional/image7.png"
    ]
  },
  {
    "topic_number": 1,
    "question_number": 192,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 192 discussion",
    "answers": {
      "A": "Attach the AWSCIoudFormationFullAccess IAM policy to the AWS CloudFormation role.",
      "B": "Automatically recover the stack resources by using AWS CloudFormation drift detection.",
      "C": "Issue a ContinueUpdateRollback command from the AWS CloudFormation console or the AWS CLI.",
      "D": "Manually adjust the resources to match the expectations of the stack.",
      "E": "Update the existing AWS CloudFormation stack by using the original template."
    },
    "suggested_answer": "CD",
    "answer": "CD",
    "link": "https://www.examtopics.com/discussions/amazon/view/101275-exam-aws-devops-engineer-professional-topic-1-question-192/",
    "multiple_choice": true,
    "question_text": "A company updated the AWS CloudFormation template for a critical business application. The stack update process failed due to an error in the updated template, and AWS CloudFormation automatically began the stack rollback process. Later, a DevOps engineer discovered that the application was still unavailable and that the stack was in the UPDATE_ROLLBACK_FAILED state.\n\nWhich combination of actions should the DevOps engineer perform so that the stack rollback can complete successfully? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 193,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 193 discussion",
    "answers": {
      "A": "Add an IPv6 CIDR block to the VPC and the private subnet for the EC2 instances. Create route table entries for the IPv6 network, use EC2 instance types that support IPv6, and assign IPv6 addresses to each EC2 instance.",
      "B": "Assign each EC2 instance an IPv6 Elastic IP address. Create a target group and add the EC2 instances as targets. Create a listener on port 443 of the ALB, and associate the target group with the ALB.",
      "C": "Replace the ALB with a Network Load Balancer (NLB). Add an IPv6 CIDR block to the VPC and subnets for the NLB, and assign the NLB an IPv6 Elastic IP address.",
      "D": "Add an IPv6 CIDR block to the VPC and subnets for the ALB. Create a listener on port 443, and specify the dualstack IP address type on the ALB. Create a target group and add the EC2 instances as targets. Associate the target group with the ALB."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/101265-exam-aws-devops-engineer-professional-topic-1-question-193/",
    "multiple_choice": false,
    "question_text": "A DevOps engineer is creating an AWS CloudFormation template to deploy a web service. The web service will run on Amazon EC2 instances in a private subnet behind an Application Load Balancer (ALB). The DevOps engineer must ensure that the service can accept requests from clients that have IPv6 addresses.\n\nWhat should the DevOps engineer do with the CloudFormation template so that IPv6 clients can access the web service?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 194,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 194 discussion",
    "answers": {
      "A": "Enable Amazon CloudWatch Logs to log the EKS components. Create a CloudWatch subscription filter for each component with Lambda as the subscription feed destination.",
      "B": "Enable Amazon CloudWatch Logs to log the EKS components. Create CloudWatch Logs Insights queries linked to Amazon EventBridge events that invoke Lambda.",
      "C": "Enable Amazon S3 logging for the EKS components. Configure an Amazon CloudWatch subscription filter for each component with Lambda as the subscription feed destination.",
      "D": "Enable Amazon S3 logging for the EKS components. Configure S3 PUT Object event notifications with AWS Lambda as the destination."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/101276-exam-aws-devops-engineer-professional-topic-1-question-194/",
    "multiple_choice": false,
    "question_text": "A company has migrated its container-based applications to Amazon EKS and want to establish automated email notifications. The notifications sent to each email address are for specific activities related to EKS components. The solution will include Amazon SNS topics and an AWS Lambda function to evaluate incoming log events and publish messages to the correct SNS topic.\n\nWhich logging solution will support these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 195,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 195 discussion",
    "answers": {
      "A": "Create an AWS WAF web ACL. Associate the web ACL with the CloudFront distribution. Create rules for each type of traffic that the company wants to block.",
      "B": "Create new ALB listener rules on the existing listeners. Configure the new rules to allow or reject incoming traffic based on whether the host header matches the CloudFront fully qualified domain name (FQDN).",
      "C": "Create an AWS PrivateLink endpoint service for the ALB Configure the endpoint service to allow requests from CloudFront. Update the web application origin in CloudFront to use the newly created endpoint service's DNS name.",
      "D": "Create a CloudFront origin access identity (OAI) for the web application. Update the web application origin in CloudFront to use the OAI Update the ALB rules to check for the OAI and return an HTTP 403 error if the OAI header is not present.",
      "E": "Create an AWS Firewall Manager security policy. Attach the security policy to the CloudFront distribution. Use the security policy to attach AWS WAF rule groups for each type of traffic that the company wants to block."
    },
    "suggested_answer": "AB",
    "answer": "AB",
    "link": "https://www.examtopics.com/discussions/amazon/view/101283-exam-aws-devops-engineer-professional-topic-1-question-195/",
    "multiple_choice": true,
    "question_text": "A company has a web application that users access over the internet. The web application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The EC2 instances are in an Auto Scaling group. The ALB is associated with a security group that allows traffic from the internet. The web application has a local cache on each EC2 instance.\n\nDuring a recent security incident requests overloaded the web application and caused an outage for the company's customers. In response to the incident, the company added Amazon CloudFront in front of the web application. All customers now access the web application through CloudFront.\n\nA DevOps engineer must implement a solution that routes all requests through CloudFront. The solution also must give the company the ability to block requests based on the content of the requests, such as header or body information.\n\nWhich combination of steps should the DevOps engineer take to meet these requirements? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 196,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 196 discussion",
    "answers": {
      "A": "Create a new AWS CodeBuild project. Configure the user name and password in an environment variable. Use the user name and password to run the command-line integration steps. Update the CodePipeline pipeline to include a new scan stage. In the new scan stage, include a test action that uses the newly created CodeBuild project.",
      "B": "Create a new AWS CodeBuild project. Store the user name and password as a secret in AWS Secrets Manager Read the secret from Secrets Manager. Use the user name and password to run the command-line integration steps. Update the CodePipeline pipeline to include a new scan stage. In the new scan stage, include a test action that uses the newly created CodeBuild project.",
      "C": "Create a new AWS CodeBuild project. Store the user name and password as a string in AWS Systems Manager Parameter Store. Read the string from Parameter Store. Use the user name and password to run the command-line integration steps. Update the CodePipeline pipeline to include a new scan stage. In the new scan stage, include a test action that uses the newly created CodeBuild project.",
      "D": "Upload the user name and password in an encrypted JSON file to an Amazon S3 bucket that has a specific policy to allow only administrators to read the file. Create a new AWS CodeBuild project. Use the user name and password from the file in Amazon S3 to run the command-line integration steps. Update the CodePipeline pipeline to include a new scan stage. In the new scan stage, include a test action that uses the newly created CodeBuild project."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/101284-exam-aws-devops-engineer-professional-topic-1-question-196/",
    "multiple_choice": false,
    "question_text": "A company needs to scan code changes for security issues before deployment and must prevent noncompliant code from being deployed. The company uses an AWS CodePipeline pipeline that starts when code changes occur. The code changes occur many times each day.\n\nThe company's security team supports a third-party application for code scans and has provided command-line integration steps to submit code scans. The code scan step requires a user name and password.\n\nWhich solution will meet these requirements in the MOST secure way?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 197,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 197 discussion",
    "answers": {
      "A": "Modify the CloudFormation template to include an UpdatePolicy attribute for the Auto Scaling group. Include the AutoScalingRollingUpdate policy with MinInstancesInService of 4 and MaxBatchSize of 2. Whenever a software update is needed, alter either or both of the ImageId and UserData of the AWS::EC2::LaunchTemplate and update the stack.",
      "B": "Set the Auto Scaling group’s minimum capacity to 4. Create an AWS CodeDeploy deployment group that has an in-place deployment type. Select Amazon EC2 Auto Scaling group for the environment configuration. Whenever a new revision is available, create a new CodeDeploy deployment that has a deployment configuration of CodeDeployDefault HalfAtATime.",
      "C": "Set the Auto Scaling group's minimum capacity to 4. Create an AWS CodeDeploy deployment group that has a blue/green deployment type. Select Amazon EC2 Auto Scaling group for the environment configuration. Whenever a new revision is available, create a new CodeDeploy deployment that has a deployment configuration of CodeDeployDefault HalfAtATime.",
      "D": "Modify the CloudFormation template to include a StackPolicy. Designate an AutoScalingReplacingUpdate policy to control the update. Specify MinInstancesInService of 4 and MaxBatchSize of 2. Whenever a software update is needed, alter either or both of the ImageId and UserData of the AWS::EC2::LaunchTemplate and update the stack."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/101285-exam-aws-devops-engineer-professional-topic-1-question-197/",
    "multiple_choice": false,
    "question_text": "A company uses AWS CloudFormation to manage an application that runs on Amazon EC2 Instances. The instances are in an Amazon EC2 Auto Scaling group. The company wants to treat its infrastructure as immutable.\n\nA DevOps engineer must implement a solution to replace two EC2 instances at a time whenever operating system configuration updates are needed or when new Amazon Machine. Images (AMIs) are needed. A minimum of four EC2 instances must be running whenever an update is in progress.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 198,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 198 discussion",
    "answers": {
      "A": "Activate S3 server access logging. Import the access logs into an Amazon Aurora database. Use an Aurora SQL query to analyze the access patterns.",
      "B": "Activate S3 server access logging. Use Amazon Athena to create an external table with the log files. Use Athena to create a SQL query to analyze the access patterns.",
      "C": "Invoke an AWS Lambda function for every S3 object access event. Configure the Lambda function to write the file access information, such as user, S3 bucket, and file key, to an Amazon Aurora database. Use an Aurora SQL query to analyze the access patterns.",
      "D": "Record an Amazon CloudWatch Logs log message for every S3 object access event. Configure a CloudWatch Logs log stream to write the file access information such as user. S3 bucket, and file key, to an Amazon Kinesis Data Analytics for SQL application. Perform a sliding window analysis."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/101287-exam-aws-devops-engineer-professional-topic-1-question-198/",
    "multiple_choice": false,
    "question_text": "A video-sharing company stores its videos in Amazon S3. The company has observed a sudden increase in video access requests, but the company does not know which videos are most popular. The company needs to identify the general access pattern for the video files. This pattern includes the number of users who access a certain file on a given day, as well as the number of pull requests for certain files.\n\nHow can the company meet these requirements with the LEAST amount of effort?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 199,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 199 discussion",
    "answers": {
      "A": "Add a post-build command to remove the temporary files from the container before termination to ensure they cannot be seen by other CodeBuild users.",
      "B": "Update the CodeBuild project role with the necessary permissions and then remove the AWS credentials from the environment variable.",
      "C": "Store the DB_PASSWORD as a SecureString value in AWS Systems Manager Parameter Store and then remove the DB_PASSWORD from the environment variables.",
      "D": "Move the environment variables to the ‘db-deploy-bucket’ Amazon S3 bucket add a prebuild stage to download, then export the variables.",
      "E": "Use AWS Systems Manager run command versus scp and ssh commands directly to the instance.",
      "F": "Scramble the environment variables using XOR followed by Base64, add a section to install, and then run XOR and Base64 to the build phase."
    },
    "suggested_answer": "ABC",
    "answer": "ABC",
    "link": "https://www.examtopics.com/discussions/amazon/view/101304-exam-aws-devops-engineer-professional-topic-1-question-199/",
    "multiple_choice": true,
    "question_text": "A DevOps engineer is working on a project that is hosted on Amazon Linux and has failed a security review. The DevOps manager has been asked to review the company buildspec.yaml file for an AWS CodeBuild project and provide recommendations. The buildspec.yaml file is configured as follows:\n\n//IMG//\n\n\nWhat changes should be recommended to comply with AWS security best practices? (Choose three.)",
    "answer_images": [],
    "question_images": [
      "https://img.examtopics.com/aws-devops-engineer-professional/image12.png"
    ]
  },
  {
    "topic_number": 1,
    "question_number": 200,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 200 discussion",
    "answers": {
      "A": "Create an Amazon EventBridge rule that reacts to an IAM CreateUser API call in AWS CloudTrail.",
      "B": "Create an Amazon EventBridge rule that reacts to an IAM GetLoginProfile API call in AWS CloudTrail.",
      "C": "Create an AWS Lambda function that is a target of the EventBridge rule. Configure the Lambda function to disable any access keys and delete the login profiles that are associated with the IAM user.",
      "D": "Create an AWS Lambda function that is a target of the EventBridge rule. Configure the Lambda function to delete the login profiles that are associated with the IAM user.",
      "E": "Create an Amazon Simple Notification Service (Amazon SNS) topic that is a target of the EventBridge rule. Subscribe the security team’s group email address to the topic.",
      "F": "Create an Amazon Simple Queue Service (Amazon SQS) queue that is a target of the Lambda function. Subscribe the security team's group email address to the queue."
    },
    "suggested_answer": "ACE",
    "answer": "ACE",
    "link": "https://www.examtopics.com/discussions/amazon/view/101288-exam-aws-devops-engineer-professional-topic-1-question-200/",
    "multiple_choice": true,
    "question_text": "A DevOps engineer at a company is supporting an AWS environment in which all users use AWS IAM identity Center (AWS Single Sign-On). The company wants to immediately disable credentials of any new IAM user and wants the security team to receive a notification.\n\nWhich combination of steps should the DevOps engineer take to meet these requirements? (Choose three.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 201,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 201 discussion",
    "answers": {
      "A": "Check the ApproximateAgeOfOldestMessage metric for the SQS queue. Increase the Lambda function concurrency limit.",
      "B": "Check the ApproximateAgeOfOldestMessage metric for the SQS queue. Configure a redrive policy on the SQS queue.",
      "C": "Check the NumberOfMessagesSent metric for the SQS queue. Increase the SQS queue visibility timeout.",
      "D": "Check the WriteThrottleEvents metric for the DynamoDB table. Increase the maximum write capacity units (WCUs) for the table's scaling policy.",
      "E": "Check the Throttles metric for the Lambda function. Increase the Lambda function timeout."
    },
    "suggested_answer": "AD",
    "answer": "AD",
    "link": "https://www.examtopics.com/discussions/amazon/view/101289-exam-aws-devops-engineer-professional-topic-1-question-201/",
    "multiple_choice": true,
    "question_text": "An ecommerce company is receiving reports that its order history page is experiencing delays in reflecting the processing status of orders. The order processing system consists of an AWS Lambda function that uses reserved concurrency. The Lambda function processes order messages from an Amazon Simple Queue Service (Amazon SQS) queue and inserts processed orders into an Amazon DynamoDB table. The DynamoDB table has auto scaling enabled for read and write capacity.\n\nWhich actions should a DevOps engineer take to resolve this delay? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 202,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 202 discussion",
    "answers": {
      "A": "Configure EC2 detailed monitoring for the EC2 instances. Create an AWS Lambda function to create a CloudWatch alarm for the bw_out_allowance_exceeded CloudWatch metric for each EC2 instance Configure the alarm to notify the DevOps team.",
      "B": "Configure the unified CloudWatch agent on the EC2 instances to export the bw_out_allowance_exceeded metric to CloudWatch metrics. Create a CloudWatch composite alarm to monitor all bw_out_allowance_exceeded metrics. Configure the alarm to notify the DevOps team.",
      "C": "Configure VPC flow logging to Amazon CloudWatch Logs for the EC2 instances. Create a CloudWatch Logs metric filter to match events in which bandwidth allowance is exceeded. Create a CloudWatch composite alarm to monitor all bw_out_allowance_exceeded metrics. Configure the alarm to notify the DevOps team.",
      "D": "Configure the unified CloudWatch agent on the EC2 instances to export the bw_out_allowance_exceeded metric to CloudWatch metrics. Create an AWS Lambda function to create a CloudWatch alarm for the bw_out_allowance_exceeded CloudWatch metric for each EC2 instance. Configure the alarm to notify the DevOps team."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/101293-exam-aws-devops-engineer-professional-topic-1-question-202/",
    "multiple_choice": false,
    "question_text": "A company has an application that runs on current-generation Amazon EC2 instances in a VPC. The EC2 instances run Amazon Linux and are launched in an Amazon EC2 Auto Scaling group. The application retrieves data from an Amazon S3 bucket, processes the data, and uploads the processed data to a different S3 bucket.\n\nRecently, the application's performance worsened. A manual investigation identified that outbound network bandwidth utilization was too high for the type of EC2 instance. The company updated the EC2 instances to a larger EC2 instance size.\n\nThe company's DevOps team needs to receive notification from an Amazon CloudWatch alarm if the application attempts to use more outbound network bandwidth than is available to the EC2 instances.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 203,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 203 discussion",
    "answers": {
      "A": "Configure AWS Firewall Manager for the organization. In the Firewall Manager administrator account, create an AWS WAF policy. Turn on automatic remediation and define the web ACL. Configure the policy scope to apply to all ALBs in the organization.",
      "B": "Use AWS Resource Access Manager (AWS RAM) from the organization's management account to enable resource sharing in the organization. Create the web ACL. Configure a resource share of the web ACL for the organization. Associate the shared web ACL with all the ALBs in the organization.",
      "C": "Set up the ALB_WAF_ENABLED AWS Config managed rule with automatic remediation. Configure the rule to create the web ACL and to attach the web ACL to all ALBs in an AWS account. Create an AWS Config conformance pack that contains the rule. Deploy the conformance pack to all AWS accounts in the organization.",
      "D": "Configure AWS Firewall Manager for the organization. In the Firewall Manager administrator account, create an AWS WAF policy that defines the web ACL. Set up the ALB_WAF_ENABLED AWS Config managed rule with automatic remediation. Configure the rule to attach the web ACL to all ALBs in an AWS account. Deploy the rule to all AWS accounts in the organization."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/101295-exam-aws-devops-engineer-professional-topic-1-question-203/",
    "multiple_choice": false,
    "question_text": "A company uses Application Load Balancers (ALBs) as part of its application architecture. The company has ALBs in AWS accounts that are part of an organization in AWS Organizations. The company has configured AWS Config in all AWS accounts in the organization.\n\nThe company needs to apply an AWS WAF web ACL with a common set of rules to all ALBs, including any ALBs that are created in the future. Administrators of each AWS account must be able to define their own AWS WAF rules that are in addition to the common rules that the company’s security team provides for all the accounts.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 204,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 204 discussion",
    "answers": {
      "A": "Create an Amazon S3 bucket in us-west-2. Configure server-side encryption with Amazon S3 managed encryption keys (SSE-S3) for the S3 bucket. Create and schedule an AWS Lambda function to run weekly to export the CloudWatch logs from the last week to the S3 bucket in us-west-2.",
      "B": "Create an Amazon S3 bucket in us-west-2. Configure server-side encryption with AWS KMS keys (SSE-KMS) for the S3 bucket. Create and schedule an AWS Lambda function to run weekly to export the CloudWatch logs from the last week to the S3 bucket in us-west-2.",
      "C": "Create an Amazon S3 bucket in us-east-1. Create an S3 bucket in us-west-2. Configure server-side encryption with Amazon S3 managed encryption keys (SSE-S3) and turn on versioning for both S3 buckets. Create and schedule an AWS Lambda function to run weekly to export the CloudWatch logs from the last week to the S3 bucket in us-east-1. Configure a replication rule on the S3 bucket in us-east-1 to replicate the logs to the S3 bucket in us-west-2.",
      "D": "Create an Amazon S3 bucket in us-east-1. Create an S3 bucket in us-west-2. Configure server-side encryption with AWS KMS keys (SSE-KMS) and turn on versioning for both S3 buckets. Create and schedule an AWS Lambda function to run weekly to export the CloudWatch logs from the last week to the S3 bucket in us-east-1. Configure a replication rule on the S3 bucket in us-east-1 to replicate the logs to the S3 bucket in us-west-2."
    },
    "suggested_answer": "D",
    "answer": "D",
    "link": "https://www.examtopics.com/discussions/amazon/view/101297-exam-aws-devops-engineer-professional-topic-1-question-204/",
    "multiple_choice": false,
    "question_text": "A company publishes application logs to an Amazon CloudWatch Logs log group in the us-east-1 Region. The company needs to export the logs from us-east-1 to the us-west-2 Region on a weekly basis. The logs must be encrypted in both Regions.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 205,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 205 discussion",
    "answers": {
      "A": "Create an application group and a deployment group in AWS CodeDeploy. Install the CodeDeploy agent on the EC2 instances.",
      "B": "Create an application revision and a deployment group in AWS CodeDeploy. Create an environment in CodeDeploy. Register the EC2 instances to the CodeDeploy environment.",
      "C": "Use AWS CodePipeline to invoke the CodeBuild job, run the CloudFormation update, and pause for a manual approval step. After approval, start the AWS CodeDeploy deployment.",
      "D": "Use AWS CodePipeline to invoke the CodeBuild job, create CloudFormation change sets for each of the application stacks, and pause for a manual approval step. After approval, run the CloudFormation change sets and start the AWS CodeDeploy deployment.",
      "E": "Use AWS CodePipeline to invoke the CodeBuild job, create CloudFormation change sets for each of the application stacks, and pause for a manual approval step. After approval, start the AWS CodeDeploy deployment."
    },
    "suggested_answer": "AD",
    "answer": "AD",
    "link": "https://www.examtopics.com/discussions/amazon/view/101301-exam-aws-devops-engineer-professional-topic-1-question-205/",
    "multiple_choice": true,
    "question_text": "A company runs an application on Amazon EC2 instances. The company uses a series of AWS CloudFormation stacks to define the application resources. A developer performs updates by building and testing the application on a laptop and then uploading the build output and CloudFormation stack templates to Amazon S3. The developer’s peers review the changes before the developer performs the CloudFormation stack update and installs a new version of the application onto the EC2 instances.\n\nThe deployment process is prone to errors and is time-consuming when the developer updates each EC2 instance with the new application. The company wants to automate as much of the application deployment process as possible while retaining a final manual approval step before the modification of the application or resources.\n\nThe company already has moved the source code for the application and the CloudFormation templates to AWS CodeCommit. The company also has created an AWS CodeBuild project to build and test the application.\n\nWhich combination of steps will meet the company's requirements? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 206,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 206 discussion",
    "answers": {
      "A": "Create an AWS Organizations SCP that denies access to all non-global services in non-US Regions. Attach the policy to the root of the organization.",
      "B": "Configure AWS CloudTrail to send logs to Amazon CloudWatch Logs and enable it for all Regions. Use a CloudWatch Logs metric filter to send an alert on any service activity in non-US Regions.",
      "C": "Use an AWS Lambda function that checks for AWS service activity and deploy it to all Regions. Write an Amazon EventBridge rule that runs the Lambda function every hour, sending an alert if activity is found in a non-US Region.",
      "D": "Use an AWS Lambda function to query Amazon Inspector to look for service activity in non-US Regions and send alerts if any activity is found.",
      "E": "Write an SCP using the aws:RequestedRegion condition key limiting access to US Regions. Apply the policy to all users, groups and roles."
    },
    "suggested_answer": "AB",
    "answer": "AB",
    "link": "https://www.examtopics.com/discussions/amazon/view/101299-exam-aws-devops-engineer-professional-topic-1-question-206/",
    "multiple_choice": true,
    "question_text": "A DevOps engineer is implementing governance controls for a company that requires its infrastructure to be housed within the United States. The engineer must restrict which AWS Regions can be used, and ensure an alert is sent as soon as possible if any activity outside the governance policy takes place. The controls should be automatically enabled on any new Region outside the United States (US).\n\nWhich combination of actions will meet these requirements? (Choose two.)",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 207,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 207 discussion",
    "answers": {
      "A": "Turn on AWS Config in the AWS account. Deploy the lam-user-unused-credentials-check AWS Config managed rule Configure the rule to run periodically Configure AWS. Config automatic remediation to run the AWSConfigRemediation-RevokeUnusedlAMUserCredentials AWS Systems Manager Automation runbook.",
      "B": "Use AWS Identity and Access Management Access Analyzer to create an analyzer in the AWS account. Create an Amazon EventBridge rule to match IAM Access Analyzer events for IAM users that were last accessed more than 90 days ago. Configure the rule to run the AWSConfigRemediation-DetachlAMPolicy AWS Systems Manager Automation runbook to detach any policies that are attached to the IAM user.",
      "C": "Enable AWS Trusted Advisor in the AWS account. Use the AWS Developer Support plan to access the AWS Support API. Configure an Amazon EventBridge scheduled rule to use the Support API’s Trusted Advisor IAM Access Key Rotation check to discover IAM credentials that have not been accessed for more than 90 days. Configure another EventBridge rule to use the Trusted Advisor Check Item Refresh Status event type and to run the AWSConfigRemediation-RevokeUnusedlAMUserCredentials AWS Systems Manager Automation runbook.",
      "D": "Enable AWS Security Hub in the AWS account. Configure a Security Hub rule that determines when an IAM user was last accessed. Configure an Amazon EventBridge rule to match the Security Hub rule and to run the AWSConfigRemediation-RevokeUnusedlAMUserCredentials AWS Systems Manager Automation runbook."
    },
    "suggested_answer": "A",
    "answer": "A",
    "link": "https://www.examtopics.com/discussions/amazon/view/101300-exam-aws-devops-engineer-professional-topic-1-question-207/",
    "multiple_choice": false,
    "question_text": "A company grants external users access to its AWS account by creating an IAM user for each external user. A DevOps engineer must implement a solution to revoke access from IAM users that have not accessed the account in 90 days.\n\nWhich solution will meet these requirements?",
    "answer_images": [],
    "question_images": []
  },
  {
    "topic_number": 1,
    "question_number": 208,
    "title": "Exam AWS DevOps Engineer Professional topic 1 question 208 discussion",
    "answers": {
      "A": "Use AWS Identity and Access Management Access Analyzer to generate a new IAM policy based on the IAM user’s AWS CloudTrail history. Replace the IAM user policy with the newly generated policy.",
      "B": "Use AWS Identity and Access Management Access Analyzer to generate a new IAM policy based on the IAM user’s AWS CloudTrail history. Attach the newly generated policy as a permissions boundary to the IAM user.",
      "C": "Use AWS Identity and Access Management Access Analyzer to discover the last accessed information for the IAM user and to create a new IAM policy that allows only the services and actions that the last accessed review identified. Replace the IAM user policy with the newly generated policy.",
      "D": "Use AWS Identity and Access Management Access Analyzer to discover the last accessed information for the IAM user and to create a new IAM policy that allows only the services and actions that the last accessed review identified. Attach the newly generated policy as a permissions boundary to the IAM user."
    },
    "suggested_answer": "B",
    "answer": "B",
    "link": "https://www.examtopics.com/discussions/amazon/view/101303-exam-aws-devops-engineer-professional-topic-1-question-208/",
    "multiple_choice": false,
    "question_text": "A company has provided an externally hosted third-party vendor product with access to the company's AWS account. The vendor product performs various AWS actions in the AWS account and requires various IAM permissions. The company granted the access by creating an IAM user, associating IAM policies and inserting the IAM user credentials into the vendor product.\n\nA security review reveals that the vendor’s access is overly permissive. The company wants to apply the principle of least privilege and wants to continue giving the vendor permissions to perform only the actions that the vendor has performed in the last 6 months.\n\nWhich solution will meet these requirements with the LEAST effort?",
    "answer_images": [],
    "question_images": []
  }
]